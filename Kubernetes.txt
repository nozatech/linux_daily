Kubernetes 

Upgrading kubeadm clusters from v1.14 to v1.15
https://v1-15.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade-1-15/


aws-iam-authenticator
https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html


kubectl Cheat Sheet
https://kubernetes.io/docs/reference/kubectl/cheatsheet/

0.Kubernetes Version Check
	$ kubectl get nodes -o yaml
	$ kubectl cluster-info
	$ kubectl get nodes; kubectl describe node <node>;
	$ kubectl verion
		Client Version: version.Info{Major:"1", Minor:"15",  ..., Platform:"linux/amd64"}
		Server Version: version.Info{Major:"1", Minor:"14",  ..., Platform:"linux/amd64"}
	
	
1. Kubectl Autocomplete
  # setup autocomplete in bash into the current shell, bash-completion package should be installed first.
	$ source <(kubectl completion bash) 

  # add autocomplete permanently to your bash shell.
	$ echo "source <(kubectl completion bash)" >> ~/.bashrc 

  # Shorthand alias for kubectl
    $ alias k=kubectl
	$ complete -F __start_kubectl k

2. Kubectl Context and Configuration
	# kubectl communicates with and modifies configuration information
	
	$ kubectl config view  <= Show Merged kubeconfig settings.
	$ KUBECONFIG=~/.kube/config:~/.kube/kubconfig2 	<= use multiple kubeconfig files at the same time and view 
														merged config
	$ kubectl config view -o jsonpath='{.users[?(@.name == "e2e")].user.password}' <= get the password for the e2e user
	$ kubectl config view -o jsonpath='{.users[].name}'    # get a list of users
	$ kubectl config get-contexts                          # display list of contexts 
	$ kubectl config current-context			           # display the current-context
	$ kubectl config use-context my-cluster-name           # set the default context to my-cluster-name
	
	## add a new cluster to your kubeconf that supports basic auth
	  $ kubectl config set-credentials kubeuser/foo.kubernetes.com --username=kubeuser --password=kubepassword
		
	# permanently save the namespace for all subsequent kubectl commands in that context.
	  $ kubectl config set-context --current --namespace=ggckad-s2

	# set a context utilizing a specific username and namespace.
	  $ kubectl config set-context gce --user=cluster-admin --namespace=foo && kubectl config use-context gce
	 
	  $ kubectl config unset users.foo                       # delete user foo

3. Apply
	'Apply' manages applications through files defining Kubernetes resources. 
	It creates and updates resources in a cluster through running kubectl apply. 

  # Creating Objects using the file extension .yaml, .yml, and .json
	$ kubectl apply -f ./my-manifest.yaml            # create resource(s)
	$ kubectl apply -f ./my1.yaml -f ./my2.yaml      # create from multiple files
	$ kubectl apply -f ./dir                         # create resource(s) in all manifest files in dir
	$ kubectl apply -f https://git.io/vPieo          # create resource(s) from url
	$ kubectl create deployment nginx --image=nginx  # start a single instance of nginx
	$ kubectl explain pods,svc                       # get the documentation for pod and svc manifests
	
	

# Create multiple YAML objects from stdin
------------------------------------------------------------
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: busybox-sleep
spec:
  containers:
  - name: busybox
    image: busybox
    args:
    - sleep
    - "1000000"
---
apiVersion: v1
kind: Pod
metadata:
  name: busybox-sleep-less
spec:
  containers:
  - name: busybox
    image: busybox
    args:
    - sleep
    - "1000"
EOF

# Create a secret with several keys
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: mysecret
type: Opaque
data:
  password: $(echo -n "s33msi4" | base64 -w0)
  username: $(echo -n "jane" | base64 -w0)
EOF
-------------------------------------------------------------------------


5. Viewing, Finding Resources
	kubectl set image deployment/frontend www=image:v2               # Rolling update "www" containers of "frontend" deployment, updating the image
	kubectl rollout history deployment/frontend                      # Check the history of deployments including the revision 
	kubectl rollout undo deployment/frontend                         # Rollback to the previous deployment
	kubectl rollout undo deployment/frontend --to-revision=2         # Rollback to a specific revision
	kubectl rollout status -w deployment/frontend                    # Watch rolling update status of "frontend" deployment until completion


	# deprecated starting version 1.11
	kubectl rolling-update frontend-v1 -f frontend-v2.json           # (deprecated) Rolling update pods of frontend-v1
	kubectl rolling-update frontend-v1 frontend-v2 --image=image:v2  # (deprecated) Change the name of the resource and update the image
	kubectl rolling-update frontend --image=image:v2                 # (deprecated) Update the pods image of frontend
	kubectl rolling-update frontend-v1 frontend-v2 --rollback        # (deprecated) Abort existing rollout in progress

	$ cat pod.json | kubectl replace -f -                              # Replace a pod based on the JSON passed into std

	# Force replace, delete and then re-create the resource. Will cause a service outage.
	kubectl replace --force -f ./pod.json

	# Create a service for a replicated nginx, which serves on port 80 and connects to the containers on port 8000
	kubectl expose rc nginx --port=80 --target-port=8000

	# Update a single-container pod's image version (tag) to v4
	kubectl get pod mypod -o yaml | sed 's/\(image: myimage\):.*$/\1:v4/' | kubectl replace -f -

	kubectl label pods my-pod new-label=awesome                      # Add a Label
	kubectl annotate pods my-pod icon-url=http://goo.gl/XXBTWq       # Add an annotation
	kubectl autoscale deployment foo --min=2 --max=10                # Auto scale a deployment "foo"


6. Editing Resources
	The edit any API resource in an editor.

	kubectl edit svc/docker-registry                      # Edit the service named docker-registry
	KUBE_EDITOR="nano" kubectl edit svc/docker-registry   # Use an alternative editor


7. Scaling Resources
	kubectl scale --replicas=3 rs/foo                                 # Scale a replicaset named 'foo' to 3
	kubectl scale --replicas=3 -f foo.yaml                            # Scale a resource specified in "foo.yaml" to 3
	kubectl scale --current-replicas=2 --replicas=3 deployment/mysql  # If the deployment named mysql's current size is 2, scale mysql to 3
	kubectl scale --replicas=5 rc/foo rc/bar rc/baz                   # Scale multiple replication controllers

8. Deleting Resources
	kubectl delete -f ./pod.json                                              # Delete a pod using the type and name specified in pod.json
	kubectl delete pod,service baz foo                                        # Delete pods and services with same names "baz" and "foo"
	kubectl delete pods,services -l name=myLabel                              # Delete pods and services with label name=myLabel
	kubectl delete pods,services -l name=myLabel --include-uninitialized      # Delete pods and services, including uninitialized ones, with label name=myLabel
	kubectl -n my-ns delete po,svc --all                                      # Delete all pods and services, including uninitialized ones, in namespace my-ns,
	
	# Delete all pods matching the awk pattern1 or pattern2
	kubectl get pods  -n mynamespace --no-headers=true | awk '/pattern1|pattern2/{print $1}' | xargs  kubectl delete -n mynamespace pod



9. Interacting with running Pods
	kubectl logs my-pod                                 # dump pod logs (stdout)
	kubectl logs -l name=myLabel                        # dump pod logs, with label name=myLabel (stdout)
	kubectl logs my-pod --previous                      # dump pod logs (stdout) for a previous instantiation of a container
	kubectl logs my-pod -c my-container                 # dump pod container logs (stdout, multi-container case)
	kubectl logs -l name=myLabel -c my-container        # dump pod logs, with label name=myLabel (stdout)
	kubectl logs my-pod -c my-container --previous      # dump pod container logs (stdout, multi-container case) for a previous instantiation of a container
	kubectl logs -f my-pod                              # stream pod logs (stdout)
	kubectl logs -f my-pod -c my-container              # stream pod container logs (stdout, multi-container case)
	kubectl logs -f -l name=myLabel --all-containers    # stream all pods logs with label name=myLabel (stdout)
	kubectl run -i --tty busybox --image=busybox -- sh  # Run pod as interactive shell
	kubectl attach my-pod -i                            # Attach to Running Container
	kubectl port-forward my-pod 5000:6000               # Listen on port 5000 on the local machine and forward to port 6000 on my-pod
	kubectl exec my-pod -- ls /                         # Run command in existing pod (1 container case)
	kubectl exec my-pod -c my-container -- ls /         # Run command in existing pod (multi-container case)
	kubectl top pod POD_NAME --containers               # Show metrics for a given pod and its containers



10. Interacting with Nodes and Cluster
	kubectl cordon my-node                                                # Mark my-node as unschedulable
	kubectl drain my-node                                                 # Drain my-node in preparation for maintenance
	kubectl uncordon my-node                                              # Mark my-node as schedulable
	kubectl top node my-node                                              # Show metrics for a given node
	kubectl cluster-info                                                  # Display addresses of the master and services
	kubectl cluster-info dump                                             # Dump current cluster state to stdout
	kubectl cluster-info dump --output-directory=/path/to/cluster-state   # Dump current cluster state to /path/to/cluster-state

	# If a taint with that key and effect already exists, its value is replaced as specified.
	kubectl taint nodes foo dedicated=special-user:NoSchedule

11. Resource types
	List all supported resource types along with their shortnames, API group, whether they are namespaced, and Kind:
	$ kubectl api-resources
		kubectl api-resources --namespaced=true      # All namespaced resources
		kubectl api-resources --namespaced=false     # All non-namespaced resources
		kubectl api-resources -o name                # All resources with simple output (just the resource name)
		kubectl api-resources -o wide                # All resources with expanded (aka "wide") output
		kubectl api-resources --verbs=list,get       # All resources that support the "list" and "get" request verbs
		kubectl api-resources --api-group=extensions # All resources in the "extensions" API group	

12. Formatting output
	-o=custom-columns=<spec>	Print a table using a comma separated list of custom columns
	-o=custom-columns-file=<filename>	Print a table using the custom columns template in the <filename> file
	-o=json	Output a JSON formatted API object
	-o=jsonpath=<template>	Print the fields defined in a jsonpath expression
	-o=jsonpath-file=<filename>	Print the fields defined by the jsonpath expression in the <filename> file
	-o=name	Print only the resource name and nothing else
	-o=wide	Output in the plain-text format with any additional information, and for pods, the node name is included
	-o=yaml	Output a YAML formatted API object



13. Kubectl output verbosity and debugging -v, --v
	--v=0	Generally useful for this to always be visible to a cluster operator.
	--v=1	A reasonable default log level if you don’t want verbosity.
	--v=2	Useful steady state information about the service and important log messages that may correlate to significant changes in the system. This is the recommended default log level for most systems.
	--v=3	Extended information about changes.
	--v=4	Debug level verbosity.
	--v=6	Display requested resources.
	--v=7	Display HTTP request headers.
	--v=8	Display HTTP request contents.
	--v=9	Display HTTP request contents without truncation of contents.
	







-------------------------------------------------------------------------
Prerequisite
Ansible <= operating-system-level dependencies and their configuration
		1. An SSH key pair on your local Linux/Mac OS/BSD machine. If you haven't used SSH keys before, 
			you can learn how to set them up by following this explanation of how to set up SSH keys on your local machine.
		2. Three servers running Ubuntu 16.04 with at least 1GB RAM. You should be able to SSH into each 
			server as the root user with your SSH key pair.
		3. Ansible installed on your local machine. If you're running Ubuntu 16.04 as your OS, follow the 
			"Step 1 - Installing Ansible" section in How to Install and Configure Ansible on Ubuntu 16.04 
			to install Ansible. For installation instructions on other platforms like Mac OS X or CentOS, 
			follow the official Ansible installation documentation.
		4. Familiarity with Ansible playbooks. For review, check out Configuration Management 101: Writing Ansible Playbooks.
		5. Knowledge of how to launch a container from a Docker image. Look at "Step 5 — Running a Docker Container" 
			in How To Install and Use Docker on Ubuntu 16.04 if you need a refresher.


https://www.digitalocean.com/community/tutorials/how-to-create-a-kubernetes-1-10-cluster-using-kubeadm-on-centos-7
https://www.digitalocean.com/community/tutorials/how-to-create-a-kubernetes-1-10-cluster-using-kubeadm-on-ubuntu-16-04


CNI 	<- Container Network Interface is a library definition, and a set of tools under the 
		   umbrella of the Cloud Native Computing Foundation project.



--------------------------------------------------------------------------------
Kubeadm 
------------------------------------------------------------------------------------	
	automates the installation and configuration of Kubernetes components such as the 
	1) API server, 2)Controller Manager, 3)Kube DNS

	1. One master node <= The master node (a node in Kubernetes refers to a server) is responsible for 
							managing the state of the cluster. It runs Etcd, which stores cluster data among 
							components that schedule workloads to worker nodes.
							Two worker nodes
	2. Worker nodes 	<= are the servers where your workloads (i.e. containerized applications and services) will run. 
							A worker will continue to run your workload once they're assigned to it, even if the master 
							goes down once scheduling is complete. A cluster's capacity can be increased by adding workers.
	e.g.
	$ kubeadm version

------------------------------------------------------------------------------------
Kunelet(Node Agent)
	https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/
------------------------------------------------------------------------------------
	A system service/program that runs on all nodes(worker servers) and handles node-level(workers) operation
	
	e.g.
	$ kubelet
	
------------------------------------------------------------------------------------	
Kubectl
------------------------------------------------------------------------------------
	A CLI tool used for issuing commands to the cluster through its API Server(Master)

	e.g.
	$ kubectl --kubeconfig='bnea-k8-config.yml' get nodes
	$ kubectl cluster-info
	$ kubectl version
	$ kubectl get nodes
	$ kubectl get pods
	
------------------------------------------------------------------------------------
Pods                            
------------------------------------------------------------------------------------	
	is an atomic unit that runs one or more Docker containers
------------------------------------------------------------------------------------                            
 
------------------------------------------------------------------------------------	
Pod Network Plugins
------------------------------------------------------------------------------------ 
	Flannel(체크남방) 



                            
### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###                             
                            
$ kubectl --kubeconfig=''    <= Path to the kubeconfig file to use for CLI requests.      

$ kubectl config view --raw			<= Account Info

$ kubectl --kubeconfig='bnea-k8-config.yml' get nodes
    NAME                STATUS   ROLES    AGE    VERSION
    bnea-k8-master      Ready    master   216d   v1.11.0
    bnea-k8-worker-01   Ready    <none>   216d   v1.11.0
    bnea-k8-worker-02   Ready    <none>   216d   v1.11.0
                           


                            
### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### 
Kubernetes Cluster Introspection(
                           
                           
$ kubectl api-resources  <= complete list of supported resources.
                           
# kubectl api-describes


$ kubectl options

$ kubectl get nodes      <= List currnet     nodes(Wokers)
$ kubectl get pods       <= List currnet     pods(Dockers)
$ kubectl get rc         <= List replication controllers    
$ kubectl get services   <= List services
              service
              svc

# Describe pod <name>
    $ kubectl describe pod 
    $ kubectl describe pod <name>


--------------------------------------------------                            
                            

                            
### Terminology                            
                            
kops 	<= Kubernetes Operations
kubeadm <= easily bootstrap a secure Kubernetes cluster.
  $ kubeadm --help
                            
# docker: Got permission denied
$ sudo usermod -a -G docker $USER                            
                            
                            
                            
                            
                            
## Kubenetes Cluster Dashboard
https://github.com/kubernetes/dashboard/blob/master/README.md

                            
                            
                            
                            
                            
                            
------------------------------------------------------------------------------------                            
# Bash Auto Completion
  https://kubernetes.io/docs/tasks/tools/install-kubectl/#enabling-shell-autocompletion                         
------------------------------------------------------------------------------------
	$ kubectl completion bash				<= Sourcing the completion script in your shell enables kubectl autocompletion.
	$ type _init_completion					<= discover how your Linux commands are executed 
		_init_completion is a 'function'		and understand your system better.
		



	$ sudo apt-get install -y bash-completion 
	$ sudo yum install -y bash-completion

	# commands create  under '/usr/share/bash-completion/bash_completion'
	$ ll /usr/share/bash-completion/
		-rw-r--r--  1 root root 66881 Jun 10  2014 bash_completion		<=  main script of bash-completion 
		drwxr-xr-x. 2 root root  8192 Sep 12 18:33 completions
		drwxr-xr-x  2 root root    18 Sep 12 18:33 helpers
	
	# Load to Current Shell
	$ source /usr/share/bash-completion/bash_completion
	
	# Add to .bashrc 
	  $ echo 'source <(kubectl completion bash)' >>~/.bashrc
	# Add the completion script to the /etc/bash_completion.d directory:
	  $ kubectl completion bash >/etc/bash_completion.d/kubectl
	  
	  
	  
	  

Enable kubectl autocompletion
 echo "source <(kubectl completion bash)" >> ~/.bashrc 


kubectl completion bash >/etc/bash_completion.d/kubectl

netops$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl



------------------------------------------------------------------------------------
------------------------------------------------------------------------------------
### 	Kubernetes Cheat Sheet     ###
------------------------------------------------------------------------------------
	https://cheatsheet.dennyzhang.com/cheatsheet-kubernetes-A4
	
------------------------------------------------------------------------------------
1.0 Tools Name
------------------------------------------------------------------------------------
kubectl		the command line util to talk to k8s cluster

kubeadm		the command to bootstrap the cluster

kubefed		the command line to control a Kubernetes Cluster Federation

Kubernetes 	Components	Link: Kubernetes Components

------------------------------------------------------------------------------------
1.1 COMMON COMMANDS
------------------------------------------------------------------------------------
Run curl test temporarily				kubectl run --rm mytest --image=yauritux/busybox-curl -it
Run wget test temporarily				kubectl run --rm mytest --image=busybox -it
Run nginx deployment with 2 replicas: 	kubectl run my-nginx --image=nginx --replicas=2 --port=80
Set namespace preference				kubectl config set-context $(kubectl config current-context) --namespace=<ns1>
List pods with nodes info				kubectl get pod -o wide
List everything							kubectl get all --all-namespaces
Get all services						kubectl get service --all-namespaces
Show nodes with labels					kubectl get nodes --show-labels
Validate yaml file with dry run			kubectl create --dry-run --validate -f pod-dummy.yaml
Start a temporary pod for testing		kubectl run --rm -i -t --image=alpine test-$RANDOM -- sh
kubectl run shell command				kubectl exec -it mytest -- ls -l /etc/hosts
Get system conf via configmap			kubectl -n kube-system get cm kubeadm-config -o yaml
Get deployment yaml						kubectl -n denny-websites get deployment mysql -o yaml
Explain resource						kubectl explain pods, kubectl explain svc
Watch pods								kubectl get pods -n wordpress --watch
Query healthcheck endpoint				curl -L http://127.0.0.1:10250/healthz
Open a bash terminal in a pod			kubectl exec -it storage sh
Check pod environment variables			kubectl exec redis-master-ft9ex env
Enable kubectl shell autocompletion		echo "source <(kubectl completion bash)" >>~/.bashrc, and reload
Use minikube dockerd in your laptop	eval $(minikube docker-env), No need to push docker hub any more
Kubectl apply a folder of yaml files	kubectl apply -R -f .
Get services sorted by name				kubectl get services –sort-by=.metadata.name
Get pods sorted by restart count		kubectl get pods –sort-by=’.status.containerStatuses[0].restartCount’

------------------------------------------------------------------------------------
1.2 CHECK PERFORMANCE
------------------------------------------------------------------------------------
Get node resource usage							kubectl top node
Get pod resource usage							kubectl top pod
Get resource usage for a given pod				kubectl top <pod_name> --containers
List resource utilization for all containers	kubectl top pod --all-namespaces --containers=true

------------------------------------------------------------------------------------
1.3 RESOURCES DELETION
------------------------------------------------------------------------------------
Delete pod								kubectl delete pod/<pod-name> -n <my-namespace>
Delete pod by force						kubectl delete pod/<pod-name> --grace-period=0 --force
Delete pods by labels					kubectl delete pod -l env=test
Delete deployments by labels			kubectl delete deployment -l app=wordpress
Delete all resources filtered by labels	kubectl delete pods,services -l name=myLabel
Delete resources under a namespace		kubectl -n my-ns delete po,svc --all
Delete persist volumes by labels		kubectl delete pvc -l app=wordpress
Delete statefulset only (not pods)		kubectl delete sts/<stateful_set_name> --cascade=false

------------------------------------------------------------------------------------
1.4 LOG & CONF FILES
------------------------------------------------------------------------------------
Config folder				/etc/kubernetes/
Certificate files			/etc/kubernetes/pki/
Credentials to API server	/etc/kubernetes/kubelet.conf
Superuser credentials		/etc/kubernetes/admin.conf
kubectl config file			~/.kube/config
Kubernets working dir		/var/lib/kubelet/
Docker working dir			/var/lib/docker/, /var/log/containers/
Etcd working dir			/var/lib/etcd/
Network cni					/etc/cni/net.d/
Log files					/var/log/pods/
log in master node			/var/log/kube-apiserver.log, kube-scheduler.log, kube-controller-manager.log
log in worker node			/var/log/kubelet.log, kubelet-proxy.log

Env	/etc/systemd/system/kubelet.service.d/10-kubeadm.conf
Env	export KUBECONFIG=/etc/kubernetes/admin.conf

------------------------------------------------------------------------------------
1.5 POD
------------------------------------------------------------------------------------
List all pods					kubectl get pods
List pods for all namespace		kubectl get pods -all-namespaces
List all critical pods			kubectl get -n kube-system pods -a
List pods with more info		kubectl get pod -o wide, kubectl get pod/<pod-name> -o yaml
Get pod info					kubectl describe pod/srv-mysql-server
List all pods with labels		kubectl get pods --show-labels
List running pods				kubectl get pods –field-selector=status.phase=Running
Get Pod initContainer status	kubectl get pod --template '{{.status.initContainerStatuses}}' <pod-name>
kubectl run command				kubectl exec -it -n “$ns” “$podname” – sh -c “echo $msg >>/dev/err.log”
Watch pods						kubectl get pods -n wordpress --watch
Get pod by selector				podname=$(kubectl get pods -n $namespace –selector=”app=syslog” -o jsonpath='{.items[*].metadata.name}’)
List pods and containers		kubectl get pods -o=’custom-columns=PODS:.metadata.name,CONTAINERS:.spec.containers[*].name’
List pods, containers&images	kubectl get pods -o=’custom-columns=PODS:.metadata.name,CONTAINERS:.spec.containers[*].name,Images:.spec.containers[*].image’

------------------------------------------------------------------------------------
1.6 LABEL & ANNONTATION
------------------------------------------------------------------------------------
Filter pods by label				kubectl get pods -l owner=denny
Manually add label to a pod			kubectl label pods dummy-input owner=denny
Remove label						kubectl label pods dummy-input owner-
Manually add annonation to a pod	kubectl annotate pods dummy-input my-url=https://dennyzhang.com

------------------------------------------------------------------------------------
1.7 DEPLOYMENT & SCALE
------------------------------------------------------------------------------------
Scale out						kubectl scale --replicas=3 deployment/nginx-app
online rolling upgrade			kubectl rollout app-v1 app-v2 --image=img:v2
Roll backup						kubectl rollout app-v1 app-v2 --rollback
List rollout					kubectl get rs
Check update status				kubectl rollout status deployment/nginx-app
Check update history			kubectl rollout history deployment/nginx-app
Pause/Resume					kubectl rollout pause deployment/nginx-deployment, resume
Rollback to previous version	kubectl rollout undo deployment/nginx-deployment

------------------------------------------------------------------------------------
1.8 QUOTA & LIMITS & RESOURCE
------------------------------------------------------------------------------------
Customize resource definition	kubectl set resources deployment nginx -c=nginx --limits=cpu=200m,memory=512Mi
List Resource Quota				kubectl get resourcequota
List Limit Range				kubectl get limitrange
Customize resource definition	kubectl set resources deployment nginx -c=nginx --limits=cpu=200m,memory=512Mi

------------------------------------------------------------------------------------
1.9 SERVICE
------------------------------------------------------------------------------------
List all services				kubectl get services
List service endpoints			kubectl get endpoints
Get service detail				kubectl get service nginx-service -o yaml
Get service cluster ip			kubectl get service nginx-service -o go-template='{{.spec.clusterIP}}’
Get service cluster port		kubectl get service nginx-service -o go-template='{{(index .spec.ports 0).port}}’
Expose deployment as lb service	kubectl expose deployment/my-app --type=LoadBalancer --name=my-service
Expose service as lb service	kubectl expose service/wordpress-1-svc --type=LoadBalancer --name=wordpress-lb

------------------------------------------------------------------------------------
1.10 SECRETS
------------------------------------------------------------------------------------
List secrets					kubectl get secrets --all-namespaces
Create secret from cfg file		kubectl create secret generic db-user-pass --from-file./username.txt=
Generate secret	echo -n 'mypasswd', then redirect to base64 -decode

------------------------------------------------------------------------------------
1.11 STATEFULSET
------------------------------------------------------------------------------------
List statefulset					kubectl get sts
Delete statefulset only (not pods)	kubectl delete sts/<stateful_set_name> --cascade=false
Scale statefulset					kubectl scale sts/<stateful_set_name> --replicas=5

------------------------------------------------------------------------------------
1.12 VOLUMES & VOLUME CLAIMS
------------------------------------------------------------------------------------
List storage class				kubectl get storageclass
Check the mounted volumes		kubectl exec storage ls /data
Check persist volume			kubectl describe pv/pv0001
Copy local file to pod			kubectl cp /tmp/my <some-namespace>/<some-pod>:/tmp/server
Copy pod file to local			kubectl cp <some-namespace>/<some-pod>:/tmp/server /tmp/my

------------------------------------------------------------------------------------
1.13 EVENTS & METRICS
------------------------------------------------------------------------------------
View all events						kubectl get events --all-namespaces
List Events sorted by timestamp		kubectl get events –sort-by=.metadata.creationTimestamp

------------------------------------------------------------------------------------
1.14 NODE MAINTENANCE
------------------------------------------------------------------------------------
Mark node as unschedulable					kubectl cordon $NDOE_NAME
Mark node as schedulable					kubectl uncordon $NDOE_NAME
Drain node in preparation for maintenance	kubectl drain $NODE_NAME

------------------------------------------------------------------------------------
1.15 NAMESPACE & SECURITY
------------------------------------------------------------------------------------
List authenticated contexts			kubectl config get-contexts, ~/.kube/config
Load context from config file		kubectl get cs --kubeconfig kube_config.yml
Switch context						kubectl config use-context <cluster-name>
Delete the specified context		kubectl config delete-context <cluster-name>
List all namespaces defined			kubectl get namespaces
Set namespace preference			kubectl config set-context $(kubectl config current-context) --namespace=<ns1>
List certificates					kubectl get csr

------------------------------------------------------------------------------------
1.16 NETWORK
------------------------------------------------------------------------------------
Name	Command
Temporarily add a port-forwarding	kubectl port-forward redis-izl09 6379
Add port-forwaring for deployment	kubectl port-forward deployment/redis-master 6379:6379
Add port-forwaring for replicaset	kubectl port-forward rs/redis-master 6379:6379
Add port-forwaring for service		kubectl port-forward svc/redis-master 6379:6379
Get network policy					kubectl get NetworkPolicy

------------------------------------------------------------------------------------
1.17 PATCH
------------------------------------------------------------------------------------
Patch service to loadbalancer	kubectl patch svc "$APP_INSTANCE_NAME-grafana" -p '{"spec": {"type": "LoadBalancer"}}'

------------------------------------------------------------------------------------
1.18 EXTENSTIONS
------------------------------------------------------------------------------------
List api group					kubectl api-versions
List all CRD					kubectl get crd
List storageclass				kubectl get storageclass
List all supported resources	kubectl api-resources

------------------------------------------------------------------------------------
1.19 COMPONENTS & SERVICES
------------------------------------------------------------------------------------
1.19.1 SERVICES ON MASTER NODES
------------------------------------------------------------------------------------
Name	Summary
kube-apiserver	exposes the Kubernetes API from master nodes
etcd	reliable data store for all k8s cluster data
kube-scheduler	schedule pods to run on selected nodes
kube-controller-manager	node controller, replication controller, endpoints controller, 
	and service account & token controllers

------------------------------------------------------------------------------------
1.19.2 SERVICES ON WORKER NODES
------------------------------------------------------------------------------------
kubelet	makes sure that containers are running in a pod
kube-proxy	perform connection forwarding
Container Runtime	Kubernetes supported runtimes: Docker, rkt, runc and any OCI 
													runtime-spec implementation.
------------------------------------------------------------------------------------
1.19.3 ADDONS: PODS AND SERVICES THAT IMPLEMENT CLUSTER FEATURES
------------------------------------------------------------------------------------
DNS	serves DNS records for Kubernetes services
Web UI	a general purpose, web-based UI for Kubernetes clusters
Container Resource Monitoring	collect, store and serve container metrics
Cluster-level Logging	save container logs to a central log store with search/browsing interface
------------------------------------------------------------------------------------

							
------------------------------------------------------------------------------------
------------------------------------------------------------------------------------
------------------------------------------------------------------------------------							
							
							

$ kubectl --kubeconfig ~/.kube/config --context platform-dev get nodes

$ kubectl --kubeconfig ~/.kube/config --context platform-stg get nodes

$ kubectl --kubeconfig ~/.kube/config --context platform-prod get nodes
							
							
							
							
$ kubectl --kubeconfig ~/.kube/config --context platform-prod get nodes
NAME                             STATUS   ROLES    AGE   VERSION
ip-172-16-107-120.ec2.internal   Ready    <none>   63d   v1.11.5
ip-172-16-69-95.ec2.internal     Ready    <none>   63d   v1.11.5
ip-172-16-77-231.ec2.internal    Ready    <none>   63d   v1.11.5
ip-172-16-82-18.ec2.internal     Ready    <none>   63d   v1.11.5
ip-172-16-83-138.ec2.internal    Ready    <none>   63d   v1.11.5


Retiring: This instance is scheduled for retirement after May 27, 2019 at 12:00:00 PM UTC-7.							
platform-prod-worker-Node i-0c0aed94d2a0f284b m5.xlarge us-east-1b						
							
							
							
							
can you upgrade kube-proxy, coredns, and CNI in platform-prod? It’s running older version. 

$ kubectl --kubeconfig ~/.kube/config --context platform-prod describe ds kube-proxy -n kube-system | grep Image
  
  Image:      602401143452.dkr.ecr.us-east-1.amazonaws.com/eks/kube-proxy:v1.11.5
   
$ kubectl --kubeconfig ~/.kube/config --context platform-prod describe deployment coredns --namespace kube-system | grep Image | cut -d '/' -f 3

coredns:v1.1.3

$ kubectl --kubeconfig ~/.kube/config --context platform-prod describe daemonset aws-node --namespace kube-system | grep Image | cut -d '/' -f 2

amazon-k8s-cni:1.2.1							
							
# kubectl config get,set,use	
Available Commands:
  current-context Displays the current-context
  delete-cluster  Delete the specified cluster from the kubeconfig
  delete-context  Delete the specified context from the kubeconfig
  get-clusters    Display clusters defined in the kubeconfig
  get-contexts    Describe one or many contexts
  rename-context  Renames a context from the kubeconfig file.
  set             Sets an individual value in a kubeconfig file
  set-cluster     Sets a cluster entry in kubeconfig
  set-context     Sets a context entry in kubeconfig
  set-credentials Sets a user entry in kubeconfig
  unset           Unsets an individual value in a kubeconfig file
  use-context     Sets the current-context in a kubeconfig file
  view            Display merged kubeconfig settings or a specified kubeconfig file

Usage:
  kubectl config SUBCOMMAND [options]
##########################################################################################						


Check config env							
kubectl config current-context
				

$ kubectl config get-contexts
CURRENT   NAME            CLUSTER         AUTHINFO        NAMESPACE
          platform-dev    platform-dev    platform-dev
*         platform-prod   platform-prod   platform-prod
          platform-stg    platform-stg    platform-stg

$ kubectl config set-context platform-dev
Context "platform-dev" modified.  <= modified to ~/.kube/config file

....
current-context: platform-dev   <= dev, stg, pro로 바뀜
....

$ kubectl config use-context platform-dev
Switched to context "platform-dev".


$ kubectl get nodes		<dev environment로 보여줌>
NAME                            STATUS   ROLES    AGE   VERSION
ip-172-18-101-32.ec2.internal   Ready    <none>   22d   v1.12.7
ip-172-18-66-183.ec2.internal   Ready    <none>   19d   v1.12.7
ip-172-18-86-246.ec2.internal   Ready    <none>   19d   v1.12.7


$ kubectl config set-context platform-apark
Context "platform-apark" modified.  <= modified to ~/.kube/config file



Check list
$ kubectl get nodes
NAME                             STATUS   ROLES    AGE    VERSION
ip-172-16-103-73.ec2.internal    Ready    <none>   19h    v1.12.7
ip-172-16-107-120.ec2.internal   Ready    <none>   153d   v1.11.5
ip-172-16-65-172.ec2.internal    Ready    <none>   19h    v1.12.7
ip-172-16-69-24.ec2.internal     Ready    <none>   19h    v1.12.7
ip-172-16-69-95.ec2.internal     Ready    <none>   153d   v1.11.5
ip-172-16-77-231.ec2.internal    Ready    <none>   153d   v1.11.5
ip-172-16-81-85.ec2.internal     Ready    <none>   89d    v1.11.5
ip-172-16-82-71.ec2.internal     Ready    <none>   19h    v1.12.7
ip-172-16-83-138.ec2.internal    Ready    <none>   153d   v1.11.5
ip-172-16-83-223.ec2.internal    Ready    <none>   19h    v1.12.7


$ kubectl config use-context platform-dev
Switched to context "platform-dev".

$ kubectl get nodes
Error from server (Forbidden): nodes is forbidden: User "arn:aws:iam::162780728042:user/apark" cannot list resource "nodes" in API group "" at the cluster scope
				
							
							
$ kubectl taint nodes ip-172-16-81-85.ec2.internal key=value:NoSchedule
node/ip-172-16-81-85.ec2.internal tainted
						
							
$ kubectl describe node ip-172-16-81-85.ec2.internal | egrep -i "taint|sched"
Taints:             key=value:NoSchedule
Unschedulable:      false

$ kubectl get nodes
$ kubectl get pods
$ kubectl get pods -o wide | grep ip-172-16-81-85.ec2.internal
							
$ kubectl delete node ip-172-16-83-138.ec2.internal   <= remove this instance from Kube Cluster			

$ kubectl get nodes
NAME                            STATUS                     ROLES    AGE    VERSION
ip-172-16-103-73.ec2.internal   Ready                      <none>   25h    v1.12.7
ip-172-16-65-172.ec2.internal   Ready                      <none>   25h    v1.12.7
ip-172-16-69-24.ec2.internal    Ready                      <none>   25h    v1.12.7
ip-172-16-82-71.ec2.internal    Ready                      <none>   25h    v1.12.7
ip-172-16-83-138.ec2.internal   Ready,SchedulingDisabled   <none>   154d   v1.11.5		<==

$ kubectl describe nodes ip-172-16-83-138.ec2.internal | egrep -i "taint|sched"
Taints:             key=value:NoSchedule
                    node.kubernetes.io/unschedulable:NoSchedule
Unschedulable:      true <<<<<<
  Normal  NodeNotSchedulable  2m9s  kubelet, ip-172-16-83-138.ec2.internal  Node ip-172-16-83-138.ec2.internal status is now: NodeNotSchedulable


------------------------------------------------------------------------------------------
# How To Install Software on Kubernetes Clusters with the Helm Package Manager
	https://www.digitalocean.com/community/tutorials/how-to-install-software-on-kubernetes-clusters-with-the-helm-package-manager
------------------------------------------------------------------------------------------

Helm 	<= is a package manager for Kubernetes that allows developers and operators to 
			more easily configure and deploy applications on Kubernetes clusters.					

Tiller 	<= is a companion to the helm command that runs on your cluster, receiving 
			commands from helm and communicating directly with the Kubernetes API to do the 
			actual work of creating and deleting resources.






------------------------------------------------------------------------------------------

Role-based Access Control
https://helm.sh/docs/using_helm/#role-based-access-control
https://docs.oracle.com/cd/E26925_01/html/E25888/rbac-1.html
------------------------------------------------------------------------------------------

Kubernetes Dashboard 

$ kubectl -n kube-system create serviceaccount t
serviceaccount/tiller created

#bind the tiller serviceaccount to the cluster-admin role:
$ kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller
clusterrolebinding.rbac.authorization.k8s.io/tiller created


$ helm init --service-account tiller

	Creating /home/netops/.helm
	Creating /home/netops/.helm/repository
	Creating /home/netops/.helm/repository/cache
	Creating /home/netops/.helm/repository/local
	Creating /home/netops/.helm/plugins
	Creating /home/netops/.helm/starters
	Creating /home/netops/.helm/cache/archive
	Creating /home/netops/.helm/repository/repositories.yaml


$ kubectl get pods --namespace kube-system

	NAME                             READY   STATUS    RESTARTS   AGE
	coredns-584795fc57-gjr8r         1/1     Running   3          10d
	coredns-584795fc57-pkzvv         1/1     Running   3          10d
	etcd-mc1                         1/1     Running   2          10d
	kube-apiserver-mc1               1/1     Running   2          10d
	kube-controller-manager-mc1      1/1     Running   2          10d
	kube-flannel-ds-amd64-btfsh      1/1     Running   0          10d
	kube-flannel-ds-amd64-pgwgs      1/1     Running   1          10d
	kube-flannel-ds-amd64-v752t      1/1     Running   0          10d
	kube-proxy-895v5                 1/1     Running   0          10d
	kube-proxy-9jd7q                 1/1     Running   0          10d
	kube-proxy-glzpf                 1/1     Running   1          10d
	kube-scheduler-mc1               1/1     Running   7          10d
	tiller-deploy-7f4d76c4b6-8bpx7   1/1     Running   0          16m  <==

Step 3 — Installing a Helm Chart
$ helm install stable/kubernetes-dashboard --name dashboard-demo	<= 
	
	NAME:   dashboard-demo
	LAST DEPLOYED: Wed Sep 11 18:23:23 2019
	NAMESPACE: default
	STATUS: DEPLOYED

	RESOURCES:
	==> v1/Deployment
	NAME                                 READY  UP-TO-DATE  AVAILABLE  AGE
	dashboard-demo-kubernetes-dashboard  0/1    1           0          0s

	------

	NOTES:
	*********************************************************************************
	*** PLEASE BE PATIENT: kubernetes-dashboard may take a few minutes to install ***
	*********************************************************************************

	Get the Kubernetes Dashboard URL by running:
	  export POD_NAME=$(kubectl get pods -n default -l "app=kubernetes-dashboard,release=dashboard-demo" -o jsonpath="{.items[0].metadata.name}")
	  echo https://127.0.0.1:8443/
	  kubectl -n default port-forward $POD_NAME 8443:8443	

$ helm list
	NAME            REVISION        UPDATED                         STATUS          CHART                           APP VERSION     NAMESPACE
	dashboard-demo  1               Wed Sep 11 18:23:23 2019        DEPLOYED        kubernetes-dashboard-1.8.0      1.10.1          default

$  kubectl get services
	NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
	dashboard-demo-kubernetes-dashboard   ClusterIP   10.111.109.142   <none>        443/TCP   3m7s
	kubernetes                            ClusterIP   10.96.0.1        <none>        443/TCP   10d


$ helm upgrade dashboard-demo stable/kubernetes-dashboard --set fullnameOverride="dashboard"


$  kubectl get services
	NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
	dashboard    ClusterIP   10.111.108.205   <none>        443/TCP   15s
	kubernetes   ClusterIP   10.96.0.1        <none>        443/TCP   10d

$ kubectl proxy



$ kubectl cluster-info

	Kubernetes master is running at https://134.209.6.242:6443
	
	KubeDNS is running at https://134.209.6.242:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

----------------------------------------------------------------------------------------
https://134.209.6.242:6443
----------------------------------------------------------------------------------------
	{
	  "kind": "Status",
	  "apiVersion": "v1",
	  "metadata": {
		
	  },
	  "status": "Failure",
	  "message": "forbidden: User \"system:anonymous\" cannot get path \"/\"",
	  "reason": "Forbidden",
	  "details": {
		
	  },
	  "code": 403
	}
----------------------------------------------------------------------------------------


----------------------------------------------------------------------------------------
https://134.209.6.242:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
----------------------------------------------------------------------------------------
	{
	  "kind": "Status",
	  "apiVersion": "v1",
	  "metadata": {
		
	  },
	  "status": "Failure",
	  "message": "services \"kube-dns:dns\" is forbidden: User \"system:anonymous\" cannot get resource \"services/proxy\" in API group \"\" in the namespace \"kube-system\"",
	  "reason": "Forbidden",
	  "details": {
		"name": "kube-dns:dns",
		"kind": "services"
	  },
	  "code": 403
	}
----------------------------------------------------------------------------------------

# Roll Back(REVERT)

  $ helm list
	NAME            REVISION        UPDATED                         STATUS          CHART                           APP VERSION NAMESPACE
	dashboard-demo  2               Wed Sep 11 18:27:13 2019        DEPLOYED        kubernetes-dashboard-1.8.0      1.10.1      default
	
  $ helm rollback dashboard-demo 1

  $ helm delete dashboard-demo

  $ helm list --deleted	

  $ helm delete dashboard-demo --purge
	release "dashboard-demo" deleted











----------------------------------------------------------------------------------------
# Monitoring
----------------------------------------------------------------------------------------
https://github.com/do-community/doks-monitoring

Monitoring Stack on DigitalOcean Kubernetes
	Prometheus 
	Grafana  
	Alertmanager 
	
	
Step 2 — Creating the Monitoring Stack
	The DigitalOcean Kubernetes Monitoring Quickstart repo contains manifests for the 
	following monitoring, scraping, and visualization components:

  Prometheus <= is a time series database and monitoring tool that works by polling metrics 
			endpoints and scraping and processing the data exposed by these endpoints. 
			It allows you to query this data using PromQL, a time series data query 
			language. Prometheus will be deployed into the cluster as a StatefulSet 
			with 2 replicas that uses Persistent Volumes with DigitalOcean Block Storage. 
			In addition, a preconfigured set of Prometheus Alerts, Rules, and Jobs will 
			be stored as a ConfigMap. To learn more about these, skip ahead to the 
			Prometheus section of Configuring the Monitoring Stack.
  Alertmanager	<= usually deployed alongside Prometheus, forms the alerting layer of the stack, 
			handling alerts generated by Prometheus and deduplicating, grouping, and routing 
			them to integrations like email or PagerDuty. Alertmanager will be installed as 
			a StatefulSet with 2 replicas. To learn more about Alertmanager, consult Alerting 
			from the Prometheus docs.
  
  Grafana 	<= is a data visualization and analytics tool that allows you to build dashboards and 
			graphs for your metrics data. Grafana will be installed as a StatefulSet with one 
			replica. In addition, a preconfigured set of Dashboards generated by kubernetes-mixin 
			will be stored as a ConfigMap.

  kube-state-metrics <= is an add-on agent that listens to the Kubernetes API server and generates 
			metrics about the state of Kubernetes objects like Deployments and Pods. These metrics 
			are served as plaintext on HTTP endpoints and consumed by Prometheus. kube-state-metrics 
			will be installed as an auto-scalable Deployment with one replica.
  
  node-exporter	<= a Prometheus exporter that runs on cluster nodes and provides OS and hardware 
			metrics like CPU and memory usage to Prometheus. These metrics are also served as 
			plaintext on HTTP endpoints and consumed by Prometheus. node-exporter will be 
			installed as a DaemonSet.	












	$ su - netops
	$ mkdir doks-monitoring&& cd doks-monitoring
	$ git clone https://github.com:do-community/doks-monitoring.git

	$ export APP_INSTANCE_NAME=cluster-monitoring
	$ export NAMESPACE=monitoring
	$ export GRAFANA_GENERATED_PASSWORD="$(echo -n 'Test00!!' | base64)"

	$ kubectl create namespace "$NAMESPACE"

Step 2 — Creating the Monitoring Stack
	$ cd doks-monitoring

	netops@mc1~/doks-monitoring$ awk 'FNR==1 {print "---"}{print}' manifest/* \
	 | envsubst '$APP_INSTANCE_NAME $NAMESPACE $GRAFANA_GENERATED_PASSWORD' \
	 > "${APP_INSTANCE_NAME}_manifest.yaml"

	$ ls -l
	-rw-r--r-- 1 netops netops 225622 Sep 11 23:32 cluster-monitoring_manifest.yaml
	
	$ kubectl apply -f "${APP_INSTANCE_NAME}_manifest.yaml" --namespace "${NAMESPACE}"
		---------------------------------------------------------
		serviceaccount/alertmanager created
		configmap/cluster-monitoring-alertmanager-config created
		...
		service/cluster-monitoring-prometheus created
		statefulset.apps/cluster-monitoring-prometheus created
		---------------------------------------------------------
		
	$ kubectl get all

	$ kubectl get namespaces ( <= $ kubectl get ns )
	
	$ kubectl get pods --all-namespaces
	
		NAMESPACE     NAME                                                    READY   STATUS    RESTARTS   AGE
	kube-system   coredns-584795fc57-gjr8r                                1/1     Running   3          11d
	...
	monitoring    cluster-monitoring-alertmanager-0                       0/1     Pending   0          103s
	monitoring    cluster-monitoring-grafana-0                            0/1     Pending   0          102s
	monitoring    cluster-monitoring-kube-state-metrics-f9c6c6f7b-lmcpw   2/2     Running   0          102s
	monitoring    cluster-monitoring-node-exporter-4pp72                  1/1     Running   0          101s
	monitoring    cluster-monitoring-node-exporter-m6lpx                  1/1     Running   0          101s
	monitoring    cluster-monitoring-prometheus-0                         0/1     Pending   0          102s
	monitoring    cluster-monitoring-prometheus-1                         0/1     Pending   0          102s

	
Step 3 — Accessing Grafana and Exploring Metrics Data
kubectl port-forward --namespace ${NAMESPACE} ${APP_INSTANCE_NAME}-grafana-0 3000




----------------------------------------------------------------------------------------
# Terminology
----------------------------------------------------------------------------------------
kube-apiserver
		The Kubernetes API server validates and configures data for the api objects which 
		include pods, services, replication controllers, and others. The API Server services 
		REST operations and provides the frontend to the cluster’s shared state through 
		which all other components interact.
		
	$ kube-apiserver [flags]

kubelet 
		the primary node agent that interacts with kube-apiserver to manage Pods and containers 
		on a node.

cAdvisor
		a node agent that discovers running containers and collects their CPU, memory, 
		filesystem, and network usage metrics.
		https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/#cadvisor




----------------------------------------------------------------------------------------
# Troubleshooting
----------------------------------------------------------------------------------------
STATUS: CrashLoopBackOff
https://sysdig.com/blog/debug-kubernetes-crashloopbackoff/

$ kubectl get pods
	NAME                        READY   STATUS             RESTARTS   AGE
	dashboard-95589d86d-jpjzd   0/1     CrashLoopBackOff   30         133m


$ kubectl get all

$ kubectl describe pod


# Check your Kubernetes deployments
https://medium.com/polarsquad/check-your-kubernetes-deployments-46dbfbc47a7c





# Deleting  Pods
https://stackoverflow.com/questions/33509194/command-to-delete-all-pods-in-all-kubernetes-namespaces
$ kubectl delete --all pods --namespace=monitoring
$ kubectl get ns( <= $ kubectl get namespaces)
$ kubectl delete --all monitoring
$ kubectl get -n monitoring all

	----------------------------------------------------------------------------------------
	for each in $(kubectl get ns -o jsonpath="{.items[*].metadata.name}" | grep -v kube-system);
	do
	  kubectl delete ns $each
	done
	----------------------------------------------------------------------------------------



# Debugging Pods
https://kubernetes.io/docs/tasks/debug-application-cluster/debug-pod-replication-controller/

# Get Nodes' CPU and Memory Info
$ kubectl get nodes -o yaml | egrep '\sname:|cpu:|memory:'
    name: mc1
      cpu: "2"
      memory: 3778092Ki
	...
	
$ kubectl get pods --all-namespaces | grep -i pending
	monitoring    cluster-monitoring-alertmanager-0                       0/1     Pending   0          10m
	monitoring    cluster-monitoring-grafana-0                            0/1     Pending   0          10m
	monitoring    cluster-monitoring-prometheus-0                         0/1     Pending   0          10m
	monitoring    cluster-monitoring-prometheus-1                         0/1     Pending   0          10m
	











----------------------------------------------------------------------------------------
kubectl
	kubectl controls the Kubernetes cluster manager.
	https://kubernetes.io/docs/reference/kubectl/overview/
----------------------------------------------------------------------------------------
$ kubectl <TAB>
annotate       certificate    create         explain        patch          scale
api-resources  cluster-info   delete         expose         plugin         set
api-versions   completion     describe       get            port-forward   taint
apply          config         diff           kustomize      proxy          top
attach         convert        drain          label          replace        uncordon
auth           cordon         edit           logs           rollout        version
autoscale      cp             exec           options        run            wait


# Basic Commands :
  create         Create a resource from a file or from stdin
  delete         Delete resources by filenames, stdin, resources and names, or by resources 
  get            Display one or many resources
  
  expose         Take a replication controller, service, deployment or pod and expose it as a new
  explain        Documentation of resources
  edit           Edit a resource on the server

  
# Kubernetes Service
  run            Run a particular image on the cluster
  set            Set specific features on objects


### label selector

# Deploy Commands:
  rollout        Manage the rollout of a resource
  scale          Set a new size for a Deployment, ReplicaSet, Replication Controller, or Job
  autoscale      Auto-scale a Deployment, ReplicaSet, or ReplicationController

# Cluster Management Commands:
  certificate    Modify certificate resources.
  cluster-info   Display cluster info
  top            Display Resource (CPU/Memory/Storage) usage.
  cordon         Mark node as unschedulable
  uncordon       Mark node as schedulable
  drain          Drain node in preparation for maintenance
  taint          Update the taints on one or more nodes

# Troubleshooting and Debugging Commands:
  describe       Show details of a specific resource or group of resources
  logs           Print the logs for a container in a pod
  attach         Attach to a running container
  exec           Execute a command in a container
  port-forward   Forward one or more local ports to a pod
  proxy          Run a proxy to the Kubernetes API server
  cp             Copy files and directories to and from containers.
  auth           Inspect authorization

# Advanced Commands:
  diff           Diff live version against would-be applied version
  apply          Apply a configuration to a resource by filename or stdin
  patch          Update field(s) of a resource using strategic merge patch
  replace        Replace a resource by filename or stdin
  wait           Experimental: Wait for a specific condition on one or many resources.
  convert        Convert config files between different API versions
  kustomize      Build a kustomization target from a directory or a remote url.

# Settings Commands:
  label          Update the labels on a resource
  annotate       Update the annotations on a resource
  completion     Output shell completion code for the specified shell (bash or zsh)

# Other Commands:
  api-resources  Print the supported API resources on the server
  api-versions   Print the supported API versions on the server, in the form of "group/version"
  config         Modify kubeconfig files
  plugin         Provides utilities for interacting with plugins.
  version        Print the client and server version information

Usage:
  kubectl [flags] [options]

# Managing Compute Resources for Containers
https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
The expression 0.1 is equivalent to the expression 100m






# Interactive Tutorial - Exploring Your App
https://kubernetes.io/docs/tutorials/kubernetes-basics/explore/explore-interactive/



kubectl cluster-info
kubectl config get-contexts
kubectl get pods --namespace kube-system





-------------------------------------------------------------------------------------------
Architecture of a Kubernetes cluster
https://www.linkedin.com/learning/learning-kubernetes/architecture-of-a-kubernetes-cluster?u=2102452
-------------------------------------------------------------------------------------------
1. Containerization with Kubernetes
-------------------------------------------------------------------------------------------
	Container <- A collection of SW processes unified by one namespace,
				with access to an operating system kernel that it shares with other 
				containers and little to no access between containers.
-------------------------------------------------------------------------------------------
	Docker Instance <- A rundtime instance of a DOcker image contains 3 things:
		1. A Docker images
		2. An execution environment
		3. A standard set of instructions
	
	Docker Engine
		- Comprised of the runtime and packaging tool
		- Must be install on the hosts that run Docker
	
	Docker Store( Docker Hub)
		- Host Docker Images
-------------------------------------------------------------------------------------------
Kubernetes Orchestrator Features( Infrastructure as an 1 PC, just like DC/OS(Infra structure as single server) 
	- Provision Hosts
	- Instantiate containers on a host
	- Restart/Recover failing containers
	- Expose containers as services outsice the cluster
	- Scale the cluster up or down
	
Kubernetes(k8s)
		An open-source platform designed to automate deploying, scaling, and operating app containers.
		
-------------------------------------------------------------------------------------------
2. Kubernetes: The Terminology
-------------------------------------------------------------------------------------------
	1. Master Node
		1.API Server
		2.Scheduler
		3.Controller Manager
	
	2. Muti-Host Container Scheduling
		- Done by the Kube-scheduler
		- Assigns pods(Docker containers) to nodes(VMs) at runtime
		- Checks resources, quality of service, policies, and user specifications before scheduling
	3. Scalability and Availability
		- k8s maste can be deployed in a highly available configuration
		- Multi-Region deployments available
	  Scalablity( v1.8) <- 5k nodes clusters with 150k pods
						 - pods can be horizontally scaled vis API	
	
	4. Flexibility and modularization
		- Plug & Play architecture
		- Add-ons: network drivers, service discovery, container runtime, visualization, and command
	
	5. Resistration
		- Seamless nodes(VMs) register themselves with master
		
	6. Service Discovery
		- Automatic detection of services and endpoints vis DNS or environment variables
		
	7. Persistent Storage
		- Much requested and important feature when working with containers
		- Pods can use persistent volumes to store data
		- Data retained across pod(container) restarts and crashes
	
	8. Application Upgrades and Downgrades
		- Upgrades: rolling updates supported
		- Downgrades: rollbacks are supported
	
	9. Maintenance	
		- Features are backward-compatible
		- APIs are versioned
		- Turn off/on host during maintenance(unschedule)
		
	10. Logging and Monitoring
		- Application monitoring built-in
			- TCP, http, container exec health check
		- Node health check	<- monitored by node controller
		- Kubernetes status	<- Add-ons: cAdvisor(simple)  -> Heapster -> Prometheus(best)
	
	11. Secrets Management
		- Sensitive data is first-class citizen
		- Mounted as data volumes or env variables
		- Specific to namespace
	
	
-------------------------------------------------------------------------------------------
3. Kubernetes Architecutre	
		
						|-> etcd(DB)
	Kubectl		--> << Master Nodes >>	 <--->   << Worker Nodes >>
  ----------        -----------------           -------------------------------------
  <kubeconfig>      [API Server]		  		[kubelet]				[Kube-proxy] <<== Internet
					 ^	      ^			  		|->	      [[ Docker ]]      <-|			   User
				[Scheduler] [Controller]		Pod			Pod			Pod	
						      Manager			Containers	Containers	Containers

-------------------------------------------------------------------------------------------
4. Basic Building Block
	Nodes(Virtual Machines) and Pods(Dockers Containers)
	
	Kubernetes Cluster
		Node-0 [Master]
		Node-1 [kubelet + Docker ]
		Node-2 [kubelet + Docker ]
		Node-3 [kubelet + Docker ] <- Node Processes
		
	Node requirements:
		1. A kubelet running
		2. Container tooling like Docker
		3. A kube-proxy process running
		4. Supervisord	<- service management
	
	Pod - A Docker Container or more
		States
			- Pending
			- Running
			- Succeeded
			- Failed
			- CrashLoopBackOff	<- restarting pod
			
			
-------------------------------------------------------------------------------------------
10. Deployments, jobs, and services
-------------------------------------------------------------------------------------------
	Benefits of Controllers
		- Application reliability
		- Scaling
		- Load Balancing
	
	Controllers
		- ReplicaSets	<- Number of pods to maintain e.g. 2, 3,..
		- Deployments	<- 
		- DaemonSets	<- 
		- Jobs			<- patch jobs
		- Services		<- Network communication
			
			Frontend ==> Backend  => Backend Pod-1
			   Pod       Service  => Backend Pod-2
								  => Backend Pod-3
			
			Internal: IP is only reachable within the Cluster
			External: endpoint
			
								
-------------------------------------------------------------------------------------------
11 Labels, selectors, and namespaces
-------------------------------------------------------------------------------------------
	Labels -key/value pair
		e.g. "release" : "dev", "release" : "stg", "release" : "live"
	
	Equality-based Selectors
		= 	 <- equal
		!=	 <- Not equal
	Set-based Selectors
		IN:		a value should be inside a set of defined values
		NOTIN:	a value should not be in a set of defined values
		EXISTS: Determines whether a label exists or not
	
	namespaces(
		Great for large group
		Allow teams to access resources, with accountability
		Profices scope for name 
		"Default"
-------------------------------------------------------------------------------------------
12 Kubelet and kube proxy
-------------------------------------------------------------------------------------------
	Kubelet <- "Kubernetes node agent that rns on each node(VMs)
			- Communicates with API server to see if pods have been assigned to nodes
			- Exec pod containers via a contrainer engine
			- Mounts and runs pod volumes and secrets
			- Exec health checks to identify pod/node status
	
	Podspec	<- YAML file that describes a pod
			- The kubelet takes a set of Podspecs that are provided by the kube-apiserver
			  and ensures that the containers described in those Podspecs are running and healthy
			- Kubelet only manages containers that were created by the API server -  not any 
			  container running on the node.
			  
	kube proxy	<- The Network Proxy
			- Process that runs on all worker nodes
			- Reflects services as defined on each node, and can do simpe network stream
			  or round-robin forwarding across a set of backends
			- Service cluster IPs and ports are currently found through Docker --link compatible
			  environment variables specifiying ports opened by the service proxy
			1. User space mode	<- most common mode
			2. Iptables mode
			3. Ipvs mode(alpha feature)
	
	Why these modes are important
	1. Services defined against the API server: kube-proxy watches the API server for
		the addition and removal of services
	2. For each new service, kube-proxy opens a randomly chosen port on the local node
	3. Connections made to the chosen port are proxied to one of the corresponding 
		back-end pods
-------------------------------------------------------------------------------------------

-------------------------------------------------------------------------------------------
15 Running a first 'Hello World' application
-------------------------------------------------------------------------------------------
$ kubectl get nodes			<= check number of worker virtual machines
	NAME   STATUS   ROLES    AGE   VERSION
	mc1    Ready    master   22d   v1.14.0
	wc1    Ready    <none>   22d   v1.14.0
	wc2    Ready    <none>   22d   v1.14.0

$ kubectl run hw --image=karthequian/helloworld --port=80	
	kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in 
	a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.
	deployment.apps/hw created

$ kubectl get pods
	NAME                                 READY   STATUS             RESTARTS   AGE
	hw-5f6c6f9545-dssvc                  1/1     Running            0          18s

# Expose as a service
$ kubectl expose deployment  hw --type=NodePort
	service/hw exposed

# Check	
$ kubectl get services
	NAME                TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
	hw                  NodePort       10.106.26.222    <none>        80:31103/TCP   24s


-------------------------------------------------------------------------------------------
16 Breaking down the Hello World application
------------------------------------------------------------------------------------------
$ kubectl get all		<- shows pods, services and deployments that are running that build the helloworld 
							application.

$ kubectl get all					<= to see what actually deployed
	NAME                            TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
	service/hw                      NodePort       10.106.26.222    <none>        80:31103/TCP        6h1m
	
$ kubectl get deploy/hw
	NAME   READY   UP-TO-DATE   AVAILABLE   AGE
	hw     1/1     1            1           6h5m


$ kubectl get deploy -o yaml		<= -o, --output='': Output format.
$ kubectl get deploy/hw -o yaml		<= This will return the YAML that composes the helloworld service
	apiVersion: extensions/v1beta1
	kind: Deployment
	metadata:
	  annotations:
		deployment.kubernetes.io/revision: "1"
	  creationTimestamp: "2019-09-23T23:51:54Z"
	  generation: 1
	  labels:
		run: hw
	  name: hw
	  namespace: default
	  resourceVersion: "2701032"
	  selfLink: /apis/extensions/v1beta1/namespaces/default/deployments/hw
	  uid: 1f2186a9-de5d-11e9-9941-62f9df03c49e

$ kubectl get services
	NAME                    TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)             AGE
	hw                      NodePort       10.106.26.222    <none>           80:31103/TCP        6h5m



$ vi helloworld-deploy-service.yml  <= use 1(single) file to create for all ONCE(deployment + service)
-------------------------------------------------------------------------------------------
apiVersion: apps/v1beta1
kind: Deployment					### <= Deployment	
metadata:
  name: helloworld-all-deployment	### <= Deployment name
spec:
  selector:
    matchLabels:
      app: helloworld
  replicas: 1 # tells deployment to run 1 pods matching the template
  template: # create pods using pod definition in this template
    metadata:
      labels:
        app: helloworld
    spec:
      containers:
      - name: helloworld
        image: karthequian/helloworld:latest
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service					### <= Service
metadata:
  name: helloworld-all-service
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  type: LoadBalancer
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: helloworld
-------------------------------------------------------------------------------------------
$ kubectl create -f helloworld-deploy-service.yml
$ kubectl get services
	NAME                     TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
	helloworld-all-service   LoadBalancer   10.99.226.255    <pending>     80:30716/TCP        64s
	hw                       NodePort       10.106.26.222    <none>        80:31103/TCP        6h20m

$ kubectl get deployment
	NAME                        READY   UP-TO-DATE   AVAILABLE   AGE
	helloworld-all-deployment   1/1     1            1           85s
	hw                          1/1     1            1           6h23m


-------------------------------------------------------------------------------------------
17 Scaling the Hello World application
-------------------------------------------------------------------------------------------
	$ kubectl get replicaset
	$ kubectl get rs
		NAME                                   DESIRED   CURRENT   READY   AGE
		helloworld-all-deployment-8597f99986   1         1         1       5m56s	<= 1
		hw-5f6c6f9545                          1         1         1       6h28m

	$ kubectl scale --replicas=3 deployment/helloworld-all-deployment
		deployment.extensions/helloworld-all-deployment scaled

	
	$ kubectl get rs	
	$ kubectl get replicaset	
		NAME                                   DESIRED   CURRENT   READY   AGE
		helloworld-all-deployment-8597f99986   3         3         3       9m45s	<= 3
		hw-5f6c6f9545                          1         1         1       6h31m

	$ kubectl get deploy/helloworld-all-deployment
		NAME                        READY   UP-TO-DATE   AVAILABLE   AGE
		helloworld-all-deployment   3/3     3            3           10m

	$ kubectl get pods
		NAME                                         READY   STATUS              RESTARTS   AGE
		helloworld-all-deployment-8597f99986-grtnf   0/1     ContainerCreating   0          3s
		helloworld-all-deployment-8597f99986-klltv   1/1     Running             0          11h
		helloworld-all-deployment-8597f99986-s8kt8   0/1     ContainerCreating   0          3s



-------------------------------------------------------------------------------------------
18 Add, change, and delete labels
-------------------------------------------------------------------------------------------
	1. Adding labels during build time
	2. Viewing labels
	2. Adding labels to running pods
	3. Deleting a label
	4. Searching by labels
	5. Extending the label concept to deployments/services

$ kubectl create -f helloworld-pod-with-labels.yml
---------------------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: helloworld
  labels:
    env: production
    author: karthequian
    application_type: ui
    release-version: "1.0"
spec:
  containers:
  - name: helloworld
    image: karthequian/helloworld:latest
---------------------------------------------------------
$ kubectl get pods
NAME                                         READY   STATUS    RESTARTS   AGE
helloworld                                   1/1     Running   0          4s

$ kubectl get pods --show-labels
helloworld   1/1     Running   0  23m  application_type=ui,author=karthequian,env=production,release-version=1.0

# Relabel
$ kubectl label pod/helloworld app=helloworldapp --overwrite
	
$ kubectl get pods --show-labels		
helloworld   1/1     Running   0  23m  "app=helloworldapp",application_type=ui,author=karthequian,env=production,release-version=1.0
													  
$ kubectl label pod/helloworld app-			<= app- minus
	pod/helloworld labeled
$ kubectl get pods --show-labels
	helloworld     1/1     Running    0   32m     application_type=ui,author=karthequian,env=production,release-version=1.0
												<app=helloworldapp <=deleted >	
												
# Search by label
$ vi sample-infrastructure-with-labels												
---------------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: homepage-dev
  labels:
    env: development
    dev-lead: karthik
    team: web
    application_type: ui
    release-version: "12.0"
spec:
  containers:
  - name: helloworld
    image: karthequian/helloworld:latest
---
apiVersion: v1
kind: Pod
metadata:
  name: homepage-staging
  name: homepage-prod
  name: cart-dev
  name: cart-stg
  name: cart-live
  .... 
  name: ordering-dev
  ...
---
---------------------------------------------------
$ kubectl crate -f sample-infrastructure-with-labels.yml
	----------------------------
	pod/homepage-dev created
	pod/homepage-staging created
	pod/homepage-prod created
	pod/login-dev created
	pod/login-staging created
	pod/login-prod created
	pod/cart-dev created
	pod/cart-staging created
	pod/cart-prod created
	pod/social-dev created
	pod/social-staging created
	pod/social-prod created
	pod/catalog-dev created
	pod/catalog-staging created
	pod/catalog-prod created
	pod/quote-dev created
	pod/quote-staging created
	pod/quote-prod created
	pod/ordering-dev created
	pod/ordering-staging created
	pod/ordering-prod created
	----------------------------

$ kubectl get pods
$ kubectl get pods --show-labels

quote-dev       1/1     Running  9    98m     application_type=api,dev-lead=amy,env=development,release-version=2.0,team=ecommerce
quote-prod      1/1     Running  9    98m     application_type=api,dev-lead=amy,env=production,release-version=1.0,team=ecommerce
quote-staging   1/1     Running  9    98m     application_type=api,dev-lead=amy,env=staging,release-version=2.0,team=ecommerce
social-dev      1/1     Running  9    98m     application_type=api,dev-lead=carisa,env=development,release-version=2.0,team=marketing
social-prod     1/1     Running  9    98m     application_type=api,dev-lead=marketing,env=production,release-version=1.0,team=marketing
social-staging  1/1     Running  9    98m     application_type=api,dev-lead=marketing,env=staging,release-version=1.0,team=marketing

# label search

$ kubectl get pods --selector env=production
	
	NAME            READY   STATUS    RESTARTS   AGE
	cart-prod       1/1     Running   11         115m
	catalog-prod    1/1     Running   11         115m
	helloworld      1/1     Running   0          167m
	homepage-prod   1/1     Running   0          115m
	login-prod      1/1     Running   11         115m
	ordering-prod   1/1     Running   11         115m
	quote-prod      1/1     Running   11         115m
	social-prod     1/1     Running   11         115m
	
	
$ kubectl get pods --selector env=production --show-labels

	NAME            READY   STATUS    RESTARTS   AGE    LABELS
	cart-prod       1/1     Running   11         115m   application_type=api,dev-lead=carisa,env=production,release-version=1.0,team=ecommerce
	catalog-prod    1/1     Running   11         115m   application_type=api,dev-lead=daniel,env=production,release-version=4.0,team=ecommerce
	helloworld      1/1     Running   0          168m   application_type=ui,author=karthequian,env=production,release-version=1.0
	homepage-prod   1/1     Running   0          115m   application_type=ui,dev-lead=karthik,env=production,release-version=12.0,team=web
	login-prod      1/1     Running   11         115m   application_type=api,dev-lead=jim,env=production,release-version=1.0,team=auth
	ordering-prod   1/1     Running   11         115m   application_type=backend,dev-lead=chen,env=production,release-version=2.0,team=purchasing
	quote-prod      1/1     Running   11         115m   application_type=api,dev-lead=amy,env=production,release-version=1.0,team=ecommerce
	social-prod     1/1     Running   11         115m   application_type=api,dev-lead=marketing,env=production,release-version=1.0,team=marketing

$ kubectl get pods --selector env=production --show-labels | grep env


# Only list for dev-lead=carisa	<= user name
$ kubectl get pods --selector dev-lead=carisa  					# <= dev name
	kubectl get pods --selector dev-lead=carisa
	NAME           READY   STATUS    RESTARTS   AGE
	cart-dev       1/1     Running   11         118m
	cart-prod      1/1     Running   11         118m
	cart-staging   1/1     Running   11         118m
	social-dev     1/1     Running   11         118m

# Multiple Labels
$ kubectl get pods --selector dev-lead=karthik,env=staging
	NAME               READY   STATUS    RESTARTS   AGE
	homepage-staging   1/1     Running   0          119m

# != Not Equal to karthik
$ kubectl get pods --selector dev-lead!=karthik,env=staging
	NAME               READY   STATUS    RESTARTS   AGE
	cart-staging       1/1     Running   14         143m
	catalog-staging    1/1     Running   14         143m
	login-staging      1/1     Running   14         143m
	ordering-staging   1/1     Running   14         143m
	quote-staging      1/1     Running   14         143m
	social-staging     1/1     Running   14         143m
	
$ kubectl get pods --selector dev-lead!=karthik,env=staging --show-labels
NAME               READY   STATUS    RESTARTS   AGE    LABELS
cart-staging       1/1     Running   14         144m   application_type=api,dev-lead=carisa,env=staging,release-version=1.0,team=ecommerce
catalog-staging    1/1     Running   14         144m   application_type=api,dev-lead=daniel,env=staging,release-version=4.0,team=ecommerce

# 
$ kubectl get pods -l 'release-version in (1.0,2.0)'

NAME               READY   STATUS    RESTARTS   AGE
cart-dev           1/1     Running   14         145m
...
social-staging     1/1     Running   14         145m


$ kubectl get pods -l 'release-version in (1.0,2.0)' --show-labels
NAME               READY   STATUS    RESTARTS   AGE     LABELS
cart-dev           1/1     Running   14         145m    application_type=api,dev-lead=carisa,env=development,release-version=1.0,team=ecommerce
cart-prod          1/1     Running   14         145m    application_type=api,dev-lead=carisa,env=production,release-version=1.0,team=ecommerce
cart-staging       1/1     Running   14         145m    application_type=api,dev-lead=carisa,env=staging,release-version=1.0,team=ecommerce

										vvv
$ kubectl get pods -l 'release-version notin (1.0,2.0)' --show-labels
homepage-dev      1/1     Running 0    147m    application_type=ui,dev-lead=karthik,env=development,release-version=12.0,team=web
homepage-prod     1/1     Running 0    147m    application_type=ui,dev-lead=karthik,env=production,release-version=12.0,team=web
homepage-staging  1/1     Running 0    147m    application_type=ui,dev-lead=karthik,env=staging,release-version=12.0,team=web
	
	
# Delete

$ kubectl get pods --show-labes

$ kubectl delete pods -l dev-lead=karthik    		<-   '-l , --select' 

$ kubectl get pods --show-labels

# Delete all dev-lead 
$ kubectl delete pods -l dev-lead		    		<-   '-l , --select' 







-------------------------------------------------------------------------------------------
20 Application health checks
-------------------------------------------------------------------------------------------
$ vi  helloworld-with-probes.yml
-------------------------------------------------------------------------------------------
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: helloworld-deployment-with-probe
spec:
  selector:
    matchLabels:
      app: helloworld
  replicas: 1 # tells deployment to run 1 pods matching the template
  template: # create pods using pod definition in this template
    metadata:
      labels:
        app: helloworld
    spec:
      containers:
      - name: helloworld
        image: karthequian/helloworld:latest
        ports:
        - containerPort: 80
        readinessProbe:
          ### length of time to wait for a pod to initialize
          ### after pod startup, before applying health checking
          initialDelaySeconds: 10
          ### Amount of time to wait before timing out
          initialDelaySeconds: 1
          ### Probe for http
          httpGet:
            # Path to probe
            path: /
            # Port to probe
            port: 80
        livenessProbe:
          ### length of time to wait for a pod to initialize
          ### after pod startup, before applying health checking
          initialDelaySeconds: 100
          ### Amount of time to wait before timing out
          timeoutSeconds: 1
          ### Probe for http
          httpGet:
            # Path to probe
            path: /
            # Port to probe
            port: 80

-------------------------------------------------------------------------------------------

$ kubectl get deployment			<- without s	same
$ kubectl get deployments			<- with s    	same

		NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
		helloworld-all-deployment          3/3     3            3           15h
		helloworld-deployment-with-probe   1/1     1            1           53s


## Failed pod check
$ kubectl create -f helloworld-BAD-liveness-probe.yml
-------------------------------------------------------------------------------------------
apiVersion: apps/v1beta1
kind: Deployment
metadata: 
  name: helloworld-deployment-with-bad-liveness-probe
spec:
  selector:
    matchLabels:
      app: helloworld
  replicas: 1 # tells deployment to run 1 pods matching the template
  template: # create pods using pod definition in this template
    metadata:
      labels:
        app: helloworld
    spec:
      containers:
      - name: helloworld
        image: karthequian/helloworld:latest
        ports:
        - containerPort: 80
        livenessProbe:
          # length of time to wait for a pod to initialize
          # after pod startup, before applying health checking
          initialDelaySeconds: 10
          # How often (in seconds) to perform the probe.
          periodSeconds: 5
          # Amount of time to wait before timing out
          timeoutSeconds: 1
          # Kubernetes will try failureThreshold times before giving up and restarting the Pod
          failureThreshold: 2
          # Probe for http
          httpGet:
            # Path to probe
            path: /
            # Port to probe
            port: 90
-------------------------------------------------------------------------------------------

$ kubectl get deployments
	helloworld-deployment-with-bad-liveness-probe   1/1     1            1           2m35s

  $ kubectl get pods
 #$ kubectl get pod
 #$ kubectl get po
	helloworld-deployment-with-bad-liveness-probe-575d9d65c5-m7dhx   1/1     Running   1          28s

# Get specific PODs info( po/pod/pods all works)
$ kubectl get   po/helloworld-deployment-with-bad-liveness-probe-575d9d65c5-m7dhx
$ kubectl get  pod/helloworld-deployment-with-bad-liveness-probe-575d9d65c5-m7dhx
$ kubectl get pods/helloworld-deployment-with-bad-liveness-probe-575d9d65c5-m7dhx

	NAME                                            READY   STATUS             RESTARTS   AGE
	helloworld-deployment-with-bad-liveness-probe   0/1     CrashLoopBackOff   5          3m57s
										
										^^^^^^^^^^^^^^^^^	
$ kubectl describe pod/helloworld-deployment-with-bad-liveness-probe-575d9d65c5-m7dhx
 Events:
  Type     Reason     Age                    From               Message
  ----     ------     ----                   ----               -------
  Normal   Scheduled  9m44s                  default-scheduler  Successfully assigned default/helloworld-deployment-with-bad-liveness-probe-575d9d65c5-m7dhx to wc1
  Normal   Pulling    8m45s (x4 over 9m43s)  kubelet, wc1       Pulling image "karthequian/helloworld:latest"
**Warning  Unhealthy  8m45s (x6 over 9m30s)  kubelet, wc1       Liveness probe failed: Get http://10.244.1.29:90/: dial tcp 10.244.1.29:90: connect: connection refused
  Normal   Killing    8m45s (x3 over 9m25s)  kubelet, wc1       Container helloworld failed liveness probe, will be restarted
  Normal   Pulled     8m44s (x4 over 9m42s)  kubelet, wc1       Successfully pulled image "karthequian/helloworld:latest"
  Normal   Created    8m44s (x4 over 9m42s)  kubelet, wc1       Created container helloworld
  Normal   Started    8m44s (x4 over 9m42s)  kubelet, wc1       Started container helloworld
**Warning  BackOff    4m34s (x17 over 8m5s)  kubelet, wc1       Back-off restarting failed container

$ kubectl get pods
$ kubectl get deployments
	NAME                                            READY   UP-TO-DATE   AVAILABLE   AGE
	helloworld-all-deployment                       3/3     3            3           16h
	helloworld-deployment-with-bad-liveness-probe   0/1     1            0           12m	<= 0 Not Ready

-------------------------------------------------------------------------------------------
21 Handling application upgrades	
-------------------------------------------------------------------------------------------
# Docker Images Location
https://hub.docker.com/r/karthequian/helloworld/tags

docker.io/karthequian/helloworld     blue                2be33d0f49e0        23 months ago       276 MB
docker.io/karthequian/helloworld     black               bb894a7bfd14        23 months ago       276 MB

$ sudo docker pull karthequian/helloworld:black
$ sudo docker pull karthequian/helloworld:blue

-------------------------------------------------------------------------------------------

# Record rollout HISTORY

$ kubectl create -f helloworld-black.yml --record		<- '--record' keeping version for 'REVERT'
-------------------------------------------------------------------------------------------
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: navbar-deployment
spec:
  selector:
    matchLabels:
      app: helloworld
  replicas: 3 	# <- tells deployment to run 3 pods matching the template
  template: 	# <- create pods using pod definition in this template
    metadata:
      labels:
        app: helloworld
    spec:
      containers:
      - name: helloworld
        image: karthequian/helloworld:black
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: navbar-service
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  type: NodePort
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: helloworld
-------------------------------------------------------------------------------------------

$ kubectl get service navbar-service
	NAME             TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
	navbar-service   NodePort   10.105.89.125   <none>        80:31583/TCP   68m

# Check 
	http://134.209.6.242:31583/	

# Manually Change the images 'BLUE'
  $ kubectl set image deployment/navbar-deployment helloworld=karthequian/helloworld:blue   <==BLUE
	-> deployment.extensions/navbar-deployment image updated

# Change back to 'BLACK'	
  $ kubectl set image deployment/navbar-deployment helloworld=karthequian/helloworld:black  <==BLACK
	-> deployment.extensions/navbar-deployment image updated


$ kubectl get deployments
	NAME                                             READY   UP-TO-DATE   AVAILABLE   AGE
	navbar-deployment                                3/3     3            3           114m

$ kubectl get pods
	navbar-deployment-64664cc7-4f2gh                                  1/1     Running            0          9m49s
	navbar-deployment-64664cc7-kfngg                                  1/1     Running            0          9m50s
	navbar-deployment-64664cc7-x82m6                                  1/1     Running            0          9m48s

$ kubectl get pods/navbar-deployment-64664cc7-4f2gh
	NAME                               READY   STATUS    RESTARTS   AGE
	navbar-deployment-64664cc7-4f2gh   1/1     Running   0          8m7s



# check replica sets
	$ kubectl get replicasets
	$ kubectl get rs


-------------------------------------------------------------------------------------------
# Upgrade deployment

# Rollout History
$ kubectl rollout history deployment/navbar-deployment
	REVISION  CHANGE-CAUSE
	1 kubectl create --filename=helloworld-black.yaml --record=true
	2 kubectl set image deployment/navbar-deployment helloworld=karthquian/helloworld:blue
	
$ kubectl rollout undo deployment/navbar-deployment
	deployment.extensions/navbar-deployment rolled back
	
	# Check 
	http://134.209.6.242:31583/	
	Blue => Black

# Go to specific version
	$kubectl rollout undo deployment/navbar-deployment --to-revision=

-------------------------------------------------------------------------------------------
# 22. Troubleshooting	
-------------------------------------------------------------------------------------------
$ kubectl get deployments
	NAME                                             READY   UP-TO-DATE   AVAILABLE   AGE
	helloworld-all-deployment                        3/3     3            3           9d
	helloworld-deployment-with-bad-liveness-probe    1/1     1            1           8d
	helloworld-deployment-with-bad-readiness-probe   0/1     1          >>0<<         8d

$ Kubectl get pods
	NAME                                                              READY   STATUS             RESTARTS   AGE
	helloworld-deployment-with-bad-liveness-probe-575d9d65c5-m7dhx    0/1     CrashLoopBackOff   4523       9d

$ kubectl describe deployment helloworld-deployment-with-bad-readiness-probe
-------------------------------------------------------------------------------------------
Name:                   helloworld-deployment-with-bad-readiness-probe
Namespace:              default
CreationTimestamp:      Tue, 24 Sep 2019 23:17:24 +0000
Labels:                 app=helloworld
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=helloworld
Replicas:               1 desired | 1 updated | 1 total | 0 available | 1 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=helloworld
  Containers:
   helloworld:
    Image:        karthequian/helloworld:latest
    Port:         80/TCP
    Host Port:    0/TCP
    Readiness:    http-get http://:90/ delay=1s timeout=1s period=10s #success=1 #failure=3
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      False   MinimumReplicasUnavailable
  Progressing    False   ProgressDeadlineExceeded
OldReplicaSets:  <none>
NewReplicaSet:   helloworld-deployment-with-bad-readiness-probe-865c6c4796 (1/1 replicas created)
Events:          <none>

-------------------------------------------------------------------------------------------
$ kubectl get pods 
$ kubectl describe pods/helloworld-deployment-with-bad-liveness-probe-575d9d65c5-m7dhx 
-------------------------------------------------------------------------------------------
Name:           helloworld-deployment-with-bad-liveness-probe-575d9d65c5-m7dhx
Namespace:      default
Priority:       0
Node:           wc1/157.230.128.122
Start Time:     Tue, 24 Sep 2019 22:56:59 +0000
Labels:         app=helloworld
                pod-template-hash=575d9d65c5
Annotations:    <none>
Status:         Running
IP:             10.244.1.29
Controlled By:  ReplicaSet/helloworld-deployment-with-bad-liveness-probe-575d9d65c5
Containers:
  helloworld:
    Container ID:   docker://65eef3d2ef7e42671b7aa6fe95e3004f2213f3e8f988c74a06614a1396c44f03
    Image:          karthequian/helloworld:latest
    Image ID:       docker-pullable://docker.io/karthequian/helloworld@sha256:da1f6fc8eb1d02af1a2eaf48111c945c4e0fe5ac5476048db99a109a865531fd
    Port:           80/TCP
    Host Port:      0/TCP
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Thu, 03 Oct 2019 23:02:29 +0000
      Finished:     Thu, 03 Oct 2019 23:02:48 +0000
    Ready:          False
    Restart Count:  4525
    Liveness:       http-get http://:90/ delay=10s timeout=1s period=5s #success=1 #failure=2
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-4k6x2 (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             False
  ContainersReady   False
  PodScheduled      True
Volumes:
  default-token-4k6x2:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-4k6x2
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events: 
    Type     Reason     Age                    From          Message
    ----     ------     ----                   ----          -------
>>  Warning  BackOff    13m (x55291 over 9d)   kubelet, wc1  Back-off restarting failed container
>>  Warning  Unhealthy  8m59s (x9048 over 9d)  kubelet, wc1  Liveness probe failed: Get http://10.244.1.29:90/: 
																dial tcp 10.244.1.29:90: connect: connection refused
    Normal   Pulling    3m50s (x4525 over 9d)  kubelet, wc1  Pulling image "karthequian/helloworld:latest"
-------------------------------------------------------------------------------------------
$ kubectl get deployments
$ Kubectl get pods
	NAME                                                              READY   STATUS             RESTARTS   AGE
	helloworld-deployment-with-bad-liveness-probe-575d9d65c5-m7dhx    0/1     CrashLoopBackOff   4523       9d

# Get Pod's Log
$ kubctl logs h <tab>
$ kubctl logs helloworld-deployment-with-bad-liveness-probe-575d9d65c5-m7dhx

# Specific pod's Nginx log
$ kubectl logs helloworld-deployment-with-probe-65d8597578-vwkb7

# Log in to a POD
# for Sigle pod
$ kubectl exec -it    helloworld-deployment-with-probe-65d8597578-vwkb7    /bin/bash
	root@helloworld-deployment-with-probe-65d8597578-vwkb7:/#

	root@helloworld-deployment-with-probe-65d8597578-vwkb7:/# ps -ef
	UID        PID  PPID  C STIME TTY          TIME CMD
	root         1     0  0 Sep24 ?        00:00:00 nginx: master process nginx
	nobody       8     1  0 Sep24 ?        00:00:54 nginx: worker process
	root         9     0  0 23:46 ?        00:00:00 /bin/bash
	root        21     9  0 23:47 ?        00:00:00 ps -ef

# Multi Pods 
$ kubectl exec -it helloworld-deployment-with-probe-65d8597578-vwkb7 -c helloworld /bin/bash

-------------------------------------------------------------------------------------------
  804  kubectl -n kube-system

  805  kubectl -n kube-system get all

  806  kubectl get ns

  807  kubectl get nodes

  808  kubectl -n kube-system get nodes

  809  kubectl -n kube-system get pods

  810  kubectl -n default get pods

  811  kubectl  get pods
  
  814  kubectl -n kube-system get all

  815  kubectl -n kube-system get deployment.apps/alb-ingress-controller

  816  kubectl -n kube-system get deployment coredns

  817  kubectl -n kube-system get deployment.apps/coredns

  818  kubectl -n kube-system get deployment alb-ingress-controller

  819  kubectl -n kube-system edit deployment alb-ingress-controller

  820  kubectl -n kube-system edit deployment alb-ingress-controller -o wide

  821  kubectl -n kube-system get  deployment alb-ingress-controller -o wide

  822  kubectl -n kube-system get  deployment alb-ingress-controller -o yaml

  847  kubectl -n kube-system get deployment alb-ingress-controller -o wide

  848  kubectl get all -n kube-system

  849  kubectl get all

  850  kubectl --namespace default get all

  851  kubectl --namespace default get all | tail -1

  852  kubectl --namespace default get all | tail -1 ; kubectl get all | tail -1

  853  kubectl config current-context

  854  kubectl config use-context platform-dev

  855  kubectl config current-context

 1885  kubectl config current-use

 1886  kubectl config current-context

 1887  kubectl config current-use platform-prod

 1888  kubectl config use-context platform-prod

 1889  kubectl get nodes

 1890  kubectl get pos

 1891  kubectl get pods

 1892  kubectl get pods | grep platform-api

 1893  kubectl get pods | grep "platform-api"

 1894  kubectl get pods | grep "platform-api"

 1895  kubectl get nodes

 1896  kubectl get pods | grep platform-api

 1931  kubectl get nodes

 1932  kubectl get pods | grep platform-prod-api

 1933  kubectl get pods

 1934  kubectl get hpa                                  <= Horizontal Pod Autoscaler
 
 2122  kubectl config current-context

 2123  kubectl config use-context platform-dev

 2124  kubectl config current-context

 2125  kubectl get ingress

 2126  kubectl get ing

 2127  kubectl get pods

 2128  kubectl get pod nginx-proxy-6b5cd479c5-lp6mp

 2129  kubectl get ing

 2130  kubectl describe ingress dev-billadmin

 2131  kubectl eit ingress dev-billadmin

 2132  kubectl edit ingress dev-billadmin

 2141  cat  eks/dev/manifests/default/ingress/alb-dev-billadmin-ing.yaml 

 2142  cvi  eks/dev/manifests/default/ingress/alb-dev-billadmin-ing.yaml 

 2143  vi  eks/dev/manifests/default/ingress/alb-dev-billadmin-ing.yaml 

 2144  curl -v https://billadmin-dev.bnea.io

 2150  cat   manifests/default/ingress/alb-dev-billadmin-ing.yaml
-------------------------------------------------------------------------------------------
$ cat switch.sh

#!/bin/bash
set -ex

aws s3 cp s3://bnea.dev/kube/config-platform-dev /tmp/config-platform-dev

KUBECONFIG=~/.kube/config:/tmp/config-platform-dev kubectl config view --flatten >| /tmp/kubeconfig && cp -f /tmp/kubeconfig ~/.kube/config
rm -f /tmp/config-platform-dev && rm -f /tmp/kubeconfig

echo ${KUBECONFIG}

kubectl config use-context platform-dev
kubectl cluster-info
kubectl get nodes
-------------------------------------------------------------------------------------------



-------------------------------------------------------------------------------------------

-------------------------------------------------------------------------------------------

-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------






























































































