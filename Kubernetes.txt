Kubernetes 1.10

Prerequisite
Ansible <= operating-system-level dependencies and their configuration
		1. An SSH key pair on your local Linux/Mac OS/BSD machine. If you haven't used SSH keys before, 
			you can learn how to set them up by following this explanation of how to set up SSH keys on your local machine.
		2. Three servers running Ubuntu 16.04 with at least 1GB RAM. You should be able to SSH into each 
			server as the root user with your SSH key pair.
		3. Ansible installed on your local machine. If you're running Ubuntu 16.04 as your OS, follow the 
			"Step 1 - Installing Ansible" section in How to Install and Configure Ansible on Ubuntu 16.04 
			to install Ansible. For installation instructions on other platforms like Mac OS X or CentOS, 
			follow the official Ansible installation documentation.
		4. Familiarity with Ansible playbooks. For review, check out Configuration Management 101: Writing Ansible Playbooks.
		5. Knowledge of how to launch a container from a Docker image. Look at "Step 5 — Running a Docker Container" 
			in How To Install and Use Docker on Ubuntu 16.04 if you need a refresher.


https://www.digitalocean.com/community/tutorials/how-to-create-a-kubernetes-1-10-cluster-using-kubeadm-on-centos-7
https://www.digitalocean.com/community/tutorials/how-to-create-a-kubernetes-1-10-cluster-using-kubeadm-on-ubuntu-16-04


CNI 	<- Container Network Interface is a library definition, and a set of tools under the 
		   umbrella of the Cloud Native Computing Foundation project.



--------------------------------------------------------------------------------
Kubeadm 
------------------------------------------------------------------------------------	
	automates the installation and configuration of Kubernetes components such as the 
	1) API server, 2)Controller Manager, 3)Kube DNS

	1. One master node <= The master node (a node in Kubernetes refers to a server) is responsible for 
							managing the state of the cluster. It runs Etcd, which stores cluster data among 
							components that schedule workloads to worker nodes.
							Two worker nodes
	2. Worker nodes 	<= are the servers where your workloads (i.e. containerized applications and services) will run. 
							A worker will continue to run your workload once they're assigned to it, even if the master 
							goes down once scheduling is complete. A cluster's capacity can be increased by adding workers.
	e.g.
	$ kubeadm version

------------------------------------------------------------------------------------
Kunelet(Node Agent)
	https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/
------------------------------------------------------------------------------------
	A system service/program that runs on all nodes(worker servers) and handles node-level(workers) operation
	
	e.g.
	$ kubelet
	
------------------------------------------------------------------------------------	
Kubectl
------------------------------------------------------------------------------------
	A CLI tool used for issuing commands to the cluster through its API Server(Master)

	e.g.
	$ kubectl --kubeconfig='bnea-k8-config.yml' get nodes
	$ kubectl cluster-info
	$ kubectl version
	$ kubectl get nodes
	$ kubectl get pods
	
------------------------------------------------------------------------------------
Pods                            
------------------------------------------------------------------------------------	
	is an atomic unit that runs one or more Docker containers
------------------------------------------------------------------------------------                            
 
------------------------------------------------------------------------------------	
Pod Network Plugins
------------------------------------------------------------------------------------ 
	Flannel(체크남방) 



                            
### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###                             
                            
$ kubectl --kubeconfig=''    <= Path to the kubeconfig file to use for CLI requests.      
                             $ kubectl config view --raw

$ kubectl --kubeconfig='bnea-k8-config.yml' get nodes
    NAME                STATUS   ROLES    AGE    VERSION
    bnea-k8-master      Ready    master   216d   v1.11.0
    bnea-k8-worker-01   Ready    <none>   216d   v1.11.0
    bnea-k8-worker-02   Ready    <none>   216d   v1.11.0
                           


                            
### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### 
Kubernetes Cluster Introspection(
                           
                           
$ kubectl api-resources  <= complete list of supported resources.
                           
# kubectl api-describes


$ kubectl options

$ kubectl get nodes      <= List currnet     nodes(Wokers)
$ kubectl get pods       <= List currnet     pods(Dockers)
$ kubectl get rc         <= List replication controllers    
$ kubectl get services   <= List services
              service
              svc

# Describe pod <name>
    $ kubectl describe pod 
    $ kubectl describe pod <name>





------------------------------------------------------------------------------------
kubectl Cheat Sheet
https://kubernetes.io/docs/reference/kubectl/cheatsheet/
------------------------------------------------------------------------------------
# Kubectl Autocompletion
--------------------------------------------------
	# setup autocomplete in bash into the current shell, bash-completion package should be installed first.
		$ source <(kubectl completion bash) 
		
	# add autocomplete permanently to your bash shell.
		$ echo "source <(kubectl completion bash)" >> ~/.bashrc 
	
	# If it is not working, Log out and Log in first.	
	
	# kubectl completion -h
	
	# alias for kubectl
		$ alias     k=kubectl
		$ complete  -F __start_kubectl k
		
	$ kubectl desc<TAB> p<TAB> my-nginx<TAB>	

# Kubectl Context and Configuration
--------------------------------------------------
	$ kubectl config view <=  Show Merged kubeconfig settings.

	# use multiple kubeconfig files at the same time and view merged config
	KUBECONFIG=~/.kube/config:~/.kube/kubconfig2 

	kubectl config view

	# get the password for the e2e user
	kubectl config view -o jsonpath='{.users[?(@.name == "e2e")].user.password}'

	kubectl config view -o jsonpath='{.users[].name}'    # get a list of users
	kubectl config get-contexts                          # display list of contexts 
	kubectl config current-context			             # display the current-context
	kubectl config use-context my-cluster-name           # set the default context to my-cluster-name

	# add a new cluster to your kubeconf that supports basic auth
	kubectl config set-credentials kubeuser/foo.kubernetes.com --username=kubeuser --password=kubepassword

	# permanently save the namespace for all subsequent kubectl commands in that context.
	kubectl config set-context --current --namespace=ggckad-s2

	# set a context utilizing a specific username and namespace.
	kubectl config set-context gce --user=cluster-admin --namespace=foo \
	  && kubectl config use-context gce
	 
	kubectl config unset users.foo                       # delete user foo
	

--------------------------------------------------                            
                            
### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### 

                            
### Terminology                            
                            
kops 	<= Kubernetes Operations
kubeadm <= easily bootstrap a secure Kubernetes cluster.
  $ kubeadm --help
                            
# docker: Got permission denied
$ sudo usermod -a -G docker $USER                            
                            
                            
                            
                            
                            
## Kubenetes Cluster Dashboard
https://github.com/kubernetes/dashboard/blob/master/README.md

                            
                            
                            
                            
                            
                            
                            
Auto Completion
   https://kubernetes.io/docs/tasks/tools/install-kubectl/#enabling-shell-autocompletion                         
                            
apt-get install bash-completion 
yum install bash-completion

 commands create '/usr/share/bash-completion/bash_completion'
 source /usr/share/bash-completion/bash_completion
 



Enable kubectl autocompletion
 echo "source <(kubectl completion bash)" >> ~/.bashrc 


kubectl completion bash >/etc/bash_completion.d/kubectl

netops$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl



------------------------------------------------------------------------------------
------------------------------------------------------------------------------------
### 	Kubernetes Cheat Sheet     ###
------------------------------------------------------------------------------------
	https://cheatsheet.dennyzhang.com/cheatsheet-kubernetes-A4
	
------------------------------------------------------------------------------------
1.0 Tools Name
------------------------------------------------------------------------------------
kubectl		the command line util to talk to k8s cluster

kubeadm		the command to bootstrap the cluster

kubefed		the command line to control a Kubernetes Cluster Federation

Kubernetes 	Components	Link: Kubernetes Components

------------------------------------------------------------------------------------
1.1 COMMON COMMANDS
------------------------------------------------------------------------------------
Run curl test temporarily				kubectl run --rm mytest --image=yauritux/busybox-curl -it
Run wget test temporarily				kubectl run --rm mytest --image=busybox -it
Run nginx deployment with 2 replicas: 	kubectl run my-nginx --image=nginx --replicas=2 --port=80
Set namespace preference				kubectl config set-context $(kubectl config current-context) --namespace=<ns1>
List pods with nodes info				kubectl get pod -o wide
List everything							kubectl get all --all-namespaces
Get all services						kubectl get service --all-namespaces
Show nodes with labels					kubectl get nodes --show-labels
Validate yaml file with dry run			kubectl create --dry-run --validate -f pod-dummy.yaml
Start a temporary pod for testing		kubectl run --rm -i -t --image=alpine test-$RANDOM -- sh
kubectl run shell command				kubectl exec -it mytest -- ls -l /etc/hosts
Get system conf via configmap			kubectl -n kube-system get cm kubeadm-config -o yaml
Get deployment yaml						kubectl -n denny-websites get deployment mysql -o yaml
Explain resource						kubectl explain pods, kubectl explain svc
Watch pods								kubectl get pods -n wordpress --watch
Query healthcheck endpoint				curl -L http://127.0.0.1:10250/healthz
Open a bash terminal in a pod			kubectl exec -it storage sh
Check pod environment variables			kubectl exec redis-master-ft9ex env
Enable kubectl shell autocompletion		echo "source <(kubectl completion bash)" >>~/.bashrc, and reload
Use minikube dockerd in your laptop	eval $(minikube docker-env), No need to push docker hub any more
Kubectl apply a folder of yaml files	kubectl apply -R -f .
Get services sorted by name				kubectl get services –sort-by=.metadata.name
Get pods sorted by restart count		kubectl get pods –sort-by=’.status.containerStatuses[0].restartCount’

------------------------------------------------------------------------------------
1.2 CHECK PERFORMANCE
------------------------------------------------------------------------------------
Get node resource usage							kubectl top node
Get pod resource usage							kubectl top pod
Get resource usage for a given pod				kubectl top <pod_name> --containers
List resource utilization for all containers	kubectl top pod --all-namespaces --containers=true

------------------------------------------------------------------------------------
1.3 RESOURCES DELETION
------------------------------------------------------------------------------------
Delete pod								kubectl delete pod/<pod-name> -n <my-namespace>
Delete pod by force						kubectl delete pod/<pod-name> --grace-period=0 --force
Delete pods by labels					kubectl delete pod -l env=test
Delete deployments by labels			kubectl delete deployment -l app=wordpress
Delete all resources filtered by labels	kubectl delete pods,services -l name=myLabel
Delete resources under a namespace		kubectl -n my-ns delete po,svc --all
Delete persist volumes by labels		kubectl delete pvc -l app=wordpress
Delete statefulset only (not pods)		kubectl delete sts/<stateful_set_name> --cascade=false

------------------------------------------------------------------------------------
1.4 LOG & CONF FILES
------------------------------------------------------------------------------------
Config folder				/etc/kubernetes/
Certificate files			/etc/kubernetes/pki/
Credentials to API server	/etc/kubernetes/kubelet.conf
Superuser credentials		/etc/kubernetes/admin.conf
kubectl config file			~/.kube/config
Kubernets working dir		/var/lib/kubelet/
Docker working dir			/var/lib/docker/, /var/log/containers/
Etcd working dir			/var/lib/etcd/
Network cni					/etc/cni/net.d/
Log files					/var/log/pods/
log in master node			/var/log/kube-apiserver.log, kube-scheduler.log, kube-controller-manager.log
log in worker node			/var/log/kubelet.log, kubelet-proxy.log

Env	/etc/systemd/system/kubelet.service.d/10-kubeadm.conf
Env	export KUBECONFIG=/etc/kubernetes/admin.conf

------------------------------------------------------------------------------------
1.5 POD
------------------------------------------------------------------------------------
List all pods					kubectl get pods
List pods for all namespace		kubectl get pods -all-namespaces
List all critical pods			kubectl get -n kube-system pods -a
List pods with more info		kubectl get pod -o wide, kubectl get pod/<pod-name> -o yaml
Get pod info					kubectl describe pod/srv-mysql-server
List all pods with labels		kubectl get pods --show-labels
List running pods				kubectl get pods –field-selector=status.phase=Running
Get Pod initContainer status	kubectl get pod --template '{{.status.initContainerStatuses}}' <pod-name>
kubectl run command				kubectl exec -it -n “$ns” “$podname” – sh -c “echo $msg >>/dev/err.log”
Watch pods						kubectl get pods -n wordpress --watch
Get pod by selector				podname=$(kubectl get pods -n $namespace –selector=”app=syslog” -o jsonpath='{.items[*].metadata.name}’)
List pods and containers		kubectl get pods -o=’custom-columns=PODS:.metadata.name,CONTAINERS:.spec.containers[*].name’
List pods, containers&images	kubectl get pods -o=’custom-columns=PODS:.metadata.name,CONTAINERS:.spec.containers[*].name,Images:.spec.containers[*].image’

------------------------------------------------------------------------------------
1.6 LABEL & ANNONTATION
------------------------------------------------------------------------------------
Filter pods by label				kubectl get pods -l owner=denny
Manually add label to a pod			kubectl label pods dummy-input owner=denny
Remove label						kubectl label pods dummy-input owner-
Manually add annonation to a pod	kubectl annotate pods dummy-input my-url=https://dennyzhang.com

------------------------------------------------------------------------------------
1.7 DEPLOYMENT & SCALE
------------------------------------------------------------------------------------
Scale out						kubectl scale --replicas=3 deployment/nginx-app
online rolling upgrade			kubectl rollout app-v1 app-v2 --image=img:v2
Roll backup						kubectl rollout app-v1 app-v2 --rollback
List rollout					kubectl get rs
Check update status				kubectl rollout status deployment/nginx-app
Check update history			kubectl rollout history deployment/nginx-app
Pause/Resume					kubectl rollout pause deployment/nginx-deployment, resume
Rollback to previous version	kubectl rollout undo deployment/nginx-deployment

------------------------------------------------------------------------------------
1.8 QUOTA & LIMITS & RESOURCE
------------------------------------------------------------------------------------
Customize resource definition	kubectl set resources deployment nginx -c=nginx --limits=cpu=200m,memory=512Mi
List Resource Quota				kubectl get resourcequota
List Limit Range				kubectl get limitrange
Customize resource definition	kubectl set resources deployment nginx -c=nginx --limits=cpu=200m,memory=512Mi

------------------------------------------------------------------------------------
1.9 SERVICE
------------------------------------------------------------------------------------
List all services				kubectl get services
List service endpoints			kubectl get endpoints
Get service detail				kubectl get service nginx-service -o yaml
Get service cluster ip			kubectl get service nginx-service -o go-template='{{.spec.clusterIP}}’
Get service cluster port		kubectl get service nginx-service -o go-template='{{(index .spec.ports 0).port}}’
Expose deployment as lb service	kubectl expose deployment/my-app --type=LoadBalancer --name=my-service
Expose service as lb service	kubectl expose service/wordpress-1-svc --type=LoadBalancer --name=wordpress-lb

------------------------------------------------------------------------------------
1.10 SECRETS
------------------------------------------------------------------------------------
List secrets					kubectl get secrets --all-namespaces
Create secret from cfg file		kubectl create secret generic db-user-pass --from-file./username.txt=
Generate secret	echo -n 'mypasswd', then redirect to base64 -decode

------------------------------------------------------------------------------------
1.11 STATEFULSET
------------------------------------------------------------------------------------
List statefulset					kubectl get sts
Delete statefulset only (not pods)	kubectl delete sts/<stateful_set_name> --cascade=false
Scale statefulset					kubectl scale sts/<stateful_set_name> --replicas=5

------------------------------------------------------------------------------------
1.12 VOLUMES & VOLUME CLAIMS
------------------------------------------------------------------------------------
List storage class				kubectl get storageclass
Check the mounted volumes		kubectl exec storage ls /data
Check persist volume			kubectl describe pv/pv0001
Copy local file to pod			kubectl cp /tmp/my <some-namespace>/<some-pod>:/tmp/server
Copy pod file to local			kubectl cp <some-namespace>/<some-pod>:/tmp/server /tmp/my

------------------------------------------------------------------------------------
1.13 EVENTS & METRICS
------------------------------------------------------------------------------------
View all events						kubectl get events --all-namespaces
List Events sorted by timestamp		kubectl get events –sort-by=.metadata.creationTimestamp

------------------------------------------------------------------------------------
1.14 NODE MAINTENANCE
------------------------------------------------------------------------------------
Mark node as unschedulable					kubectl cordon $NDOE_NAME
Mark node as schedulable					kubectl uncordon $NDOE_NAME
Drain node in preparation for maintenance	kubectl drain $NODE_NAME

------------------------------------------------------------------------------------
1.15 NAMESPACE & SECURITY
------------------------------------------------------------------------------------
List authenticated contexts			kubectl config get-contexts, ~/.kube/config
Load context from config file		kubectl get cs --kubeconfig kube_config.yml
Switch context						kubectl config use-context <cluster-name>
Delete the specified context		kubectl config delete-context <cluster-name>
List all namespaces defined			kubectl get namespaces
Set namespace preference			kubectl config set-context $(kubectl config current-context) --namespace=<ns1>
List certificates					kubectl get csr

------------------------------------------------------------------------------------
1.16 NETWORK
------------------------------------------------------------------------------------
Name	Command
Temporarily add a port-forwarding	kubectl port-forward redis-izl09 6379
Add port-forwaring for deployment	kubectl port-forward deployment/redis-master 6379:6379
Add port-forwaring for replicaset	kubectl port-forward rs/redis-master 6379:6379
Add port-forwaring for service		kubectl port-forward svc/redis-master 6379:6379
Get network policy					kubectl get NetworkPolicy

------------------------------------------------------------------------------------
1.17 PATCH
------------------------------------------------------------------------------------
Patch service to loadbalancer	kubectl patch svc "$APP_INSTANCE_NAME-grafana" -p '{"spec": {"type": "LoadBalancer"}}'

------------------------------------------------------------------------------------
1.18 EXTENSTIONS
------------------------------------------------------------------------------------
List api group					kubectl api-versions
List all CRD					kubectl get crd
List storageclass				kubectl get storageclass
List all supported resources	kubectl api-resources

------------------------------------------------------------------------------------
1.19 COMPONENTS & SERVICES
------------------------------------------------------------------------------------
1.19.1 SERVICES ON MASTER NODES
------------------------------------------------------------------------------------
Name	Summary
kube-apiserver	exposes the Kubernetes API from master nodes
etcd	reliable data store for all k8s cluster data
kube-scheduler	schedule pods to run on selected nodes
kube-controller-manager	node controller, replication controller, endpoints controller, 
	and service account & token controllers

------------------------------------------------------------------------------------
1.19.2 SERVICES ON WORKER NODES
------------------------------------------------------------------------------------
kubelet	makes sure that containers are running in a pod
kube-proxy	perform connection forwarding
Container Runtime	Kubernetes supported runtimes: Docker, rkt, runc and any OCI 
													runtime-spec implementation.
------------------------------------------------------------------------------------
1.19.3 ADDONS: PODS AND SERVICES THAT IMPLEMENT CLUSTER FEATURES
------------------------------------------------------------------------------------
DNS	serves DNS records for Kubernetes services
Web UI	a general purpose, web-based UI for Kubernetes clusters
Container Resource Monitoring	collect, store and serve container metrics
Cluster-level Logging	save container logs to a central log store with search/browsing interface
------------------------------------------------------------------------------------

							
------------------------------------------------------------------------------------
------------------------------------------------------------------------------------
------------------------------------------------------------------------------------							
							
							

$ kubectl --kubeconfig ~/.kube/config --context platform-dev get nodes

$ kubectl --kubeconfig ~/.kube/config --context platform-stg get nodes

$ kubectl --kubeconfig ~/.kube/config --context platform-prod get nodes
							
							
							
							
$ kubectl --kubeconfig ~/.kube/config --context platform-prod get nodes
NAME                             STATUS   ROLES    AGE   VERSION
ip-172-16-107-120.ec2.internal   Ready    <none>   63d   v1.11.5
ip-172-16-69-95.ec2.internal     Ready    <none>   63d   v1.11.5
ip-172-16-77-231.ec2.internal    Ready    <none>   63d   v1.11.5
ip-172-16-82-18.ec2.internal     Ready    <none>   63d   v1.11.5
ip-172-16-83-138.ec2.internal    Ready    <none>   63d   v1.11.5


Retiring: This instance is scheduled for retirement after May 27, 2019 at 12:00:00 PM UTC-7.							
platform-prod-worker-Node i-0c0aed94d2a0f284b m5.xlarge us-east-1b						
							
							
							
							
can you upgrade kube-proxy, coredns, and CNI in platform-prod? It’s running older version. 

[DavidHPark@~]$ kubectl --kubeconfig ~/.kube/config --context platform-prod describe ds kube-proxy -n kube-system | grep Image
  
  Image:      602401143452.dkr.ecr.us-east-1.amazonaws.com/eks/kube-proxy:v1.11.5
   
[DavidHPark@~]$ kubectl --kubeconfig ~/.kube/config --context platform-prod describe deployment coredns --namespace kube-system | grep Image | cut -d '/' -f 3

coredns:v1.1.3

[DavidHPark@~]$ kubectl --kubeconfig ~/.kube/config --context platform-prod describe daemonset aws-node --namespace kube-system | grep Image | cut -d '/' -f 2

amazon-k8s-cni:1.2.1							
							
# kubectl config get,set,use	
Available Commands:
  current-context Displays the current-context
  delete-cluster  Delete the specified cluster from the kubeconfig
  delete-context  Delete the specified context from the kubeconfig
  get-clusters    Display clusters defined in the kubeconfig
  get-contexts    Describe one or many contexts
  rename-context  Renames a context from the kubeconfig file.
  set             Sets an individual value in a kubeconfig file
  set-cluster     Sets a cluster entry in kubeconfig
  set-context     Sets a context entry in kubeconfig
  set-credentials Sets a user entry in kubeconfig
  unset           Unsets an individual value in a kubeconfig file
  use-context     Sets the current-context in a kubeconfig file
  view            Display merged kubeconfig settings or a specified kubeconfig file

Usage:
  kubectl config SUBCOMMAND [options]
##########################################################################################						


Check config env							
kubectl config current-context
				

$ kubectl config get-contexts
CURRENT   NAME            CLUSTER         AUTHINFO        NAMESPACE
          platform-dev    platform-dev    platform-dev
*         platform-prod   platform-prod   platform-prod
          platform-stg    platform-stg    platform-stg

$ kubectl config set-context platform-dev
Context "platform-dev" modified.  <= modified to ~/.kube/config file

....
current-context: platform-dev   <= dev, stg, pro로 바뀜
....

$ kubectl config use-context platform-dev
Switched to context "platform-dev".


$ kubectl get nodes		<dev environment로 보여줌>
NAME                            STATUS   ROLES    AGE   VERSION
ip-172-18-101-32.ec2.internal   Ready    <none>   22d   v1.12.7
ip-172-18-66-183.ec2.internal   Ready    <none>   19d   v1.12.7
ip-172-18-86-246.ec2.internal   Ready    <none>   19d   v1.12.7


$ kubectl config set-context platform-apark
Context "platform-apark" modified.  <= modified to ~/.kube/config file



Check list
$ kubectl get nodes
NAME                             STATUS   ROLES    AGE    VERSION
ip-172-16-103-73.ec2.internal    Ready    <none>   19h    v1.12.7
ip-172-16-107-120.ec2.internal   Ready    <none>   153d   v1.11.5
ip-172-16-65-172.ec2.internal    Ready    <none>   19h    v1.12.7
ip-172-16-69-24.ec2.internal     Ready    <none>   19h    v1.12.7
ip-172-16-69-95.ec2.internal     Ready    <none>   153d   v1.11.5
ip-172-16-77-231.ec2.internal    Ready    <none>   153d   v1.11.5
ip-172-16-81-85.ec2.internal     Ready    <none>   89d    v1.11.5
ip-172-16-82-71.ec2.internal     Ready    <none>   19h    v1.12.7
ip-172-16-83-138.ec2.internal    Ready    <none>   153d   v1.11.5
ip-172-16-83-223.ec2.internal    Ready    <none>   19h    v1.12.7


$ kubectl config use-context platform-dev
Switched to context "platform-dev".

$ kubectl get nodes
Error from server (Forbidden): nodes is forbidden: User "arn:aws:iam::162780728042:user/apark" cannot list resource "nodes" in API group "" at the cluster scope
				
							
							
$ kubectl taint nodes ip-172-16-81-85.ec2.internal key=value:NoSchedule
node/ip-172-16-81-85.ec2.internal tainted
						
							
$ kubectl describe node ip-172-16-81-85.ec2.internal | egrep -i "taint|sched"
Taints:             key=value:NoSchedule
Unschedulable:      false

$ kubectl get nodes
$ kubectl get pods
$ kubectl get pods -o wide | grep ip-172-16-81-85.ec2.internal
							
$ kubectl delete node ip-172-16-83-138.ec2.internal   <= remove this instance from Kube Cluster			

$ kubectl get nodes
NAME                            STATUS                     ROLES    AGE    VERSION
ip-172-16-103-73.ec2.internal   Ready                      <none>   25h    v1.12.7
ip-172-16-65-172.ec2.internal   Ready                      <none>   25h    v1.12.7
ip-172-16-69-24.ec2.internal    Ready                      <none>   25h    v1.12.7
ip-172-16-82-71.ec2.internal    Ready                      <none>   25h    v1.12.7
ip-172-16-83-138.ec2.internal   Ready,SchedulingDisabled   <none>   154d   v1.11.5		<==

$ kubectl describe nodes ip-172-16-83-138.ec2.internal | egrep -i "taint|sched"
Taints:             key=value:NoSchedule
                    node.kubernetes.io/unschedulable:NoSchedule
Unschedulable:      true <<<<<<
  Normal  NodeNotSchedulable  2m9s  kubelet, ip-172-16-83-138.ec2.internal  Node ip-172-16-83-138.ec2.internal status is now: NodeNotSchedulable


------------------------------------------------------------------------------------------
# How To Install Software on Kubernetes Clusters with the Helm Package Manager
	https://www.digitalocean.com/community/tutorials/how-to-install-software-on-kubernetes-clusters-with-the-helm-package-manager
------------------------------------------------------------------------------------------

Helm 	<= is a package manager for Kubernetes that allows developers and operators to 
			more easily configure and deploy applications on Kubernetes clusters.					

Tiller 	<= is a companion to the helm command that runs on your cluster, receiving 
			commands from helm and communicating directly with the Kubernetes API to do the 
			actual work of creating and deleting resources.






------------------------------------------------------------------------------------------

Role-based Access Control
https://helm.sh/docs/using_helm/#role-based-access-control
https://docs.oracle.com/cd/E26925_01/html/E25888/rbac-1.html
------------------------------------------------------------------------------------------

Kubernetes Dashboard 

$ kubectl -n kube-system create serviceaccount t
serviceaccount/tiller created

#bind the tiller serviceaccount to the cluster-admin role:
$ kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller
clusterrolebinding.rbac.authorization.k8s.io/tiller created


$ helm init --service-account tiller

	Creating /home/netops/.helm
	Creating /home/netops/.helm/repository
	Creating /home/netops/.helm/repository/cache
	Creating /home/netops/.helm/repository/local
	Creating /home/netops/.helm/plugins
	Creating /home/netops/.helm/starters
	Creating /home/netops/.helm/cache/archive
	Creating /home/netops/.helm/repository/repositories.yaml


$ kubectl get pods --namespace kube-system

	NAME                             READY   STATUS    RESTARTS   AGE
	coredns-584795fc57-gjr8r         1/1     Running   3          10d
	coredns-584795fc57-pkzvv         1/1     Running   3          10d
	etcd-mc1                         1/1     Running   2          10d
	kube-apiserver-mc1               1/1     Running   2          10d
	kube-controller-manager-mc1      1/1     Running   2          10d
	kube-flannel-ds-amd64-btfsh      1/1     Running   0          10d
	kube-flannel-ds-amd64-pgwgs      1/1     Running   1          10d
	kube-flannel-ds-amd64-v752t      1/1     Running   0          10d
	kube-proxy-895v5                 1/1     Running   0          10d
	kube-proxy-9jd7q                 1/1     Running   0          10d
	kube-proxy-glzpf                 1/1     Running   1          10d
	kube-scheduler-mc1               1/1     Running   7          10d
	tiller-deploy-7f4d76c4b6-8bpx7   1/1     Running   0          16m  <==

Step 3 — Installing a Helm Chart
$ helm install stable/kubernetes-dashboard --name dashboard-demo	<= 
	
	NAME:   dashboard-demo
	LAST DEPLOYED: Wed Sep 11 18:23:23 2019
	NAMESPACE: default
	STATUS: DEPLOYED

	RESOURCES:
	==> v1/Deployment
	NAME                                 READY  UP-TO-DATE  AVAILABLE  AGE
	dashboard-demo-kubernetes-dashboard  0/1    1           0          0s

	------

	NOTES:
	*********************************************************************************
	*** PLEASE BE PATIENT: kubernetes-dashboard may take a few minutes to install ***
	*********************************************************************************

	Get the Kubernetes Dashboard URL by running:
	  export POD_NAME=$(kubectl get pods -n default -l "app=kubernetes-dashboard,release=dashboard-demo" -o jsonpath="{.items[0].metadata.name}")
	  echo https://127.0.0.1:8443/
	  kubectl -n default port-forward $POD_NAME 8443:8443	

$ helm list
	NAME            REVISION        UPDATED                         STATUS          CHART                           APP VERSION     NAMESPACE
	dashboard-demo  1               Wed Sep 11 18:23:23 2019        DEPLOYED        kubernetes-dashboard-1.8.0      1.10.1          default

$  kubectl get services
	NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
	dashboard-demo-kubernetes-dashboard   ClusterIP   10.111.109.142   <none>        443/TCP   3m7s
	kubernetes                            ClusterIP   10.96.0.1        <none>        443/TCP   10d


$ helm upgrade dashboard-demo stable/kubernetes-dashboard --set fullnameOverride="dashboard"


$  kubectl get services
	NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
	dashboard    ClusterIP   10.111.108.205   <none>        443/TCP   15s
	kubernetes   ClusterIP   10.96.0.1        <none>        443/TCP   10d

$ kubectl proxy



$ kubectl cluster-info

	Kubernetes master is running at https://134.209.6.242:6443
	
	KubeDNS is running at https://134.209.6.242:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

----------------------------------------------------------------------------------------
https://134.209.6.242:6443
----------------------------------------------------------------------------------------
	{
	  "kind": "Status",
	  "apiVersion": "v1",
	  "metadata": {
		
	  },
	  "status": "Failure",
	  "message": "forbidden: User \"system:anonymous\" cannot get path \"/\"",
	  "reason": "Forbidden",
	  "details": {
		
	  },
	  "code": 403
	}
----------------------------------------------------------------------------------------


----------------------------------------------------------------------------------------
https://134.209.6.242:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
----------------------------------------------------------------------------------------
	{
	  "kind": "Status",
	  "apiVersion": "v1",
	  "metadata": {
		
	  },
	  "status": "Failure",
	  "message": "services \"kube-dns:dns\" is forbidden: User \"system:anonymous\" cannot get resource \"services/proxy\" in API group \"\" in the namespace \"kube-system\"",
	  "reason": "Forbidden",
	  "details": {
		"name": "kube-dns:dns",
		"kind": "services"
	  },
	  "code": 403
	}
----------------------------------------------------------------------------------------

# Roll Back(REVERT)

  $ helm list
	NAME            REVISION        UPDATED                         STATUS          CHART                           APP VERSION NAMESPACE
	dashboard-demo  2               Wed Sep 11 18:27:13 2019        DEPLOYED        kubernetes-dashboard-1.8.0      1.10.1      default
	
  $ helm rollback dashboard-demo 1

  $ helm delete dashboard-demo

  $ helm list --deleted	

  $ helm delete dashboard-demo --purge
	release "dashboard-demo" deleted











----------------------------------------------------------------------------------------
# Monitoring
----------------------------------------------------------------------------------------
https://github.com/do-community/doks-monitoring

Monitoring Stack on DigitalOcean Kubernetes
	Prometheus 
	Grafana  
	Alertmanager 
	
	
Step 2 — Creating the Monitoring Stack
	The DigitalOcean Kubernetes Monitoring Quickstart repo contains manifests for the 
	following monitoring, scraping, and visualization components:

  Prometheus <= is a time series database and monitoring tool that works by polling metrics 
			endpoints and scraping and processing the data exposed by these endpoints. 
			It allows you to query this data using PromQL, a time series data query 
			language. Prometheus will be deployed into the cluster as a StatefulSet 
			with 2 replicas that uses Persistent Volumes with DigitalOcean Block Storage. 
			In addition, a preconfigured set of Prometheus Alerts, Rules, and Jobs will 
			be stored as a ConfigMap. To learn more about these, skip ahead to the 
			Prometheus section of Configuring the Monitoring Stack.
  Alertmanager	<= usually deployed alongside Prometheus, forms the alerting layer of the stack, 
			handling alerts generated by Prometheus and deduplicating, grouping, and routing 
			them to integrations like email or PagerDuty. Alertmanager will be installed as 
			a StatefulSet with 2 replicas. To learn more about Alertmanager, consult Alerting 
			from the Prometheus docs.
  
  Grafana 	<= is a data visualization and analytics tool that allows you to build dashboards and 
			graphs for your metrics data. Grafana will be installed as a StatefulSet with one 
			replica. In addition, a preconfigured set of Dashboards generated by kubernetes-mixin 
			will be stored as a ConfigMap.

  kube-state-metrics <= is an add-on agent that listens to the Kubernetes API server and generates 
			metrics about the state of Kubernetes objects like Deployments and Pods. These metrics 
			are served as plaintext on HTTP endpoints and consumed by Prometheus. kube-state-metrics 
			will be installed as an auto-scalable Deployment with one replica.
  
  node-exporter	<= a Prometheus exporter that runs on cluster nodes and provides OS and hardware 
			metrics like CPU and memory usage to Prometheus. These metrics are also served as 
			plaintext on HTTP endpoints and consumed by Prometheus. node-exporter will be 
			installed as a DaemonSet.	












	$ su - netops
	$ mkdir doks-monitoring&& cd doks-monitoring
	$ git clone https://github.com:do-community/doks-monitoring.git

	$ export APP_INSTANCE_NAME=cluster-monitoring
	$ export NAMESPACE=monitoring
	$ export GRAFANA_GENERATED_PASSWORD="$(echo -n 'Test00!!' | base64)"

	$ kubectl create namespace "$NAMESPACE"

Step 2 — Creating the Monitoring Stack
	$ cd doks-monitoring

	netops@mc1~/doks-monitoring$ awk 'FNR==1 {print "---"}{print}' manifest/* \
	 | envsubst '$APP_INSTANCE_NAME $NAMESPACE $GRAFANA_GENERATED_PASSWORD' \
	 > "${APP_INSTANCE_NAME}_manifest.yaml"

	$ ls -l
	-rw-r--r-- 1 netops netops 225622 Sep 11 23:32 cluster-monitoring_manifest.yaml
	
	$ kubectl apply -f "${APP_INSTANCE_NAME}_manifest.yaml" --namespace "${NAMESPACE}"
		---------------------------------------------------------
		serviceaccount/alertmanager created
		configmap/cluster-monitoring-alertmanager-config created
		...
		service/cluster-monitoring-prometheus created
		statefulset.apps/cluster-monitoring-prometheus created
		---------------------------------------------------------
		
	$ kubectl get all

	$ kubectl get namespaces ( <= $ kubectl get ns )
	
	$ kubectl get pods --all-namespaces
	
		NAMESPACE     NAME                                                    READY   STATUS    RESTARTS   AGE
	kube-system   coredns-584795fc57-gjr8r                                1/1     Running   3          11d
	...
	monitoring    cluster-monitoring-alertmanager-0                       0/1     Pending   0          103s
	monitoring    cluster-monitoring-grafana-0                            0/1     Pending   0          102s
	monitoring    cluster-monitoring-kube-state-metrics-f9c6c6f7b-lmcpw   2/2     Running   0          102s
	monitoring    cluster-monitoring-node-exporter-4pp72                  1/1     Running   0          101s
	monitoring    cluster-monitoring-node-exporter-m6lpx                  1/1     Running   0          101s
	monitoring    cluster-monitoring-prometheus-0                         0/1     Pending   0          102s
	monitoring    cluster-monitoring-prometheus-1                         0/1     Pending   0          102s

	
Step 3 — Accessing Grafana and Exploring Metrics Data
kubectl port-forward --namespace ${NAMESPACE} ${APP_INSTANCE_NAME}-grafana-0 3000




----------------------------------------------------------------------------------------
# Terminology
----------------------------------------------------------------------------------------
kube-apiserver
		The Kubernetes API server validates and configures data for the api objects which 
		include pods, services, replicationcontrollers, and others. The API Server services 
		REST operations and provides the frontend to the cluster’s shared state through 
		which all other components interact.
		
	$ kube-apiserver [flags]

kubelet 
		the primary node agent that interacts with kube-apiserver to manage Pods and containers 
		on a node.

cAdvisor
		a node agent that discovers running containers and collects their CPU, memory, 
		filesystem, and network usage metrics.
		https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/#cadvisor




----------------------------------------------------------------------------------------
# Troubleshooting
----------------------------------------------------------------------------------------
STATUS: CrashLoopBackOff
https://sysdig.com/blog/debug-kubernetes-crashloopbackoff/

$ kubectl get pods
	NAME                        READY   STATUS             RESTARTS   AGE
	dashboard-95589d86d-jpjzd   0/1     CrashLoopBackOff   30         133m


$ kubectl get all

$ kubectl describe pod


# Check your Kubernetes deployments
https://medium.com/polarsquad/check-your-kubernetes-deployments-46dbfbc47a7c





# Deleting  Pods
https://stackoverflow.com/questions/33509194/command-to-delete-all-pods-in-all-kubernetes-namespaces
$ kubectl delete --all pods --namespace=monitoring
$ kubectl get ns( <= $ kubectl get namespaces)
$ kubectl delete --all monitoring
$ kubectl get -n monitoring all

	----------------------------------------------------------------------------------------
	for each in $(kubectl get ns -o jsonpath="{.items[*].metadata.name}" | grep -v kube-system);
	do
	  kubectl delete ns $each
	done
	----------------------------------------------------------------------------------------



# Debugging Pods
https://kubernetes.io/docs/tasks/debug-application-cluster/debug-pod-replication-controller/

# Get Nodes' CPU and Memory Info
$ kubectl get nodes -o yaml | egrep '\sname:|cpu:|memory:'
    name: mc1
      cpu: "2"
      memory: 3778092Ki
	...
	
$ kubectl get pods --all-namespaces | grep -i pending
	monitoring    cluster-monitoring-alertmanager-0                       0/1     Pending   0          10m
	monitoring    cluster-monitoring-grafana-0                            0/1     Pending   0          10m
	monitoring    cluster-monitoring-prometheus-0                         0/1     Pending   0          10m
	monitoring    cluster-monitoring-prometheus-1                         0/1     Pending   0          10m
	











----------------------------------------------------------------------------------------
kubectl
	kubectl controls the Kubernetes cluster manager.
	https://kubernetes.io/docs/reference/kubectl/overview/
----------------------------------------------------------------------------------------
$ kubectl <TAB>
annotate       certificate    create         explain        patch          scale
api-resources  cluster-info   delete         expose         plugin         set
api-versions   completion     describe       get            port-forward   taint
apply          config         diff           kustomize      proxy          top
attach         convert        drain          label          replace        uncordon
auth           cordon         edit           logs           rollout        version
autoscale      cp             exec           options        run            wait

Basic Commands (Beginner):
  create         Create a resource from a file or from stdin.
  expose         Take a replication controller, service, deployment or pod and expose it as a new

Kubernetes Service
  run            Run a particular image on the cluster
  set            Set specific features on objects

Basic Commands (Intermediate):
  explain        Documentation of resources
  get            Display one or many resources
  edit           Edit a resource on the server
  delete         Delete resources by filenames, stdin, resources and names, or by resources and

label selector

Deploy Commands:
  rollout        Manage the rollout of a resource
  scale          Set a new size for a Deployment, ReplicaSet, Replication Controller, or Job
  autoscale      Auto-scale a Deployment, ReplicaSet, or ReplicationController

Cluster Management Commands:
  certificate    Modify certificate resources.
  cluster-info   Display cluster info
  top            Display Resource (CPU/Memory/Storage) usage.
  cordon         Mark node as unschedulable
  uncordon       Mark node as schedulable
  drain          Drain node in preparation for maintenance
  taint          Update the taints on one or more nodes

Troubleshooting and Debugging Commands:
  describe       Show details of a specific resource or group of resources
  logs           Print the logs for a container in a pod
  attach         Attach to a running container
  exec           Execute a command in a container
  port-forward   Forward one or more local ports to a pod
  proxy          Run a proxy to the Kubernetes API server
  cp             Copy files and directories to and from containers.
  auth           Inspect authorization

Advanced Commands:
  diff           Diff live version against would-be applied version
  apply          Apply a configuration to a resource by filename or stdin
  patch          Update field(s) of a resource using strategic merge patch
  replace        Replace a resource by filename or stdin
  wait           Experimental: Wait for a specific condition on one or many resources.
  convert        Convert config files between different API versions
  kustomize      Build a kustomization target from a directory or a remote url.

Settings Commands:
  label          Update the labels on a resource
  annotate       Update the annotations on a resource
  completion     Output shell completion code for the specified shell (bash or zsh)

Other Commands:
  api-resources  Print the supported API resources on the server
  api-versions   Print the supported API versions on the server, in the form of "group/version"
  config         Modify kubeconfig files
  plugin         Provides utilities for interacting with plugins.
  version        Print the client and server version information

Usage:
  kubectl [flags] [options]




# Managing Compute Resources for Containers
https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
The expression 0.1 is equivalent to the expression 100m






# Interactive Tutorial - Exploring Your App
https://kubernetes.io/docs/tutorials/kubernetes-basics/explore/explore-interactive/



kubectl cluster-info
kubectl config get-contexts
kubectl get pods --namespace kube-system










































































































