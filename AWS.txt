AWS Regions

Region   Name	Region	Endpoint
US East (N. Virginia)	us-east-1	
US West (N. California)	us-west-1	
US West (Oregon)	    us-west-2


--------------------------------------------------------------------------------------------
### AWS CLI ### 
--------------------------------------------------------------------------------------------

$ sudo pip install awscli --ignore-installed six 		<= version 1.16, it supports EKS
--------------------------------------------------------------------------------------------
	# Alternative Installation using CentOS Repository YUM
	https://devopsmates.com/install-configure-aws-cli-amazon-web-services-command-line-interface/
	yum install epel-release –y
	yum install python-pip –y
	pip install awscli
	pip install –upgrade awscli
	aws –version							<=1.14  !Not supporting the ESK(starts on 1.15.32)yet
	aws help 
--------------------------------------------------------------------------------------------

$ aws --version
	aws-cli/1.16.115 Python/3.6.7 Linux/3.10.0-957.1.3.el7.x86_64 botocore/1.12.105   <= EKS Works

$ aws configure
	AWS Access Key ID [None]: 
	AWS Secret Access Key [None]: 
	Default region name [None]: us-west-2  <= Oregon
	Default output format [None]: json
	
$ aws configure --profile=clusterAdmin					<= Specific AWS USER account credential
	AWS Access Key ID [****************UVFA]:
	AWS Secret Access Key [****************KJ2l]:
	Default region name [us-region-2]: us-west-2		<= Oregon
	Default output format [None]: json					<= ONLY 'JSON' WORKS!!!! 
-------------------------------------------------------------------------------
# Configuration test
-------------------------------------------------------------------------------
$ aws s3 ls
	2017-02-27 20:39:36 backup-jenkins-sign
	2017-05-22 16:10:49 mobile-xpromo
-------------------------------------------------------------------------------
# Canonical ID #
-------------------------------------------------------------------------------
$ aws s3api list-buckets
{
    "Owner": {
        "DisplayName": "aws-gdpr",
        "ID": "25c4bb815a498aa63ffee0cedfd35798858a12cc0897ef268fa0073ad729ef2e"  <= Canonical ID
    },

--------------------------------------------------------------------------------------------



##############################################################################
### EKS  (Elastic Kubernetes Service)
#   Training: https://www.linkedin.com/learning/running-kubernetes-on-aws-eks
##############################################################################
Pre-EKS Deployment
	1. AWS CLI
	2. Kubectl CLI
	3. BASH CLI
Pre-AWS EKS Deployment
	1. IAM Configuration
		- Create a ROLE defined with EKS Permissions
		- EKS:* Policy applied to user/group
		
	2. VPC create for ESK use
		- Create ESK VPC using CloudFormation

EKS Core Service
	1. Create cluster 'controle plane'(system configuration and management)
	2. Establish kubectl credentials
		- Install aws-iam-authenticator and kubectl
		- aws eks update-kubeconfig --name '#Rename to cluster's_name'
Create Worker Nodes	
	1. Create an autoscaling group of nodes with CloudFormation
	2. Create node auth with 'kubectl apply -f aws-auth-cm.yaml'
	
Wait for the nodes to register
	1. 'kubectl get nodes -w'
	
Ensure you can create an ELB
	1. 'aws iam create-service-linked-role --aws-service-name elasticloadbalancing.amazonaws.comaws
	
Use your Kubernetes Envrionment
	

--------------------------------------------------------------------------------------------
# EKS Support Regions 
--------------------------------------------------------------------------------------------
https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/
us-west-2 (Oregon), us-east-1 (N. Virginia), us-east-2 (Ohio)
Ireland, Frankfurt, London,	Paris, Stockholm, Singapore, Tokyo, Sydney, Seoul, Mumbai
--------------------------------------------------------------------------------------------

--------------------------------------------------------------------------------------------
### Gethering ESK Setup Info ###
--------------------------------------------------------------------------------------------
IAM-ROLE-ARN: arn:aws:iam::688595016292:role/Cluster_EKS_Role

VPC-ID:vpc-0121526bc433d8e2b
SECURITY-GROUP-ID:sg-09222c96502064a3a
SUBNET-IDS:subnet-09442239f4e596b6d,subnet-069fb4ed48718a9f7,subnet-05a8b3907455065ce

NODE-ROLE-ARN:
LABEL-NODE-ROLE-ARN:
USER_ARN:


--------------------------------------------------------------------------------------------
1. Create IAM Accounts and Policy for CRUD operations 
--------------------------------------------------------------------------------------------
  Create 2 Policies for EKS and CloudFormation Admins
	AWS -> IAM -> Policies -> Create Policy
		=> AdminEKSPolicy & AdminCloudFormationPolicy

  # Name: AdminEKSPolicy				<= Kubernetes 
----------------------------------------------
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",			<= Full permisson
            "Action": [
                "eks:*"					<= ARN EKS
            ],
            "Resource": "*"
        }
    ]
}
----------------------------------------------
  # Name: AdminCloudFormationPolicy			<= CM Tool
----------------------------------------------
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",			<= Full permisson
            "Action": "*",
            "Resource": "*"				<= ARN ALL
        }
    ]
}
----------------------------------------------

Create Roll 
	AWS -> IAM -> Roles -> Create Role -> AWS Service -> EKS -> Add 
	  - AmazonEKSServicePolicy 			<= From Existing Policy
      - AmazonEKSClusterPolicy 			<= From Existkuing Policy
	Create -> Name: ClusterEKSRoll

	IAM-ROLE-ARN: arn:aws:iam::6...2:role/Cluster_EKS_Role


--------------------------------------------------------------------------------------------
IAM: Creating ClusterAdmin and ClusterUser accounts
--------------------------------------------------------------------------------------------

User #1:  clusterAdmin

  IAM -> Username: clusterAdmin -> Access Type: both Programmatic and console Access 
	  -> Password -> Attach 4 existing Policies ->  Download CSV
					AdminEKSPolicy					<= Newly created by me
					AdminCloudFormationPolicy		<= Newly created by me
					AmazonEKSServicePolicy 			<= From Existing   Policy
					AmazonEKSClusterPolicy 			<= From Existkuing Policy
					
 - eks admin policy
 - k8s admin "system:master" group
 


User #2: clusterUser

	IAM -> Username: clusterAdmin -> Access Type: both Programmatic and console Access 
		-> Password -> Attach 4 existing Policies ->  Download CSV


  Add policies: 
 - no IAM policies
 - k8s admin "system:master" group
 - AdminEKSPolicy					<= NEW

--------------------------------------------------------------------------------------------
# CloudFormation - Create a Stack VPC Template From S3
--------------------------------------------------------------------------------------------
1. Check Region: us-west-02(Orgegon)

2. AWS Colsone -> ESK -> Create Cluster -> Specify an AWS S3 template URL
	https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2018-08-30/amazon-eks-vpc-sample.yaml

  -> Stack name: classCluster (or classEKSVPC) 
	VPCBlock: 192.168.0.0/16
	Subnet01Block: subnet1(192.168.64.0./18...)
	Subnet02Block: subnet2(192.168.128.0./18...)
	Subnet03Block: subnet3(192.168.192.0./18...)

  -> Rest Default to create
  -> From Output
		Key				Value					Description	       Export Name
		SecurityGroups	sg-09222c96502064a3a		
		VpcId			vpc-0121526bc433d8e2b		
		SubnetIds		subnet-09442239f4e596b6d,subnet-069fb4ed48718a9f7,subnet-05a8b3907455065ce 
	
Copy from output:
	IAM-ROLE-ARN: arn:aws:iam::688595016292:role/Cluster_EKS_Role
	
	VPC-ID: vpc-0121526bc433d8e2b
	SECURITY-GROUP-ID:s g-09222c96502064a3a
	SUBNET-IDS: subnet-09442239f4e596b6d,subnet-069fb4ed48718a9f7,subnet-05a8b3907455065ce 

-------------------------------------------------------------------------------
# Remote Tools 'Kubectl', 'aws-iam-authenticator', 'AWS CLI'
-------------------------------------------------------------------------------
  1. Install "kubectl" 
	https://kubernetes.io/docs/tasks/tools/install-kubectl/
-------------------------------------------------------------------------------
  Linux:
	curl -LO https://storage.googleapis.com/kubernetes-release/release/\
		$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
  MacOS:
	curl -LO https://storage.googleapis.com/kubernetes-release/release/\
		$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl

	$ chmod + x kubectl
	$ mv kubectl /usr/local/bin
	# $ source .bash_profile				<= If kubectl not works, reload profile
	
	$ kubectl version --short --client
	
	---------------------------------------------------
	# Enabling shell autocompletion
	---------------------------------------------------
	https://kubernetes.io/docs/tasks/tools/install-kubectl/#enabling-shell-autocompletion
	$ kubectl completion -h
	$ yum install bash-completion -y
	$ source <(kubectl completion bash)
	$ echo "source <(kubectl completion bash)" >> ~/.bashrc
	
	$ kubectl  <TAB>
	  annotate       autoscale      cordon         drain          label          proxy          taint
	  api-resources  certificate    cp             edit           logs           replace        top
	  api-versions   cluster-info   create         exec           options        rollout        uncordon
	  apply          completion     delete         explain        patch          run            version
	  attach         config         describe       expose         plugin         scale          wait
	  auth           convert        diff           get            port-forward   set

	
-------------------------------------------------------------------------------
  2. Download "aws-iam-authenticator" binary:
-------------------------------------------------------------------------------
	https://docs.aws.amazon.com/eks/latest/userguide/configure-kubectl.html
	https://github.com/kubernetes-sigs/aws-iam-authenticator
	-------------------------------------------------------------------------------
  Linux:
	curl -sLO https://amazon-eks.s3-us-west-2.amazonaws.com/1.10.3/2018-07-26/bin/linux/amd64/aws-iam-authenticator
  MacOS:
	curl -sLO https://amazon-eks.s3-us-west-2.amazonaws.com/1.10.3/2018-07-26/bin/darwin/amd64/aws-iam-authenticator
	
  $ chmod + x 	aws-iam-authenticator
  $ mv aws-iam-authenticator /usr/lcoal/bin   			<= echo $PATH location
  
-------------------------------------------------------------------------------
  3. Install "AWS CLI" 
	https://docs.aws.amazon.com/cli/latest/userguide/installing.html
-------------------------------------------------------------------------------
	$ sudo pip install awscli --ignore-installed six 		<= 1.16 EKS Works
	$ pip install awscli --upgrade --user
-------------------------------------------------------------------------------
	$ aws --version
		aw s-cli/1.16.115 Python/3.6.7 Linux/3.10.0-957.1.3.el7.x86_64 botocore/1.12.105

	# AWS sts (Security Token Service)
	$ aws sts get-caller-identity --output text --query 'Account'
		688595016292		<= account ID
	# get your account ID
		ACCOUNT_ID=$(aws sts get-caller-identity --output text --query 'Account')

	$ aws eks update-kubeconfig --name classEKS

-------------------------------------------------------------------------------
# Configuration on Linux Shell 
# Add to Environment Variable
-------------------------------------------------------------------------------
  # Config CLI for AWS and Kubectl
  # AWS CLI
  $ aws configure									<= Setup or update
	  AWS Access Key ID [****************UVFA]:
	  AWS Secret Access Key [****************KJ2l]:
	  Default region name [us-west-2]: 				<= Oregon
	  Default output format [json]: 				<= Only json works
   
    SYNOPSIS
     aws configure [--profile profile-name]  
	
	$ aws configure --profile=clusterAdmin
	
	$ export AWS_PROFILE=clusterAdmin

	$ env | grep AWS_PROFILE									<= If no, add 

***	$ echo "export AWS_PROFILE=clusterAdmin" >> .bash_profile	<= .bash_profile <= login shell 
																<= .bashrc 		 <= after login user shell
	
***	$ aws eks update-kubeconfig --name classEKS					<= Updated CLI
	
	# $ aws eks --region us-west-2 update-kubeconfig --name classEKS	<= Old CLI
	  => Updated context arn:aws:eks:us-west-2:688595016292:cluster/classCluster in /home/awseks/.kube/config

	$ aws eks list-clusters			<= Get EKS cluster info
	{
		"clusters": [
			"classEKS"				<= AWS EKS Cluster Name
		]
	}



-------------------------------------------------------------------------------
# EKS is Kubernetes Master Server
# Create a EKS Cluster from AWS Console
-------------------------------------------------------------------------------
AWS -> EKS -> Create Cluster -> 

# A New Cluster configuration(A new Kubernetes SERVER)
	Cluster name: classEKS
	Kubernetes Version -> 1.11   				<= Latest
	Role Name: Cluster_EKS_Role					<= grep from Role creation

# Networking	
	VPC -> 	vpc-xxx(192.168.0.0/16..)
	Subnets	-> subnet1(192.168.64.0./18...)
			   subnet2(192.168.128.0./18...)
			   subnet3(192.168.192.0./18...)	
			   
# Security groups 
	sg-09222c96502064a3a
	
>>> Create <<<	

-------------------------------------------------------------------------------
# Reigster cluster 'classEKS' to Kubectl
-------------------------------------------------------------------------------

# Check the cluster list
$ aws eks list-clusters
	{
		"clusters": [
			"classEKS"
		]
	}
	
# Register
$ aws eks update-kubeconfig --name classEKS
	Added new context arn:aws:eks:us-west-2:688595016292:cluster/classEKS to /home/awseks/.kube/config


# check if kubeclt actually communicating with 'classEKS'
$ kubectl get pods
	No resources found.						<= Good sign, no error
	
$ kubectl get nodes
	No resources found.

# test if pod can create apply hostname.yaml
$ kubectl apply -f hostname.yaml				
	deployment.extensions/hostname-v1 created	<= ok
	service/hostname-v1 created					<= ok

$ kubectl get pods
	NAME                           READY   STATUS    RESTARTS   AGE
	hostname-v1-56bc754656-njdgp   0/1     Pending   0          13s		<= In order but no workers to deploy
------------------------------------------
	# hostname.yaml
------------------------------------------
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: hostname-v1
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: hostname-v1
        version: v1
    spec:
      containers:
      - image: rstarmer/hostname:v1
        imagePullPolicy: Always
        name: hostname
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: hostname-v1
  name: hostname-v1
spec:
  ports:
  - name: web
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: hostname-v1
----------------------------------------

-------------------------------------------------------------------------------
# CloudFormation		<= for WORKER NODES Addition
# Adding Wokers Nodes(No-Labeled Nodes) to EKS 
-------------------------------------------------------------------------------

AWS -> CloudFormation -> Create a New stack -> Specify an Amazon S3 template URL
	https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2018-08-30/amazon-eks-nodegroup.yaml
	-> Stack Name: eksNolabeledWorkerNodes
	-> Cluster Name: noLabeledCluster
	-> ClusterControlPlaneSecurityGroup: Learning-EKS-VPC
	-> NodeGroupName: noLabeledworkerNodes
	-> NodeAutoScaling size: 1~3				<= Min ~ max size of Node Group AutoScaleGroup.
	-> NodeVolumeSize: 20 						<= default
	-> NodeImageId: ami-0c28139856aaf9c3b		<= us-west-2(Oregon)<- ESK Optimized AMI
	-------------------------------------------------------------------------------
	# Amazon EKS-Optimized AMI List
	https://docs.aws.amazon.com/eks/latest/userguide/eks-optimized-ami.html
	-------------------------------------------------------------------------------
	-> KeyName:eksAdmin				<= EC2 access PEM key (EC2 -> Create a key Pair)

	-> Worker Network Configuration
		VpcId	: vpc-xxx(192.168.0.0/16..)					<= EKS' classCluster VPC
		Subnets	: subnet1(192.168.64.0./18...)				<= EKS' classCluster subnets
				  subnet2(192.168.128.0./18...)
				  subnet3(192.168.192.0./18...)			

	-> Options:  											<= pass on this		
	-> Check on Agree then Click on Create!
	
	eksNolabeledWorkerNodes 2019-03-04 CREATE_IN_PROGRESS NOT_CHECKED Amazon EKS - Node Group 

-------------------------------------------------------------------------------
# After No Labeled Workder Nodes creatation is done, get eksNolabeledWorkerNodes' 
	'ARN' and add to 'rolearn' in order to the Kubectl accesses the 'eksNolabeledWorkerNodes'
    -> CouldFormation -> Stacks -> chose 'eksNolabeledWorkerNodes' -> Stack Details 
	-> Outputs -> copy value : arn:aws:iam::6...2:role/eksNolabeledWorkerNodes-NodeInstanceRole
	
-------------------------------------------------------------------------------
 $ vi aws-auth-cm.yaml
-------------------------------------------------------------------------------
apiVersion: v1
kind: ConfigMap
metadata:
  name: aws-auth
  namespace: kube-system
data:
  mapRoles: |
    - rolearn: arn:aws:iam::6...2:role/eksNolabeledWorkerNodes-NodeInstanceRole-14RJGE47079RC
    #- rolearn: <ARN of instance role (not instance profile)>
      username: system:node:{{EC2PrivateDNSName}}
      groups:
        - system:bootstrappers
        - system:nodes
-------------------------------------------------------------------------------

$ kubectl apply -f aws-auth-cm.yaml
	configmap/aws-auth created

$ kubectl config view

$ kubectl get nodes
	NAME                                            STATUS   ROLES    AGE   VERSION
	ip-192-168-120-42.us-west-2.compute.internal    Ready    <none>   58s   v1.11.5
	ip-192-168-165-134.us-west-2.compute.internal   Ready    <none>   1m    v1.11.5
	ip-192-168-201-63.us-west-2.compute.internal    Ready    <none>   1m    v1.11.5
-------------------------------------------------------------------------------
# Now it is deployed into the Nodes so the POD is Running
-------------------------------------------------------------------------------
$ kubectl get pods
	NAME                           READY   STATUS    RESTARTS   AGE
	hostname-v1-56bc754656-njdgp   1/1     Running   0          1h
-------------------------------------------------------------------------------
# AutoScalingGroup_Policy
-------------------------------------------------------------------------------
	AWS -> EC2 -> AutoScaling -> Auto Scaling Group -> Choose: eksNolabeledWorkerNodes
	-> Scaling Policies -> 
	------------------------------------------------------------------
	Name 	Launch Config.. 	 Instances Desired Min Max Availability Zones
	eks..	eksNolabeledWorkerNodes  3		3      1    3  us-west-02a,b,c
	------------------------------------------------------------------
	Add Policy  -> Name: scale-cpu-70 
				-> metric type: Ave CPU
				-> Target Value: 70
				-> Instances need: none
				- Disable scale-in: none
				
	>>> CREATE <<<

  # After AutoScalePolicy creation, it immediatly reducing number of Nodes from 3 to
	$ kubectl get nodes
	NAME                                           STATUS   ROLES    AGE   VERSION
	ip-192-168-120-42.us-west-2.compute.internal   Ready    <none>   29m   v1.11.5
	ip-192-168-201-63.us-west-2.compute.internal   Ready    <none>   29m   v1.11.5

	# Scaled down to ONLY 1****
	$kubectl get nodes
	NAME                                           STATUS   ROLES    AGE   VERSION
	ip-192-168-120-42.us-west-2.compute.internal   Ready    <none>   30m   v1.11.5

-------------------------------------------------------------------------------
# Differenciate Workers - Video 12
# Auto Labeling Nodes during Auto Scaling since number of nodes are keep changing 
	manually labeling nodes update is impossible
	
	Manual update: $ kubectl lab nodes <node-name> <label-key>=<label-value>
-------------------------------------------------------------------------------

AWS -> CloudFormation -> Create Stack -> Specify template -> Template source -> Next
	https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2018-08-30/amazon-eks-nodegroup.yaml
--------------------------------------------
# checking EKS Cluster Name
$ aws eks list-clusters
	{
		"clusters": [
			"classEKS"    <== Cluster Name   <== USE THIS!!
		]
	}
--------------------------------------------
  # Specify stack details
	Stack name: labeledNodes
	EKS Cluster
		ClusterName: classEKS				<===!!!  If wrong, CAN't JOIN EKS Cluster!!!!
		ClusterControlPlaneSecurityGroup: Learning-EKS-VPC....3a)
	Worker Node Configuration
		NodeGroupName: labeledNodes
		NodeAutoScalingGroupMinSize: 1
		NodeAutoScalingGroupMaxSize: 3
		NodeInstanceType: t2.small
		NodeImageID: ami-0c28139856aaf9c3b		<= us-west-2(Oregon)<- ESK Optimized AMI
		KeyName: eksAdmin						<= Key Pair
		
		# A script pass to the argument and add '--node-labels' for labeling #
		BootstrapArguments:--kubelet-extra-args '--node-labels "nodetype=generalpurpose"'	
			
	
	Worker Network Configuration
		VpcId:vpc-xxx(192.168.0.0/16..)
		Subnets: subnet1(192.168.64.0./18...)
				 subnet2(192.168.128.0./18...)
				 subnet3(192.168.192.0./18...)	

  # Go to labelNodes -> Outputs -> get the ARN 
	
-------------------------------------------------------------------------------				 
# Edit and add 'Label Nodes ARN' to aws-auth-cm+NodesLabel.yaml
-------------------------------------------------------------------------------				 
apiVersion: v1
kind: ConfigMap
metadata:
  name: aws-auth
  namespace: kube-system
data:
  mapRoles: |
	# Without Label Nodes
    - rolearn: arn:aws:iam::688595016292:role/eksWorkerNodesStack-NodeInstanceRole-14RJGE47079RC
      username: system:node:{{EC2PrivateDNSName}}
      groups:
        - system:bootstrappers
        - system:nodes
	# Label Nodes Enabled Cluster	
    - rolearn: 	arn:aws:iam::688595016292:role/labelNodes-NodeInstanceRole-8QKQNDGMVNQ5
      username: system:node:{{EC2PrivateDNSName}}
      groups:
        - system:bootstrappers
        - system:nodes		
-------------------------------------------------------------------------------	
$ kubectl apply -f aws-auth-cm+NodesLabel.yaml
# System should apply for TWO different ROLES 'No Label' and 'Label Enabled' Clusters

$ kubectl get nodes
	  NAME                                            STATUS   ROLES    AGE   VERSION
new=> ip-192-168-112-219.us-west-2.compute.internal   Ready    <none>   8m    v1.11.5
new=> ip-192-168-137-151.us-west-2.compute.internal   Ready    <none>   7m    v1.11.5
new=> ip-192-168-199-194.us-west-2.compute.internal   Ready    <none>   6m    v1.11.5

old=> ip-192-168-120-42.us-west-2.compute.internal    Ready    <none>   19h   v1.11.5



-------------------------------------------------------------------------------	
# $ vi hostnameLabeled.yaml
-------------------------------------------------------------------------------	

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: hostname-v2
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: hostname-v2
        version: v2
    spec:
      containers:
      - image: rstarmer/hostname:v2
        imagePullPolicy: Always
        name: hostname
      nodeSelector:								# <=
        nodetype: generalpurpose				# <= 
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: hostname-v2
  name: hostname-v2
spec:
  ports:
  - name: web
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: hostname-v2
-------------------------------------------------------------------------------	
$ kubectl apply -f hostnameLabeled.yaml

$ kubectl get pods
		NAME                           READY   STATUS    RESTARTS   AGE
Old=>	hostname-v1-56bc754656-j8mwh   1/1     Running   0          19h
new=>	hostname-v2-6499cb8cc8-w6w4s   1/1     Running   0          1m			
				 v2 <= renamed with V2

-------------------------------------------------------------------------------
$kubectl describe pod hostname-v2-6499cb8cc8-w6w4s

Name:               hostname-v2-6499cb8cc8-w6w4s
Namespace:          default
Priority:           0
PriorityClassName:  <none>
Node:               ip-192-168-199-194.us-west-2.compute.internal/192.168.199.194
Start Time:         Wed, 06 Mar 2019 11:38:03 -0800
Labels:             app=hostname-v2						## Labels
                    pod-template-hash=2055764774
                    version=v2
Annotations:        <none>
Status:             Running
IP:                 192.168.201.177
Controlled By:      ReplicaSet/hostname-v2-6499cb8cc8
Containers:
  hostname:
    Container ID:   docker://61ce17272e9
    Image:          rstarmer/hostname:v2
    Image ID:       docker-pullable://rstarmer/hostname@sha256:e0
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Wed, 06 Mar 2019 11:38:10 -0800
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rgwhg (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True
Volumes:
  default-token-rgwhg:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-rgwhg
    Optional:    false
QoS Class:       BestEffort
------------------------------------------
Node-Selectors:  nodetype=generalpurpose		<= This is what we are looking for
------------------------------------------
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age    From                    Message
  ----    ------     ----   ----                    -------


-------------------------------------------------------------------------------
# Creating Storage Class - Video 14
Read: https://kubernetes.io/docs/concepts/storage/storage-classes/#aws-ebs
type: io1, gp2, sc1, st1. See AWS docs for details. Default: gp2.
-------------------------------------------------------------------------------
- By default EKS doesn't have any storage classes defined, and we need to 
	have a storage class model in order to be able to create 'persistent storage.'
=> Simply enable the 'storage class connection' to the underlying EBS service.

- Create a "standard" EBS volume to set as DEFAULT.

----------------------------------------------------
# General Purpose Storage
$ kubectl apply -f generalPurpose-storage.yaml
----------------------------------------------------
$ vi generalPurpose-storage.yaml
----------------------------------------------------

kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: gp2
  annotations:
    storageclass.kubernetes.io/is-default-class: 'true'
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2			
reclaimPolicy: Retain			<= Persistent EBS Volume Retain
mountOptions:
  - debug

----------------------------------------------------
# Fast Storage
# Creating some Fast (100 iops/GB) SSD Storage
$ kubectl apply -f fast-storage.yaml
----------------------------------------------------
$ vi fast-storage.yaml
----------------------------------------------------
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: fast-100
provisioner: kubernetes.io/aws-ebs
parameters:
  type: io1							<= io1 type
  iopsPerGB: "100"					<= 20,000 iops is Max
reclaimPolicy: Retain				<= Persistent EBS Volume Retain
mountOptions:
  - debug
-------------------------------------------------------------------------------
$ kubectl create -f fast-storage.yaml
	storageclass.storage.k8s.io/fast-100 created

$ kubectl create -f generalPurpose-storage.yaml		
	Error from server (AlreadyExists): error when creating 	
	"generalPurpose-storage.yaml": storageclasses.storage.k8s.io "gp2" already exists


$ kubectl get storageclasses
	NAME            PROVISIONER             AGE
	fast-100        kubernetes.io/aws-ebs   1m
	gp2 (default)   kubernetes.io/aws-ebs   22h

-------------------------------------------------------------------------------
# Storage Persistent Claim	- Video 15 
# Mapping Storage
-------------------------------------------------------------------------------


-------------------------------------------------------------------------------
$ vi hostname-volume.yaml
-------------------------------------------------------------------------------
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: hostname-volume
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: hostname-volume
        version: v1
    spec:
      volumes:
      - name: hostname-pvc					#PVC - persist volume claim
        persistentVolumeClaim:
          claimName: hostname-pvc
      containers:
      - image: rstarmer/hostname:v1
        imagePullPolicy: Always
        name: hostname
        volumeMounts:
          - mountPath: "/www"
            name: hostname-pvc
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: hostname-volume
  name: hostname-volume
spec:
  ports:
  - name: web
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: hostname-volume
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: hostname-pvc
spec:
  storageClassName: gp2
  accessModes:
    - ReadWriteOnce					# Can't share 'ReadWriteOnce' 
  resources:
    requests:
      storage: 1Gi
-------------------------------------------------------------------------------
$ kubectl apply -f hostname-volume.yaml
	deployment.extensions/hostname-volume created
	service/hostname-volume created
	persistentvolumeclaim/hostname-pvc created

$ kubectl get pv			# Persistent Volume
  NAME     CAPACITY  ACCESS MODES  RECLAIM POLICY STATUS CLAIM             STORAGECLASS   AGE
  pvc-60.d4  1Gi      RWO            Delete       Bound  default/hostname-pvc   gp2       19s

$ kubectl get pvc -o wide
  NAME           STATUS   VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS   AGE
  hostname-pvc   Bound    pvc-...   1Gi        RWO            gp2            3m

-------------------------------------------------------------------------------
$ kubectl get pod -l app=hostname-volume -o jsonpath={.items..metadata.name}
  hostname-volume-8479ffdd6f-nhjv2

$ kubectl exec -it $(kubectl get pod -l app=hostname-volume -o jsonpath={.items..metadata.name}) -- df -h /www

	Filesystem      Size  Used Avail Use% Mounted on
	/dev/xvdbr      976M  2.6M  958M   1% /www

-------------------------------------------------------------------------------
### Clean Up + Persistent Volumes ##
-------------------------------------------------------------------------------
clean up hostname-volume "stack" with:

$ kubectl delete -f hostname-volume.yaml
-------------------------------------------------------------------------------
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: hostname-volume
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: hostname-volume
        version: v1
    spec:
      volumes:
      - name: hostname-pvc
        persistentVolumeClaim:
          claimName: hostname-pvc
      containers:
      - image: rstarmer/hostname:v1
        imagePullPolicy: Always
        name: hostname
        volumeMounts:
          - mountPath: "/www"
            name: hostname-pvc
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: hostname-volume
  name: hostname-volume
spec:
  ports:
  - name: web
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: hostname-volume
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: hostname-pvc
spec:
  storageClassName: gp2
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
-------------------------------------------------------------------------------
 
$ kubectl delete -f hostname-volume.yaml
	deployment.extensions "hostname-volume" deleted
	service "hostname-volume" deleted
	persistentvolumeclaim "hostname-pvc" deleted

# To Check  EC2 -> Volume 
  kubernetes-dynamic-pvc-60069873-..

$ kubectl get pv
  No resources found.

$ kubectl delete pv $(kubectl get pv -o jsonpath={.items..metadata.name})


-------------------------------------------------------------------------------
# Networking  (File > 03-05)
-------------------------------------------------------------------------------
Networking in EKS uses the VPC-CNI project to use the AWS VPC network model 
to provide connectivity across the cluster.  
This is more efficient than having another layer of networking (e.g. Flannel, 
Calico, Weave, etc.) deployed as an overlay on top of the system, and maps 
perfectly into the VPC environment, using the VPC network management and IPAM 
services to support address management further improving the efficiency of 
the overall Kubernetes deployment.
-----------------------------------------------------------
# Deploy Alpine image
-----------------------------------------------------------
$ kubectl run --image alpine alpine sleep 3600
kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed 
in a future version. 
Use 'kubectl run --generator=run-pod/v1' or 'kubectl create' instead.
deployment.apps/alpine created

$ kubectl get pods
	NAME                           READY   STATUS    RESTARTS   AGE
	alpine-6b9858595b-7zncb        1/1     Running   0          1m	<= Alpine image
	hostname-v1-56bc754656-j8mwh   1/1     Running   0          1d
	hostname-v2-6499cb8cc8-w6w4s   1/1     Running   0          5h

$IPs=`kubectl get pod $(kubectl get pod -l run=alpine -o \
	  jsonpath={.items..metadata.name}) -o yaml | awk '/IP/ {print $2}'`

$ echo $IPs
	192.168.137.151 192.168.133.249

$ for i in $IPs; do kubectl exec -it $(kubectl get pod -l run=alpine -o \
	jsonpath={.items..metadata.name})  traceroute $i ; done

	traceroute to 192.168.137.151 (192.168.137.151), 30 hops max, 46 byte packets
	1  192.168.137.151 (192.168.137.151)  0.006 ms  0.007 ms  0.002 ms
	
	traceroute to 192.168.133.249 (192.168.133.249), 30 hops max, 46 byte packets
	1  alpine-6b9858595b-7zncb (192.168.133.249)  0.005 ms  0.002 ms  0.002 ms



-------------------------------------------------------------------------------
# Load Balancing and Ingress( Adding ingress is a Kubernetes function)
-------------------------------------------------------------------------------
We'll add the 'Traefik load balancer' as an ingress function, and make use of 
the EKS integration with Amazon ELB to enable external access.

As ingress can route based on DNS, we can also do a little DNS manipulation to 
get traffic routed to our resources.

1) Since we're using 1.10.0 Kubernetes (or newer) we'll need to make sure we have 
   a 'cluster role binding' for the services to use(Much like IAM):

$ kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-rbac.yaml

  clusterrole.rbac.authorization.k8s.io/traefik-ingress-controller created
  clusterrolebinding.rbac.authorization.k8s.io/traefik-ingress-controller created

2) We'll leverage the deployment model for our ingress controller, as we don't 
   necessarily want to bind host address, and would rather have the ingress transit 
   through the normal kube-proxy functions (note that we're changing the default 
   "NodePort" type to "LoadBalancer"):

$ kubectl apply -f <(curl -so - https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-deployment.yaml\
					| sed -e 's/NodePort/LoadBalancer/')
  serviceaccount/traefik-ingress-controller created
  deployment.extensions/traefik-ingress-controller created
  service/traefik-ingress-service created

# Get Services
$ kubectl get svc
	NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
	hostname-v1   ClusterIP   10.100.81.10    <none>        80/TCP    1d
	hostname-v2   ClusterIP   10.100.148.78   <none>        80/TCP    5h
	kubernetes    ClusterIP   10.100.0.1      <none>        443/TCP   1d

$ kubectl get svc -n kube-system
NAME                      TYPE           CLUSTER-IP     EXTERNAL-IP                       PORT(S)                       AGE
kube-dns                  ClusterIP      10.100.0.10    <none>                            53/UDP,53/TCP                 1d
traefik-ingress-service   LoadBalancer   10.100.35.58   a...us-west-2.elb.amazonaws.com   80:32575/TCP,8080:30184/TCP   2m


-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
-------------------------------------------------------------------------------

-------------------------------------------------------------------------------


-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
# Debug	connecting AWS EKS clusterAdmin
  
  # Check Who's ID is used for connection 
  $ aws sts get-caller-identity			<= AWS Security Token Service (STS)
	{
      "UserId": "AIDAJC4NG62FQHAPKEYRK",
      "Account": "688595016292",
      "Arn": "arn:aws:iam::688595016292:user/clusterAdmin"
	}

  $ kubectl config view
    apiVersion: v1
	clusters:
		- cluster:
			certificate-authority-data: DATA+OMITTED
			server: https://F08A5CEEF5AC38E949E4AA91C2FE028D.sk1.us-west-2.eks.amazonaws.com
			name: arn:aws:eks:us-west-2:688595016292:cluster/classCluster
			......
			
  $ kubectl get svc --v=10				<= --v=5  verbose level 5
  
  # Version Check
  $ aws --version
		aws-cli/1.16.115 Python/3.6.7 Linux/3.10.0-957.1.3.el7.x86_64 botocore/1.12.105
		
  $ kubectl version --short --client
		Client Version: v1.13.4
	
  # RBAC <= Role-based access control (RBAC)

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------













































































































































############################################################################
1. CloudTrail
############################################################################

	a. CloudTrail Viewer Tool
	https://github.com/githublemming/CloudTrailViewer/releases

# Create a S3 bucket	
$aws s3api create-bucket --bucket bnea-cloudtrail-bucket --region us-east-1
{
    "Location": "/bnea-cloudtrail-bucket"
}

# Create a Policy
##############################################################################
{
	"Version": "2012-10-17",
	"Statement": [{
			"Sid": "AWSCloudTrailAclCheck20150319",
			"Effect": "Allow",
			"Principal": {
				"Service": "cloudtrail.amazonaws.com"
			},
			"Action": "s3:GetBucketAcl",
			"Resource": "arn:aws:s3:::bnga-cloudtrail-bucket"
		},
		{
			"Sid": "AWSCloudTrailWrite20150319",
			"Effect": "Allow",
			"Principal": {
				"Service": "cloudtrail.amazonaws.com"
			},
			"Action": "s3:PutObject",
			"Resource": "arn:aws:s3:::bnea-cloudtrail-bucket/[optional prefix]/AWSLogs/myAccountID/*",
			"Condition": {
				"StringEquals": {
					"s3:x-amz-acl": "bucket-owner-full-control"
				}
			}
		}
	]
}
##############################################################################













