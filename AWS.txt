--------------------------------------------------------------------------------------------
AWS Terminology	
--------------------------------------------------------------------------------------------

--------------------------------------------------------------------------------------------
Compute:
--------------------------------------------------------------------------------------------
	----------------------------------------------------------------------------------------
	EC2 (VM Servers)
	----------------------------------------------------------------------------------------
	
	----------------------------------------------------------------------------------------
	LightSail
	----------------------------------------------------------------------------------------
	Lightsail is designed to be the easiest way to launch and manage a virtual private server 
	with AWS. Lightsail offers bundled plans that include everything you need to deploy 
	a virtual private server, for a low monthly rate.

	See Also https://aws.amazon.com/lightsail/.
	
	
	----------------------------------------------------------------------------------------
	ECR(Elastic Container Registry - Docker Hub )
	----------------------------------------------------------------------------------------
	A fully managed Docker container registry that makes it easy for developers to store, 
	manage, and deploy Docker container images. Amazon ECR is integrated with Amazon Elastic 
	Container Service (Amazon ECS) and AWS Identity and Access Management (IAM).

	See Also https://aws.amazon.com/ecr.
	
	
	----------------------------------------------------------------------------------------
	ECS (Elastic Container Service)
	----------------------------------------------------------------------------------------
	A highly scalable, fast, container management service that makes it easy to run, stop, 
	and manage Docker containers on a cluster of EC2 instances.

	See Also https://aws.amazon.com/ecs.
	
	----------------------------------------------------------------------------------------
	EKS (Elastic Kubernetes Service)
	----------------------------------------------------------------------------------------
	
	
	
	----------------------------------------------------------------------------------------
	Lambda
	----------------------------------------------------------------------------------------
	A web service that lets you run code without provisioning or managing servers. You can 
	run code for virtually any type of application or back-end service with zero administration. 
	You can set up your code to automatically trigger from other AWS services or call it 
	directly from any web or mobile app.

	See Also https://aws.amazon.com/lambda/.
	
	
	----------------------------------------------------------------------------------------
	Batch
	----------------------------------------------------------------------------------------
	AWS Batch enables developers, scientists, and engineers to easily and efficiently run 
	hundreds of thousands of batch computing jobs on AWS. AWS Batch dynamically provisions 
	the optimal quantity and type of compute resources (e.g., CPU or memory optimized instances) 
	based on the volume and specific resource requirements of the batch jobs submitted. 
	With AWS Batch, there is no need to install and manage batch computing software or server 
	clusters that you use to run your jobs, allowing you to focus on analyzing results and 
	solving problems. AWS Batch plans, schedules, and executes your batch computing workloads 
	across the full range of AWS compute services and features, such as Amazon EC2 and 
	Spot Instances.
	

	----------------------------------------------------------------------------------------
	Elastic Beanstalk
	----------------------------------------------------------------------------------------
	AWS Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications 
	and services developed with Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker on 
	familiar servers such as Apache, Nginx, Passenger, and IIS.
	
	----------------------------------------------------------------------------------------
	Serverless Application Repository
	----------------------------------------------------------------------------------------
	The AWS Serverless Application Repository is a managed repository for serverless applications. 
	It enables teams, organizations, and individual developers to store and share reusable 
	applications, and easily assemble and deploy serverless architectures in powerful new ways. 
	Using the Serverless Application Repository, you don't need to clone, build, package, or 
	publish source code to AWS before deploying it. Instead, you can use pre-built applications 
	from the Serverless Application Repository in your serverless architectures, helping you 
	and your teams reduce duplicated work, ensure organizational best practices, and get to 
	market faster. Integration with AWS Identity and Access Management (IAM) provides 
	resource-level control of each application, enabling you to publicly share applications 
	with everyone or privately share them with specific AWS accounts. To share an application 
	you've built, publish it to the AWS Serverless Application Repository.

	Each application is packaged with an AWS Serverless Application Model (SAM) template that 
	defines the AWS resources used. Publicly shared applications also include a link to the 
	application’s source code. There is no additional charge to use the Serverless Application 
	Repository - you only pay for the AWS resources used in the applications you deploy.

----------------------------------------------------------------------------------------	
Storage:
----------------------------------------------------------------------------------------
	----------------------------------------------------------------------------------------
	S3
	----------------------------------------------------------------------------------------
	
	----------------------------------------------------------------------------------------
	EFS(Elastic File System - NFS)
	https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html
	----------------------------------------------------------------------------------------
	Amazon EFS provides file storage in the AWS Cloud. With Amazon EFS, you can create a file 
	system, mount the file system on an Amazon EC2 instance, and then read and write data to 
	and from your file system. You can mount an Amazon EFS file system in your VPC, through 
	the Network File System versions 4.0 and 4.1 (NFSv4) protocol.
	
	Amazon Elastic File System (Amazon EFS- NFS) provides a simple, scalable, elastic file system 
	for Linux-based workloads for use with AWS Cloud services and on-premises resources. It 
	is built to scale on demand to petabytes without disrupting applications, growing and 
	shrinking automatically as you add and remove files, so your applications have the storage 
	they need – when they need it. It is designed to provide massively parallel shared access 
	to thousands of Amazon EC2 instances, enabling your applications to achieve high levels 
	of aggregate throughput and IOPS with consistent low latencies. Amazon EFS is a fully 
	managed service that requires no changes to your existing applications and tools, 
	providing access through a standard file system interface for seamless integration. 
	There is a Standard and an Infrequent Access storage class available with Amazon EFS. 
	Using Lifecycle Management, files not accessed for 30 days will automatically be moved 
	to a cost-optimized Infrequent Access storage class, giving you a simple way to store 
	and access active and infrequently accessed file system data in the same file system 
	while reducing storage costs by up to 85%. Amazon EFS is a regional service storing 
	data within and across multiple Availability Zones (AZs) for high availability and 
	durability. You can access your file systems across AZs, regions, and VPCs and share 
	files between thousands of Amazon EC2 instances and on-premises servers via AWS Direct 
	Connect or AWS VPN.

	Amazon EFS is well suited to support a broad spectrum of use cases from highly parallelized, 
	scale-out workloads that require the highest possible throughput to single-threaded, 
	latency-sensitive workloads. Use cases such as lift-and-shift enterprise applications, 
	big data analytics, web serving and content management, application development and testing, 
	media and entertainment workflows, database backups, and container storage.
	
	
	
	----------------------------------------------------------------------------------------
	FSx (Manage 3rd Party File System)
	----------------------------------------------------------------------------------------
	Amazon FSx provides fully managed third-party file systems. Amazon FSx provides you with 
	the native compatibility of third-party file systems with feature sets for workloads such 
	as Windows-based storage, high-performance computing (HPC), machine learning, and 
	electronic design automation (EDA). You don’t have to worry about managing file servers 
	and storage, as Amazon FSx automates the time-consuming administration tasks such as 
	hardware provisioning, software configuration, patching, and backups. Amazon FSx 
	integrates the file systems with cloud-native AWS services, making them even more 
	useful for a broader set of workloads.

	Amazon FSx provides you with two file systems to choose from: Amazon FSx for Windows 
	File Server for Windows-based applications and Amazon FSx for Lustre for compute-intensive 
	workloads.

	----------------------------------------------------------------------------------------
	S3 Glacier
	----------------------------------------------------------------------------------------
	Amazon S3 Glacier is a secure, durable, and extremely low-cost cloud storage service for 
	data archiving and long-term backup. It is designed to deliver 99.999999999% durability, 
	and provides comprehensive security and compliance capabilities that can help meet even 
	the most stringent regulatory requirements. Amazon S3 Glacier provides query-in-place 
	functionality, allowing you to run powerful analytics directly on your archive data at 
	rest. Customers can store data for as little as $0.004 per gigabyte per month, a significant 
	savings compared to on-premises solutions. To keep costs low yet suitable for varying 
	retrieval needs, Amazon S3 Glacier provides three options for access to archives, from 
	a few minutes to several hours.
	
	----------------------------------------------------------------------------------------
	Storage Gateway
	----------------------------------------------------------------------------------------
	AWS Storage Gateway is a hybrid storage service that enables your on-premises applications 
	to seamlessly use AWS cloud storage. You can use the service for backup and archiving, 
	disaster recovery, cloud data processing, storage tiering, and migration. The service 
	helps you reduce and simplify your datacenter and branch or remote office storage 
	infrastructure. Your applications connect to the service through a virtual machine 
	or hardware gateway appliance using standard storage protocols, such as NFS, SMB and 
	iSCSI. The gateway connects to AWS storage services, such as Amazon S3, Amazon Glacier, 
	Amazon EBS, and AWS Backup, providing storage for files, volumes, snapshots, and virtual 
	tapes in AWS. The service includes a highly-optimized data transfer mechanism, with 
	bandwidth management, automated network resilience, and efficient data transfer, along 
	with a local cache for low-latency on-premises access to your most active data.
	
	----------------------------------------------------------------------------------------
	AWS Backup
	----------------------------------------------------------------------------------------
	AWS Backup is a fully managed backup service that makes it easy to centralize and automate 
	the back up of data across AWS services in the cloud as well as on premises using the AWS 
	Storage Gateway. Using AWS Backup, you can centrally configure backup policies and monitor 
	backup activity for AWS resources, such as Amazon EBS volumes, Amazon RDS databases, 
	Amazon DynamoDB tables, Amazon EFS file systems, and AWS Storage Gateway volumes. 
	AWS Backup automates and consolidates backup tasks previously performed service-by-service, 
	removing the need to create custom scripts and manual processes. With just a few clicks 
	in the AWS Backup console, you can create backup policies that automate backup schedules 
	and retention management. AWS Backup provides a fully managed, policy-based backup solution, 
	simplifying your backup management, enabling you to meet your business and regulatory 
	backup compliance requirements.
	
----------------------------------------------------------------------------------------	
Database
----------------------------------------------------------------------------------------
	----------------------------------------------------------------------------------------
	RDS (Relational Database Service MySQL, Aurora, Postgres)
	----------------------------------------------------------------------------------------
	
	
	----------------------------------------------------------------------------------------
	DynamoDB (Fast and flexible NoSQL database service for any scale)
	----------------------------------------------------------------------------------------
	Amazon DynamoDB is a key-value and document database that delivers single-digit millisecond 
	performance at any scale. It's a fully managed, multiregion, multimaster database with 
	built-in security, backup and restore, and in-memory caching for internet-scale applications. 
	DynamoDB can handle more than 10 trillion requests per day and support peaks of more than 
	20 million requests per second.

	Many of the world's fastest growing businesses such as Lyft, Airbnb, and Redfin as well 
	as enterprises such as Samsung, Toyota, and Capital One depend on the scale and 
	performance of DynamoDB to support their mission-critical workloads.

	More than 100,000 AWS customers have chosen DynamoDB as their key-value and document 
	database for mobile, web, gaming, ad tech, IoT, and other applications that need 
	low-latency data access at any scale. Create a new table for your application and 
	let DynamoDB handle the rest.
	
	
	----------------------------------------------------------------------------------------
	ElastiCache(Managed, Redis or Memcached-compatible in-memory data store.)
	----------------------------------------------------------------------------------------
	Amazon ElastiCache offers fully managed Redis and Memcached. Seamlessly deploy, run, and 
	scale popular open source compatible in-memory data stores. Build data-intensive apps or 
	improve the performance of your existing apps by retrieving data from high throughput and 
	low latency in-memory data stores. Amazon ElastiCache is a popular choice for Gaming, 
	Ad-Tech, Financial Services, Healthcare, and IoT apps.
	
	----------------------------------------------------------------------------------------
	Neptune
	----------------------------------------------------------------------------------------
		
	----------------------------------------------------------------------------------------
	Redshift(Fast, simple, cost-effective data warehouse that can extend queries to your data lake)
	----------------------------------------------------------------------------------------
	Amazon Redshift is a fast, scalable data warehouse that makes it simple and cost-effective 
	to analyze all your data across your data warehouse and data lake. Redshift delivers ten 
	times faster performance than other data warehouses by using machine learning, massively 
	parallel query execution, and columnar storage on high-performance disk. You can setup 
	and deploy a new data warehouse in minutes, and run queries across petabytes of data 
	in your Redshift data warehouse, and exabytes of data in your data lake built on Amazon 
	S3. You can start small for just $0.25 per hour and scale to $250 per terabyte per year, 
	less than one-tenth the cost of other solutions.

	To create your first Amazon Redshift data warehouse, follow our Getting Started Guide 
	and get the most out of your experience. Contact us to request support for your 
	proof-of-concept or evaluation.To accelerate your migration to Amazon Redshift, 
	you can use the AWS Database Migration Service (DMS) free for six months. 
	
	
	----------------------------------------------------------------------------------------
	DocumentDB (MongoDB compatibility)
	----------------------------------------------------------------------------------------
	Amazon DocumentDB (with MongoDB compatibility) is a fast, scalable, highly available, 
	and fully managed document database service that supports MongoDB workloads.

	Customers use MongoDB as a document database to store, retrieve, and manage semi-structured 
	data. However, it is hard to build performant, highly available applications that can 
	quickly scale to multiple terabytes and hundreds of thousands of reads- and writes-per-second 
	because of the complexity that comes with setting up and managing MongoDB clusters at scale. 
	Amazon DocumentDB is designed from the ground-up to give you the performance, scalability, 
	and availability you need when operating mission-critical MongoDB workloads at scale. 
	Amazon DocumentDB implements the Apache 2.0 open source MongoDB 3.6 API by emulating the 
	responses that a MongoDB client expects from a MongoDB server, allowing you to use your 
	existing MongoDB drivers and tools with Amazon DocumentDB. Amazon DocumentDB uses a distributed, 
	fault-tolerant, self-healing storage system that auto-scales up to 64 TB per database cluster. 
	In Amazon DocumentDB, the storage and compute are decoupled, allowing each to scale independently, 
	and developers can increase the read capacity to millions of requests per second by adding 
	up to 15 low latency read replicas in minutes, regardless of the size of your data. 
	Amazon DocumentDB is designed for 99.99% availability and replicates six copies of your data 
	across three AWS Availability Zones (AZs). Customers can use AWS Database Migration Service 
	(DMS) for free (for six months) to easily migrate their on-premises or Amazon Elastic 
	Compute Cloud (EC2) MongoDB databases to Amazon DocumentDB with virtually no downtime.
	
	
----------------------------------------------------------------------------------------	
Networking & Content Delivery
----------------------------------------------------------------------------------------
	----------------------------------------------------------------------------------------
	VPC
	----------------------------------------------------------------------------------------
	
	
	----------------------------------------------------------------------------------------
	CloudFront (Content Delivery Network (CDN)
	----------------------------------------------------------------------------------------
	
	
	----------------------------------------------------------------------------------------
	Route 53 (DNS)
	----------------------------------------------------------------------------------------
	
	
	----------------------------------------------------------------------------------------
	API Gateway
	----------------------------------------------------------------------------------------
	A fully managed service that makes it easy for developers to create, publish, maintain, 
	monitor, and secure APIs at any scale.

	See Also https://aws.amazon.com/api-gateway.
	
	----------------------------------------------------------------------------------------
	Direct Connect
	----------------------------------------------------------------------------------------
	AWS Direct Connect is a cloud service solution that makes it easy to establish a dedicated 
	network connection from your premises to AWS. Using AWS Direct Connect, you can establish 
	private connectivity between AWS and your datacenter, office, or colocation environment, 
	which in many cases can reduce your network costs, increase bandwidth throughput, and 
	provide a more consistent network experience than Internet-based connections.
	
	
	----------------------------------------------------------------------------------------
	AWS Cloud Map
	----------------------------------------------------------------------------------------
	AWS Cloud Map is a cloud resource discovery service. With Cloud Map, you can define custom 
	names for your application resources, and it maintains the updated location of these 
	dynamically changing resources. This increases your application availability because 
	your web service always discovers the most up-to-date locations of its resources.
	
	----------------------------------------------------------------------------------------
	Global Accelerator
	----------------------------------------------------------------------------------------
	AWS Global Accelerator is a networking service that improves the availability and 
	performance of the applications that you offer to your global users.
	
----------------------------------------------------------------------------------------	
Developer Tools
----------------------------------------------------------------------------------------
	
	----------------------------------------------------------------------------------------
	CodeStar(Quickly develop, build, and deploy applications on AWS)
	----------------------------------------------------------------------------------------
	AWS CodeStar enables you to quickly develop, build, and deploy applications on AWS. AWS 
	CodeStar provides a unified user interface, enabling you to easily manage your software 
	development activities in one place. With AWS CodeStar, you can set up your entire 
	continuous delivery toolchain in minutes, allowing you to start releasing code faster. 
	AWS CodeStar makes it easy for your whole team to work together securely, allowing you 
	to easily manage access and add owners, contributors, and viewers to your projects. 
	Each AWS CodeStar project comes with a project management dashboard, including an 
	integrated issue tracking capability powered by Atlassian JIRA Software. With the AWS 
	CodeStar project dashboard, you can easily track progress across your entire software 
	development process, from your backlog of work items to teams’ recent code deployments. 
	Visit here to learn more.

	There is no additional charge for using AWS CodeStar. You only pay for the AWS resources 
	that you provision for developing and running your application (for example, 
	Amazon EC2 instances).
	
	----------------------------------------------------------------------------------------
	CodeCommit
	(Securely host highly scalable private Git repositories. Collaborate on code.)
	----------------------------------------------------------------------------------------
	AWS CodeCommit is a fully-managed source control service that hosts secure Git-based repositories. It makes it easy for teams to collaborate on code in a secure and highly scalable ecosystem. CodeCommit eliminates the need to operate your own source control system or worry about scaling its infrastructure. You can use CodeCommit to securely store anything from source code to binaries, and it works seamlessly with your existing Git tools.
	
	
	
	----------------------------------------------------------------------------------------
	CodeBuild
	(Build and test code with continuous scaling. Pay only for the build time you use.)
	----------------------------------------------------------------------------------------
	AWS CodeBuild is a fully managed continuous integration service that compiles source code, runs tests, and produces software packages that are ready to deploy. With CodeBuild, you don’t need to provision, manage, and scale your own build servers. CodeBuild scales continuously and processes multiple builds concurrently, so your builds are not left waiting in a queue. You can get started quickly by using prepackaged build environments, or you can create custom build environments that use your own build tools. With CodeBuild, you are charged by the minute for the compute resources you use.
	
	
	----------------------------------------------------------------------------------------
	CodeDeploy
	(Automate code deployments to maintain application uptime)
	----------------------------------------------------------------------------------------
	AWS CodeDeploy is a fully managed deployment service that automates software deployments to a variety of compute services such as Amazon EC2, AWS Fargate, AWS Lambda, and your on-premises servers. AWS CodeDeploy makes it easier for you to rapidly release new features, helps you avoid downtime during application deployment, and handles the complexity of updating your applications. You can use AWS CodeDeploy to automate software deployments, eliminating the need for error-prone manual operations. The service scales to match your deployment needs.
	
	
	----------------------------------------------------------------------------------------
	CodePipeline
	(Automate continuous delivery pipelines for fast and reliable updates)
	----------------------------------------------------------------------------------------
	AWS CodePipeline is a fully managed continuous delivery service that helps you automate your release pipelines for fast and reliable application and infrastructure updates. CodePipeline automates the build, test, and deploy phases of your release process every time there is a code change, based on the release model you define. This enables you to rapidly and reliably deliver features and updates. You can easily integrate AWS CodePipeline with third-party services such as GitHub or with your own custom plugin. With AWS CodePipeline, you only pay for what you use. There are no upfront fees or long-term commitments.
	
	----------------------------------------------------------------------------------------
	Cloud9(A cloud IDE for writing, running, and debugging code)
	----------------------------------------------------------------------------------------
	AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you don’t need to install files or configure your development machine to start new projects. Since your Cloud9 IDE is cloud-based, you can work on your projects from your office, home, or anywhere using an internet-connected machine. Cloud9 also provides a seamless experience for developing serverless applications enabling you to easily define resources, debug, and switch between local and remote execution of serverless applications. With Cloud9, you can quickly share your development environment with your team, enabling you to pair program and track each other's inputs in real time.
	
	
----------------------------------------------------------------------------------------
Management(운영) & Governance(관리)
----------------------------------------------------------------------------------------

	----------------------------------------------------------------------------------------
	CloudWatch(Monitoring)
	----------------------------------------------------------------------------------------
	
	
	----------------------------------------------------------------------------------------
	AWS Auto Scaling
	----------------------------------------------------------------------------------------
	
	----------------------------------------------------------------------------------------
	CloudFormation
	(Model and provision all your cloud infrastructure resources)
	----------------------------------------------------------------------------------------
	AWS CloudFormation provides a common language for you to describe and provision all the 
	infrastructure resources in your cloud environment. CloudFormation allows you to use a 
	simple text file to model and provision, in an automated and secure manner, all the 
	resources needed for your applications across all regions and accounts. This file serves 
	as the single source of truth for your cloud environment. 
	
	AWS CloudFormation is available at no additional charge, and you pay only for the AWS 
	resources needed to run your applications.
	
	----------------------------------------------------------------------------------------
	CloudTrail(Track user activity and API usage)
	----------------------------------------------------------------------------------------
	AWS CloudTrail is a service that enables governance, compliance, operational auditing, 
	and risk auditing of your AWS account. With CloudTrail, you can log, continuously monitor, 
	and retain account activity related to actions across your AWS infrastructure. CloudTrail 
	provides event history of your AWS account activity, including actions taken through the 
	AWS Management Console, AWS SDKs, command line tools, and other AWS services. This event 
	history simplifies security analysis, resource change tracking, and troubleshooting.
	
	
	----------------------------------------------------------------------------------------
	Config(Record and evaluate configurations of your AWS resources)
	----------------------------------------------------------------------------------------
	AWS Config is a service that enables you to assess, audit, and evaluate the configurations 
	of your AWS resources. Config continuously monitors and records your AWS resource 
	configurations and allows you to automate the evaluation of recorded configurations 
	against desired configurations. With Config, you can review changes in configurations 
	and relationships between AWS resources, dive into detailed resource configuration 
	histories, and determine your overall compliance against the configurations specified 
	in your internal guidelines. This enables you to simplify compliance auditing, security 
	analysis, change management, and operational troubleshooting.
	
	----------------------------------------------------------------------------------------
	OpsWorks(Automate Operations with Chef and Puppet)
	https://aws.amazon.com/opsworks/
	----------------------------------------------------------------------------------------
	AWS OpsWorks is a configuration management service that provides managed instances of Chef 
	and Puppet. Chef and Puppet are automation platforms that allow you to use code to automate 
	the configurations of your servers. OpsWorks lets you use Chef and Puppet to automate how 
	servers are configured, deployed, and managed across your Amazon EC2 instances or on-premises 
	compute environments. OpsWorks has three offerings, AWS Opsworks for Chef Automate, AWS OpsWorks 
	for Puppet Enterprise, and AWS OpsWorks Stacks.
	
	
	----------------------------------------------------------------------------------------
	Service Catalog
	----------------------------------------------------------------------------------------
	AWS Service Catalog allows organizations to create and manage catalogs of IT services that 
	are approved for use on AWS. These IT services can include everything from virtual machine 
	images, servers, software, and databases to complete multi-tier application architectures. 
	AWS Service Catalog allows you to centrally manage commonly deployed IT services, and helps 
	you achieve consistent governance and meet your compliance requirements, while enabling 
	users to quickly deploy only the approved IT services they need.
	
	----------------------------------------------------------------------------------------
	Systems Manager
	----------------------------------------------------------------------------------------
	
	
	----------------------------------------------------------------------------------------
	Trusted Advisor
	----------------------------------------------------------------------------------------
	
	
	----------------------------------------------------------------------------------------
	Managed Services
	----------------------------------------------------------------------------------------
	
	
	----------------------------------------------------------------------------------------
	Control Tower
	(The easiest way to set up and govern a secure, compliant multi-account AWS environment)
	----------------------------------------------------------------------------------------
	AWS Control Tower automates the set-up of a baseline environment, or landing zone, that 
	is a secure, well-architected multi-account AWS environment. The configuration of the 
	landing zone is based on best practices that have been established by working with 
	thousands of enterprise customers to create a secure environment that makes it easier 
	to govern AWS workloads with rules for security, operations, and compliance.

	As enterprises migrate to AWS, they typically have a large number of applications and 
	distributed teams. They often want to create multiple accounts to allow their teams to 
	work independently, while still maintaining a consistent level of security and compliance. 
	In addition, they use AWS’s management and security services, like AWS Organizations, 
	AWS Service Catalog and AWS Config, that provide very granular controls over their workloads. 
	They want to maintain this control, but they also want a way to centrally govern and 
	enforce the best use of AWS services across all the accounts in their environment.

	Control Tower automates the set-up of their landing zone and configures AWS management 
	and security services based on established best practices in a secure, compliant, 
	multi-account environment. Distributed teams are able to provision new AWS accounts 
	quickly, while central teams have the peace of mind knowing that new accounts are 
	aligned with centrally established, company-wide compliance policies. This gives you 
	control over your environment, without sacrificing the speed and agility AWS provides 
	your development teams.
	
	----------------------------------------------------------------------------------------
	AWS License Manager
	----------------------------------------------------------------------------------------
	
	
	----------------------------------------------------------------------------------------
	AWS Well-Architected Tool
	----------------------------------------------------------------------------------------
	
	
	----------------------------------------------------------------------------------------
	Personal Health Dashboard
	----------------------------------------------------------------------------------------

----------------------------------------------------------------------------------------
Analytics
----------------------------------------------------------------------------------------
	
	----------------------------------------------------------------------------------------
	Athena(Start querying data instantly. Get results in seconds. Pay only for the queries you run.)
	----------------------------------------------------------------------------------------
	Amazon Athena is an interactive query service that makes it easy to analyze data in Amazon 
	S3 using standard SQL. Athena is serverless, so there is no infrastructure to manage, and 
	you pay only for the queries that you run.

	Athena is easy to use. Simply point to your data in Amazon S3, define the schema, and 
	start querying using standard SQL. Most results are delivered within seconds. With Athena, 
	there’s no need for complex ETL jobs to prepare your data for analysis. This makes it easy 
	for anyone with SQL skills to quickly analyze large-scale datasets.

	Athena is out-of-the-box integrated with AWS Glue Data Catalog, allowing you to create a 
	unified metadata repository across various services, crawl data sources to discover 
	schemas and populate your Catalog with new and modified table and partition definitions, 
	and maintain schema versioning. You can also use Glue’s fully-managed ETL capabilities 
	to transform data or convert it into columnar formats to optimize cost and improve performance.

	
	----------------------------------------------------------------------------------------
	EMR(Apache Spark, Hadoop, HBase, Presto, Hive, and other Big Data Frameworks)
	----------------------------------------------------------------------------------------
	Amazon EMR provides a managed Hadoop framework that makes it easy, fast, and cost-effective 
	to process vast amounts of data across dynamically scalable Amazon EC2 instances. You can 
	also run other popular distributed frameworks such as Apache Spark, HBase, Presto, and 
	Flink in EMR, and interact with data in other AWS data stores such as Amazon S3 and Amazon 
	DynamoDB. EMR Notebooks, based on the popular Jupyter Notebook, provide a development and 
	collaboration environment for ad hoc querying and exploratory analysis.

	EMR securely and reliably handles a broad set of big data use cases, including log analysis, 
	web indexing, data transformations (ETL), machine learning, financial analysis, scientific 
	simulation, and bioinformatics.
	
	----------------------------------------------------------------------------------------
	CloudSearch
	----------------------------------------------------------------------------------------
	Amazon CloudSearch is a managed service in the AWS Cloud that makes it simple and 
	cost-effective to set up, manage, and scale a search solution for your website or application.
	
	Amazon CloudSearch supports 34 languages and popular search features such as highlighting, 
	autocomplete, and geospatial search. For more information, see Benefits.
	
	----------------------------------------------------------------------------------------
	Elasticsearch Service
	----------------------------------------------------------------------------------------
	Amazon Elasticsearch Service is a fully managed service that makes it easy for you to deploy, 
	secure, and operate Elasticsearch at scale with zero down time. The service offers open-source 
	Elasticsearch APIs, managed Kibana, and integrations with Logstash and other AWS Services, 
	enabling you to securely ingest data from any source and search, analyze, and visualize 
	it in real time. Amazon Elasticsearch Service lets you pay only for what you use – there 
	are no upfront costs or usage requirements. With Amazon Elasticsearch Service, you get 
	the ELK stack you need, without the operational overhead.
	
	
	----------------------------------------------------------------------------------------
	Kinesis(collect, process, and analyze video and data streams in real time)
	----------------------------------------------------------------------------------------
	Amazon Kinesis makes it easy to collect, process, and analyze real-time, streaming data 
	so you can get timely insights and react quickly to new information. Amazon Kinesis offers 
	key capabilities to cost-effectively process streaming data at any scale, along with the 
	flexibility to choose the tools that best suit the requirements of your application. With 
	Amazon Kinesis, you can ingest real-time data such as video, audio, application logs, 
	website clickstreams, and IoT telemetry data for machine learning, analytics, and other 
	applications. Amazon Kinesis enables you to process and analyze data as it arrives and 
	respond instantly instead of having to wait until all your data is collected before the 
	processing can begin.
	
	
	----------------------------------------------------------------------------------------
	QuickSight (First BI Service with Pay-per-Session Pricing
				and ML Insights for everyone.)
	----------------------------------------------------------------------------------------
	Amazon QuickSight is a fast, cloud-powered business intelligence service that makes it easy 
	to deliver insights to everyone in your organization.

	As a fully managed service, QuickSight lets you easily create and publish interactive 
	dashboards that include ML Insights. Dashboards can then be accessed from any device, 
	and embedded into your applications, portals, and websites.

	With our Pay-per-Session pricing, QuickSight allows you to give everyone access to the 
	data they need, while only paying for what you use.
	
	----------------------------------------------------------------------------------------
	Data Pipeline
	----------------------------------------------------------------------------------------
	AWS Data Pipeline is a web service that helps you reliably process and move data between 
	different AWS compute and storage services, as well as on-premises data sources, at 
	specified intervals. With AWS Data Pipeline, you can regularly access your data where 
	it’s stored, transform and process it at scale, and efficiently transfer the results 
	to AWS services such as Amazon S3, Amazon RDS, Amazon DynamoDB, and Amazon EMR.

	AWS Data Pipeline helps you easily create complex data processing workloads that are 
	fault tolerant, repeatable, and highly available. You don’t have to worry about ensuring 
	resource availability, managing inter-task dependencies, retrying transient failures or 
	timeouts in individual tasks, or creating a failure notification system. AWS Data Pipeline 
	also allows you to move and process data that was previously locked up in on-premises 
	data silos.
	
	
	----------------------------------------------------------------------------------------
	Glue(Simple, flexible, and cost-effective ETL)
	----------------------------------------------------------------------------------------
	AWS Glue is a fully managed extract, transform, and load (ETL) service that makes it easy 
	for customers to prepare and load their data for analytics. You can create and run an 
	ETL job with a few clicks in the AWS Management Console. You simply point AWS Glue to 
	your data stored on AWS, and AWS Glue discovers your data and stores the associated 
	metadata (e.g. table definition and schema) in the AWS Glue Data Catalog. Once cataloged, 
	your data is immediately searchable, queryable, and available for ETL.
	
	----------------------------------------------------------------------------------------
	MSK(Managed Streaming for Kafka0
	----------------------------------------------------------------------------------------
	Amazon Managed Streaming for Kafka (Amazon MSK) is a fully managed service that makes it 
	easy for you to build and run applications that use Apache Kafka to process streaming 
	data. Apache Kafka is an open-source platform for building real-time streaming data 
	pipelines and applications. With Amazon MSK, you can use Apache Kafka APIs to populate 
	data lakes, stream changes to and from databases, and power machine learning and 
	analytics applications.

	Apache Kafka clusters are challenging to setup, scale, and manage in production. When 
	you run Apache Kafka on your own, you need to provision servers, configure Apache Kafka 
	manually, replace servers when they fail, orchestrate server patches and upgrades, 
	architect the cluster for high availability, ensure data is durably stored and secured, 
	setup monitoring and alarms, and carefully plan scaling events to support load changes. 
	Amazon Managed Streaming for Kafka makes it easy for you to build and run production 
	applications on Apache Kafka without needing Apache Kafka infrastructure management 
	expertise. That means you spend less time managing infrastructure and more time building 
	applications.

	With a few clicks in the Amazon MSK console you can create highly available Apache 
	Kafka clusters with settings and configuration based on Apache Kafka’s deployment 
	best practices. Amazon MSK automatically provisions and runs your Apache Kafka clusters. 
	Amazon MSK continuously monitors cluster health and automatically replaces unhealthy 
	nodes with no downtime to your application. In addition, Amazon MSK secures your Apache 
	Kafka cluster by encrypting data at rest.
	
	
	
	
	
	
	
	
	
	
	
	
	
----------------------------------------------------------------------------------------
Security, Identity, & Compliance
----------------------------------------------------------------------------------------

	----------------------------------------------------------------------------------------
	IAM
	----------------------------------------------------------------------------------------
	
	
	----------------------------------------------------------------------------------------
	Resource Access Manager(Simple, secure service to share AWS resources)
	----------------------------------------------------------------------------------------
	AWS Resource Access Manager (RAM) is a service that enables you to easily and securely 
	share AWS resources with any AWS account or within your AWS Organization. You can share 
	AWS Transit Gateways, Subnets, AWS License Manager configurations, and Amazon Route 53 
	Resolver rules resources with RAM.

	Many organizations use multiple accounts to create administrative or billing isolation, 
	and to limit the impact of errors. RAM eliminates the need to create duplicate resources 
	in multiple accounts, reducing the operational overhead of managing those resources in 
	every single account you own. You can create resources centrally in a multi-account 
	environment, and use RAM to share those resources across accounts in three simple steps: 
	create a Resource Share, specify resources, and specify accounts. RAM is available to 
	you at no additional charge.
	
	
	----------------------------------------------------------------------------------------
	Cognito(Simple and Secure User Sign-Up, Sign-In, and Access Control)
	----------------------------------------------------------------------------------------
	Amazon Cognito lets you add user sign-up, sign-in, and access control to your web and 
	mobile apps quickly and easily. Amazon Cognito scales to millions of users and supports 
	sign-in with social identity providers, such as Facebook, Google, and Amazon, and 
	enterprise identity providers via SAML 2.0.
	
	
	----------------------------------------------------------------------------------------
	Secrets Manager
		(rotate, manage, and retrieve database credentials, API keys, and other secrets 
		through their lifecycle)
	----------------------------------------------------------------------------------------
	AWS Secrets Manager helps you protect secrets needed to access your applications, services, 
	and IT resources. The service enables you to easily rotate, manage, and retrieve database 
	credentials, API keys, and other secrets throughout their lifecycle. Users and applications 
	retrieve secrets with a call to Secrets Manager APIs, eliminating the need to hardcode 
	sensitive information in plain text. Secrets Manager offers secret rotation with built-in 
	integration for Amazon RDS for MySQL, PostgreSQL, and Amazon Aurora. Also, the service 
	is extensible to other types of secrets, including API keys and OAuth tokens. In addition, 
	Secrets Manager enables you to control access to secrets using fine-grained permissions 
	and audit secret rotation centrally for resources in the AWS Cloud, third-party services, 
	and on-premises.
	
	----------------------------------------------------------------------------------------
	GuardDuty
	----------------------------------------------------------------------------------------
	
	
	
	----------------------------------------------------------------------------------------
	Inspector
	----------------------------------------------------------------------------------------
	
	
	
	----------------------------------------------------------------------------------------
	Macie
	(A machine learning-powered security service to discover, classify, and protect sensitive data.)
	----------------------------------------------------------------------------------------
	Amazon Macie is a security service that uses machine learning to automatically discover, 
	classify, and protect sensitive data in AWS. Amazon Macie recognizes sensitive data such 
	as personally identifiable information (PII) or intellectual property, and provides you 
	with dashboards and alerts that give visibility into how this data is being accessed or 
	moved. The fully managed service continuously monitors data access activity for anomalies, 
	and generates detailed alerts when it detects risk of unauthorized access or inadvertent 
	data leaks. Today, Amazon Macie is available to protect data stored in Amazon S3, with 
	support for additional AWS data stores coming later this year.
	
	----------------------------------------------------------------------------------------
	Organizations
	----------------------------------------------------------------------------------------
	
	
	
	----------------------------------------------------------------------------------------
	Single Sign-On
	----------------------------------------------------------------------------------------
	AWS Single Sign-On (SSO) is a cloud SSO service that makes it easy to centrally manage 
	SSO access to multiple AWS accounts and business applications. With just a few clicks, 
	you can enable a highly available SSO service without the upfront investment and on-going 
	maintenance costs of operating your own SSO infrastructure. With AWS SSO, you can easily 
	manage SSO access and user permissions to all of your accounts in AWS Organizations 
	centrally. AWS SSO also includes built-in SAML integrations to many business applications, 
	such as Salesforce, Box, and Office 365. Further, by using the AWS SSO application 
	configuration wizard, you can create Security Assertion Markup Language (SAML) 2.0 
	integrations and extend SSO access to any of your SAML-enabled applications. Your users 
	simply sign in to a user portal with credentials they configure in AWS SSO or using 
	their existing corporate credentials to access all their assigned accounts and applications 
	from one place.
	
	----------------------------------------------------------------------------------------
	Certificate Manager
		Easily provision, manage, and deploy public and private SSL/TLS certificates 
		for use with AWS services and your internal connected resources
	----------------------------------------------------------------------------------------
	AWS Certificate Manager is a service that lets you easily provision, manage, and deploy 
	public and private Secure Sockets Layer/Transport Layer Security (SSL/TLS) certificates 
	for use with AWS services and your internal connected resources. SSL/TLS certificates 
	are used to secure network communications and establish the identity of websites over 
	the Internet as well as resources on private networks. AWS Certificate Manager removes t
	he time-consuming manual process of purchasing, uploading, and renewing SSL/TLS certificates.

	With AWS Certificate Manager, you can quickly request a certificate, deploy it on 
	ACM-integrated AWS resources, such as Elastic Load Balancers, Amazon CloudFront 
	distributions, and APIs on API Gateway, and let AWS Certificate Manager handle certificate 
	renewals. It also enables you to create private certificates for your internal resources 
	and manage the certificate lifecycle centrally. Public and private certificates provisioned 
	through AWS Certificate Manager for use with ACM-integrated services are free. You pay 
	only for the AWS resources you create to run your application. With AWS Certificate 
	Manager Private Certificate Authority, you pay monthly for the operation of the private 
	CA and for the private certificates you issue.
	
	----------------------------------------------------------------------------------------
	Key Management Service
	----------------------------------------------------------------------------------------
	
	
	
	----------------------------------------------------------------------------------------
	CloudHSM
	----------------------------------------------------------------------------------------
	
	
	
	----------------------------------------------------------------------------------------
	Directory Service
	----------------------------------------------------------------------------------------
	
	
	
	----------------------------------------------------------------------------------------
	WAF & Shield
	----------------------------------------------------------------------------------------
	
	
	
	----------------------------------------------------------------------------------------	
	Artifact
	----------------------------------------------------------------------------------------
	AWS Artifact is your go-to, central resource for compliance-related information that 
	matters to you. It provides on-demand access to AWS’ security and compliance reports and 
	select online agreements. Reports available in AWS Artifact include our Service 
	Organization Control (SOC) reports, Payment Card Industry (PCI) reports, and certifications 
	from accreditation bodies across geographies and compliance verticals that validate the 
	implementation and operating effectiveness of AWS security controls. Agreements available 
	in AWS Artifact include the Business Associate Addendum (BAA) and the Nondisclosure 
	Agreement (NDA).
	
	
	----------------------------------------------------------------------------------------
	Security Hub(Centrally view and manage security alerts and automate compliance checks)
	----------------------------------------------------------------------------------------
	AWS Security Hub gives you a comprehensive view of your high-priority security alerts 
	and compliance status across AWS accounts. There are a range of powerful security tools 
	at your disposal, from firewalls and endpoint protection to vulnerability and compliance 
	scanners. But oftentimes this leaves your team switching back-and-forth between these 
	tools to deal with hundreds, and sometimes thousands, of security alerts every day. 
	With Security Hub, you now have a single place that aggregates, organizes, and 
	prioritizes your security alerts, or findings, from multiple AWS services, such as 
	Amazon GuardDuty, Amazon Inspector, and Amazon Macie, as well as from AWS Partner 
	solutions. Your findings are visually summarized on integrated dashboards with actionable 
	graphs and tables. You can also continuously monitor your environment using automated 
	compliance checks based on the AWS best practices and industry standards your organization 
	follows. Get started with AWS Security Hub in just a few clicks in the Management Console 
	and once enabled, Security Hub will begin aggregating and prioritizing findings.
	
	
	
	----------------------------------------------------------------------------------------
	AWS Certificate Manager (ACM)
	----------------------------------------------------------------------------------------
	A web service for provisioning, managing, and deploying Secure Sockets Layer/Transport 
	Layer Security (SSL/TLS) certificates for use with AWS services.

	See Also https://aws.amazon.com/certificate-manager/.

----------------------------------------------------------------------------------------
Application Integration
----------------------------------------------------------------------------------------
	
	----------------------------------------------------------------------------------------
	Step Functions
	----------------------------------------------------------------------------------------
	
	
	----------------------------------------------------------------------------------------
	Amazon MQ
	----------------------------------------------------------------------------------------
	managed message broker service for Apache ActiveMQ
	
	Amazon MQ is a managed message broker service for ActiveMQ that makes it easy to set up 
	and operate message brokers in the cloud, so you can migrate your messaging and 
	applications without rewriting code.
	
	----------------------------------------------------------------------------------------
	Simple Notification Service (SNS)
	----------------------------------------------------------------------------------------
	Amazon SNS is a fully managed pub/sub messaging and mobile notification service with 
	nearly unlimited throughput.
	
	A web service that enables applications, end-users, and devices to instantly send and 
	receive notifications from the cloud.

	See Also https://aws.amazon.com/sns.
	
	----------------------------------------------------------------------------------------
	Simple Queue Service (SQS)
	----------------------------------------------------------------------------------------
	Amazon SQS is a fully managed and highly scalable message queuing service for distributed 
	applications and systems.
	
	
	----------------------------------------------------------------------------------------
	SWF(Simple Workflow Service)
	----------------------------------------------------------------------------------------
	Amazon SWF helps developers build, run, and scale background jobs that have parallel or 
	sequential steps. You can think of Amazon SWF as a fully-managed state tracker and task
	coordinator in the Cloud.

If your app's steps take more than 500 milliseconds to complete, you need to track the state 
of processing, and you need to recover or retry if a task fails, Amazon SWF can help you.
	
	
	----------------------------------------------------------------------------------------
	Simple Email Service(email sending and receiving platform)
	----------------------------------------------------------------------------------------
	Amazon Simple Email Service (Amazon SES) is a cloud-based email sending service designed 
	to help digital marketers and application developers send marketing, notification, and 
	transactional emails. It is a reliable, cost-effective service for businesses of all sizes 
	that use email to keep in contact with their customers.

	You can use our SMTP interface or one of the AWS SDKs to integrate Amazon SES directly 
	into your existing applications. You can also integrate the email sending capabilities 
	of Amazon SES into the software you already use, such as ticketing systems and email 
	clients.
	
	
	

## OpsWorks vs. CloudFormation ###

OpsWorks is an orchestration tool like Chef - in fact, it's derived from Chef - Puppet, Ansible or Saltstalk. 
	You use Opsworks to specify the state that you want your network to be in by specifying the state 
	that you want each resource - server instances, applications, storage - that you want that resource 
	to be in. And you specify the state that you want each resource to be in by specifying the value that 
	you want for each attribute of the state. For example, you might want the apache service to be always 
	and up running and top always start on bootup with apache as the user and apache as the Linux group.

CloudFormation is a json template that specifies the state of the resource(s) that you want to deploy i.e. 
	you want to deploy an AWS EC2 micro t2 instance in us-east-1 as part of VPC 192.168.1.0/24. 
	In the case of an EC2 instance, you can specify what should run on that resource through 
	your custom bash script in the user-data section of the EC2 resource. CloudFormation is just 
	a template. The template gets fleshed out as a running resource only if you run it either 
	through the AWS Management Console for CloudFormation or if you run the aws cli command 
	for Cloudformation i.e. aws cloudformation

ElasticBeanstalk is a [PAAS] - you can upload the specifically Ruby/Rails, node.js or Python/django or 
	Python/Flask apps. If you're running anything else like Scala, Haskell or anything else, create 
	a Docker image for it and upload that Docker image into Elastic Beanstalk (*).You can do the 
	uploading of your app into Elastic Beanstalk by either running the aws cli for CloudFormation 
	or you create a recipe for Opsworks to upload your app into Elastic Beanstalk. You can also 
	run the aws cli for Cloudformation through Opsworks.

I think of it CF vs OW as a bit like level 1 and level 2. CF is like Terraform, its is fully coded automation 
of almost every service in AWS. So use if you have a very extensive service that requires full description 
of environments or templated stacks to cover low level services like auto scaling, spot instance, redshift, 
Cloudwatch alarmss and much more. The configuration time is much more extensive, and time consuming.

OW is basically AWS managed Chef. It has some great features for automation via the GUI, and you can configure 
most things. The great thing about Opsworks is that a good Devops can script the system, so someone that has 
ittle knowledge of infrastructure or cloud can still deploy apps super simply, and in very little time. 
However it is not as powerful as CF

So i think of it as CFT for large environments / many users and OpsWorks for smaller solutions 
or Application/Solution Stacks








--------------------------------------------------------------------------------------------
AWS Regions
--------------------------------------------------------------------------------------------

	Region   Name	Region	Endpoint
	US East (N. Virginia)	us-east-1	
	US West (N. California)	us-west-1	
	US West (Oregon)	    us-west-2

--------------------------------------------------------------------------------------------
### AWS CLI ### 
--------------------------------------------------------------------------------------------

$ sudo pip install awscli --ignore-installed six 		<= version 1.16, it supports EKS
--------------------------------------------------------------------------------------------
	# Alternative Installation using CentOS Repository YUM
	https://devopsmates.com/install-configure-aws-cli-amazon-web-services-command-line-interface/
	$ yum install epel-release –y
	$ yum install python-pip –y
	$ pip install awscli
	$ pip install –upgrade awscli
	$ aws –version							<=1.14  !Not supporting the ESK(starts on 1.15.32)yet
	 aws help 
--------------------------------------------------------------------------------------------

	$ aws --version
	aws-cli/1.16.115 Python/3.6.7 Linux/3.10.0-957.1.3.el7.x86_64 botocore/1.12.105   <= EKS Works

	$ aws configure
	  AWS Access Key ID [None]: 
	  AWS Secret Access Key [None]: 
	  Default region name [None]: us-west-2  <= Oregon
	  Default output format [None]: json
	
	$ aws configure --profile=clusterAdmin					<= Specific AWS USER account credential
	  AWS Access Key ID [****************UVFA]:
	  AWS Secret Access Key [****************KJ2l]:
	  Default region name [us-region-2]: us-west-2			<= Oregon
	  Default output format [None]: json					<= ONLY 'JSON' WORKS!!!! 
-------------------------------------------------------------------------------
# Connection test
-------------------------------------------------------------------------------
$ aws s3 ls
	2017-02-27 20:39:36 backup-jenkins-sign
	2017-05-22 16:10:49 mobile-xpromo
	
-------------------------------------------------------------------------------
# Canonical ID ? #
	https://docs.aws.amazon.com/general/latest/gr/acct-identifiers.html
-------------------------------------------------------------------------------
$ aws s3api list-buckets
{
    "Owner": {
        "DisplayName": "aws-gdpr",
        "ID": "25c4bb...............d729ef2e"  				<= Canonical ID
    },

--------------------------------------------------------------------------------------------



##############################################################################
# EKS  (Elastic Kubernetes Service)
# Training: https://www.linkedin.com/learning/running-kubernetes-on-aws-eks
##############################################################################

API/CLI		---> Kubectl, Ajax, etc
Management				|
------------------------V-----------------------------------------------------
Secheduler	\						Kubelet Node		
									Service Proxy
								/	
  etcd		-	API Server		-	Kubelet Node		<- User from Internet
			   (Master Node)	\	Service Proxy

Controller /						Kubelet Node
Manager								Servcie Proxy

<------ EKS ---------------->|<------- EC2 -------->|<---- Internet User ----> 



Pre-EKS Deployment
	1. AWS 		CLI
	2. Kubectl  CLI				<= Auto Shell CMD completion
	3. BASH 	CLI
	
Pre-AWS EKS Deployment
	1. IAM Configuration
		- Create a 'ROLE' defined with EKS Permissions
		- EKS:* 'Policy' applied to user/group
		
	2. VPC create for ESK use
		- Create 'ESK VPC' using CloudFormation

EKS Core Service
	1. Create cluster 'Controle Plane'(system configuration and management)
	2. Establish kubectl credentials
		- Install aws-iam-authenticator(binary) and kubectl
		- $ aws eks update-kubeconfig --name '#Rename to cluster's_name'
		
Create Worker Nodes	
	1. Create an AutoScaling group of nodes with CloudFormation
	2. Create Node Auth with '$ kubectl apply -f aws-auth-cm.yaml'
	
Wait for the nodes to register
	$ kubectl get nodes -w
	
Ensure you can create an ELB
	$ aws iam create-service-linked-role --aws-service-name elasticloadbalancing.amazonaws.comaws
	
Use your Kubernetes Envrionment
	

--------------------------------------------------------------------------------------------
# EKS Supports Regions 
--------------------------------------------------------------------------------------------
https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/
us-west-2 (Oregon), us-east-1 (N. Virginia), us-east-2 (Ohio)
Ireland, Frankfurt, London,	Paris, Stockholm, Singapore, Tokyo, Sydney, Seoul, Mumbai
--------------------------------------------------------------------------------------------

--------------------------------------------------------------------------------------------
### ESK Setup Lab Info Gethering  ###
--------------------------------------------------------------------------------------------
IAM-ROLE-ARN: arn:aws:iam::688595016292:role/Cluster_EKS_Role

VPC-ID:vpc-0121526bc433d8e2b
SECURITY-GROUP-ID:sg-09222c96502064a3a
SUBNET-IDS:subnet-09442239f4e596b6d,subnet-069fb4ed48718a9f7,subnet-05a8b3907455065ce

NODE-ROLE-ARN:
LABEL-NODE-ROLE-ARN:
USER_ARN:


--------------------------------------------------------------------------------------------
1. Create IAM Accounts and Policy for 'CRUD' operations 
--------------------------------------------------------------------------------------------
  Create 2x Policies for EKS and CloudFormation Admins
	AWS -> IAM -> Policies -> Create Policy
		=> AdminEKSPolicy 
		=> AdminCloudFormationPolicy

----------------------------------------------------------
# Create Policy		
----------------------------------------------------------
  # Name: AdminEKSPolicy			<= for Kubernetes 
----------------------------------------------------------
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",			<= Full permisson
            "Action": [
                "eks:*"					<= All resource for EKS
            ],
            "Resource": "*"
        }
    ]
}
----------------------------------------------------------
  # Name: AdminCloudFormationPolicy		<= fot CM Tool
----------------------------------------------------------
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",			<= Permisson
            "Action": "*",				<= Full permisson
            "Resource": "*"				<= All resource
        }
    ]
}
----------------------------------------------------------
# Create Roll 
----------------------------------------------------------
	AWS -> IAM -> Roles -> Create Role -> AWS Service -> EKS -> Add 
	  - AmazonEKSServicePolicy 			<= From Existing Policy
      - AmazonEKSClusterPolicy 			<= From Existkuing Policy

	Create -> Name: Cluster_EKS_Roll

	IAM-ROLE-ARN: arn:aws:iam::6...2:role/Cluster_EKS_Role

-------------------------------------------------------------------
IAM: Creating ClusterAdmin and ClusterUser accounts
-------------------------------------------------------------------

-----------------------------------------------------
# Create User #1:  clusterAdmin
-----------------------------------------------------
  IAM -> Username: clusterAdmin 
	  -> Access Type: both Programmatic and console Access 
	  -> Password 
	  -> Attach 4 existing Policies 
	  
			1. AdminEKSPolicy					<= Newly created
			2. AdminCloudFormationPolicy		<= Newly created
			3. AmazonEKSServicePolicy 			<= From Existing   Policy
			4. AmazonEKSClusterPolicy 			<= From Existkuing Policy
	  
	  -> Download CSV
		
 - eks admin policy
 - k8s admin "system:master" group
 

-----------------------------------------------------
# Create User #2: clusterUser
-----------------------------------------------------
	IAM -> Username: clusterAdmin 
		-> Access Type: both Programmatic and console Access 
		-> Password 
		-> Attach 4 existing Policies 
		-> Download CSV


	Add policies: 
	  - AdminEKSPolicy					<= NEW
		
	- no IAM policies
	- k8s admin "system:master" group


--------------------------------------------------------------------------------------------
# CloudFormation - Create a Stack VPC Template From S3
--------------------------------------------------------------------------------------------
1. Check Region: us-west-02(Orgegon)

2. AWS Colsone 
	-> ESK 
	-> Create Cluster 
	-> Specify an AWS S3 template URL
	https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2018-08-30/amazon-eks-vpc-sample.yaml

  -> Stack name: classCluster (or classEKSVPC) 
	VPCBlock: 		192.168.0.0/16
	Subnet01Block: subnet1(192.168.64.0./18...)
	Subnet02Block: subnet2(192.168.128.0./18...)
	Subnet03Block: subnet3(192.168.192.0./18...)

  -> Reset Default to create
  -> From Output
		Key				Value					Description	       Export Name
		SecurityGroups	sg-09222c96502064a3a		
		VpcId			vpc-0121526bc433d8e2b		
		SubnetIds		subnet-09442239f4e596b6d,subnet-069fb4ed48718a9f7,subnet-05a8b3907455065ce 
	
	Copy from output:
	IAM-ROLE-ARN: arn:aws:iam::688595016292:role/Cluster_EKS_Role
	
	VPC-ID: vpc-0121526bc433d8e2b
	SECURITY-GROUP-ID:s g-09222c96502064a3a
	SUBNET-IDS: subnet-09442239f4e596b6d,subnet-069fb4ed48718a9f7,subnet-05a8b3907455065ce 

-------------------------------------------------------------------------------
# Setup 3x-Remote Tools 
	- Kubectl 
	- aws-iam-authenticator 
	- AWS CLI
	
-------------------------------------------------------------------------------
  1. Install "kubectl" 
	https://kubernetes.io/docs/tasks/tools/install-kubectl/
-------------------------------------------------------------------------------
  Linux:
	curl -LO https://storage.googleapis.com/kubernetes-release/release/\
		$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
  MacOS:
	curl -LO https://storage.googleapis.com/kubernetes-release/release/\
		$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl

	$ chmod + x kubectl
	$ mv kubectl /usr/local/bin
	# $ source .bash_profile				<= If kubectl not works, reload profile
	
	$ kubectl version --short --client
	
	-------------------------------------------------
	| ###  kubectl command syntax ###				|
	| $ kubectl [command] [TYPE] [NAME] [flags]		|	
	-------------------------------------------------
	
	---------------------------------------------------
	# Enabling shell auto-completion
	---------------------------------------------------
	https://kubernetes.io/docs/tasks/tools/install-kubectl/#enabling-shell-autocompletion
	$ kubectl completion -h						<= Check first
	
	$ yum install bash-completion -y
	$ source <(kubectl completion bash)
	$ echo "source <(kubectl completion bash)" >> ~/.bashrc
	
	$ kubectl  <TAB>		<= Autocompletion works!
	  annotate       autoscale      cordon         drain          label          proxy          taint
	  api-resources  certificate    cp             edit           logs           replace        top
	  api-versions   cluster-info   create         exec           options        rollout        uncordon
	  apply          completion     delete         explain        patch          run            version
	  attach         config         describe       expose         plugin         scale          wait
	  auth           convert        diff           get            port-forward   set

	
-------------------------------------------------------------------------------
  2. Download "aws-iam-authenticator" binary:
-------------------------------------------------------------------------------
	https://docs.aws.amazon.com/eks/latest/userguide/configure-kubectl.html
	https://github.com/kubernetes-sigs/aws-iam-authenticator
	-------------------------------------------------------------------------------
  Linux:
	curl -sLO https://amazon-eks.s3-us-west-2.amazonaws.com/1.10.3/2018-07-26/bin/linux/amd64/aws-iam-authenticator
  MacOS:
	curl -sLO https://amazon-eks.s3-us-west-2.amazonaws.com/1.10.3/2018-07-26/bin/darwin/amd64/aws-iam-authenticator
	
  $ chmod + x 	aws-iam-authenticator
  $ mv aws-iam-authenticator /usr/lcoal/bin   			<= echo $PATH location
  
-------------------------------------------------------------------------------
  3. Install "AWS CLI" 
	https://docs.aws.amazon.com/cli/latest/userguide/installing.html
-------------------------------------------------------------------------------
	$ sudo pip install awscli --ignore-installed six 		<= 1.16 EKS Works
	$ pip install awscli --upgrade --user
-------------------------------------------------------------------------------
	$ aws --version
		aw s-cli/1.16.115 Python/3.6.7 Linux/3.10.0-957.1.3.el7.x86_64 botocore/1.12.105

	# AWS sts (Security Token Service)
	$ aws sts get-caller-identity --output text --query 'Account'
		688595016292		<= account ID
	# get your account ID
		ACCOUNT_ID=$(aws sts get-caller-identity --output text --query 'Account')

	# 
	$ aws eks update-kubeconfig --name classEKS

	$  cat credentials
[default]
aws_access_key_id = AKIAJ...EZPUVFA
aws_secret_access_key = NJUpg...4fKJ2l
[clusterAdmin]
aws_access_key_id = AKIAJR...PUVFA
aws_secret_access_key = NJUpgo2+y...
[clusterUser]
aws_access_key_id = AKIA...7ABA
aws_secret_access_key = j8/8a....Rmgf2


-------------------------------------------------------------------------------
# Configuration on Linux Shell 
# Add to Environment Variable
-------------------------------------------------------------------------------
  # Config CLI for AWS and Kubectl
  # AWS CLI
  $ aws configure									<= Setup or update
	  AWS Access Key ID [****************UVFA]:
	  AWS Secret Access Key [****************KJ2l]:
	  Default region name [us-west-2]: 				<= Oregon
	  Default output format [json]: 				<= Only json works
   
    SYNOPSIS
     aws configure [--profile profile-name]  
	
	$ aws configure --profile=clusterAdmin			<=for 'clusterAdmin' User
	
	$ export AWS_PROFILE=clusterAdmin

	$ env | grep AWS_PROFILE									<= If no, add to env

***	$ echo "export AWS_PROFILE=clusterAdmin" >> .bash_profile	<= .bash_profile <= login shell 
																<= .bashrc 		 <= after login user shell
	
***	$ aws eks update-kubeconfig --name classEKS					<= Updated CLI
	
	# $ aws eks --region us-west-2 update-kubeconfig --name classEKS	<= Old CLI
	  => Updated context arn:aws:eks:us-west-2:688595016292:cluster/classCluster in /home/awseks/.kube/config

	$ aws eks list-clusters			<= Get EKS cluster info
	------------------------------------------
	{
		"clusters": [
			"classEKS"				<= AWS EKS Cluster Name
		]
	}
	------------------------------------------


-------------------------------------------------------------------------------
# EKS is Kubernetes Master Server
# Create a EKS Cluster from AWS Console
-------------------------------------------------------------------------------
AWS -> EKS -> Create Cluster -> 

# A New Cluster configuration(A new Kubernetes SERVER)
	Cluster name: classEKS
	Kubernetes Version -> 1.11   				<= Latest
	Role Name: Cluster_EKS_Role					<= grep from Role creation

# Networking	
	VPC 	-> vpc-xxx(192.168.0.0/16..)
	Subnets	-> subnet1(192.168.64.0./18...)
			   subnet2(192.168.128.0./18...)
			   subnet3(192.168.192.0./18...)	
			   
# Security groups -> sg-09222c96502064a3a
	
	>>> Create <<<	

-------------------------------------------------------------------------------
# Reigster cluster 'classEKS' to Kubectl
-------------------------------------------------------------------------------

# Check the cluster list
$ aws eks list-clusters
------------------------------------------
	{
		"clusters": [
			"classEKS"
		]
	}
------------------------------------------
# Register
------------------------------------------
$ aws eks update-kubeconfig --name classEKS
	Added new context arn:aws:eks:us-west-2:688595016292:cluster/classEKS to /home/awseks/.kube/config

----------------------------------------------------------------------------
# check if kubeclt actually communicating with 'classEKS'
----------------------------------------------------------------------------
$ kubectl get pods
	No resources found.						<= Good sign, no error
	
$ kubectl get nodes
	No resources found.
----------------------------------------------------------------------------
# test if pod can create apply hostname.yaml
----------------------------------------------------------------------------
$ kubectl apply -f hostname.yaml				
	deployment.extensions/hostname-v1 created	<= ok
	service/hostname-v1 created					<= ok

$ kubectl get pods
	NAME                           READY   STATUS    RESTARTS   AGE
	hostname-v1-56bc754656-njdgp   0/1     Pending   0          13s		
											^ <= It's pending cuz no workers to deploy
------------------------------------------
	# hostname.yaml
------------------------------------------
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: hostname-v1
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: hostname-v1
        version: v1
    spec:
      containers:
      - image: rstarmer/hostname:v1
        imagePullPolicy: Always
        name: hostname
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: hostname-v1
  name: hostname-v1
spec:
  ports:
  - name: web
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: hostname-v1
----------------------------------------

-------------------------------------------------------------------------------
# CloudFormation		<= for WORKER NODES Addition
# Adding Wokers Nodes(No-Labeled Nodes) to EKS 
-------------------------------------------------------------------------------

AWS -> CloudFormation 
	-> Create a New stack 
	-> Specify an Amazon S3 template URL
	   https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2018-08-30/amazon-eks-nodegroup.yaml
	-> Stack Name: eksNolabeledWorkerNodes
	-> Cluster Name: noLabeledCluster
	-> ClusterControlPlaneSecurityGroup: Learning-EKS-VPC
	-> NodeGroupName: noLabeledworkerNodes
	-> NodeAutoScaling size: 1~3				<= Min ~ max size of Node Group AutoScaleGroup.
	-> NodeVolumeSize: 20 						<= default
	-> NodeImageId: ami-0c28139856aaf9c3b		<= us-west-2(Oregon)<- ESK Optimized AMI
	-----------------------------------------------------------------------
	# Amazon EKS-Optimized AMI List
	https://docs.aws.amazon.com/eks/latest/userguide/eks-optimized-ami.html
	-----------------------------------------------------------------------
	-> KeyName:eksAdmin				<= EC2 access PEM key (EC2 -> Create a key Pair)

	-> Worker Network Configuration
		VpcId	: vpc-xxx(192.168.0.0/16..)					<= EKS' classCluster VPC
		Subnets	: subnet1(192.168.64.0./18...)				<= EKS' classCluster subnets
				  subnet2(192.168.128.0./18...)
				  subnet3(192.168.192.0./18...)			

	-> Options:  											<= pass on this		
	-> Check on Agree then Click on Create!
	
	Status: eksNolabeledWorkerNodes 2019-03-04 CREATE_IN_PROGRESS NOT_CHECKED Amazon EKS - Node Group 

-------------------------------------------------------------------------------
# After 'No-Labeled Workder Nodes' creatation is done, get eksNolabeledWorkerNodes' 
	'ARN' and add to 'rolearn' in order to the Kubectl accesses the 'eksNolabeledWorkerNodes'
    -> CouldFormation 
	-> Stacks 
	-> chose 'eksNolabeledWorkerNodes' 
	-> Stack Details 
	-> Outputs 
	-> copy value : arn:aws:iam::6...2:role/eksNolabeledWorkerNodes-NodeInstanceRole
	
-------------------------------------------------------------------------------
 $ vi aws-auth-cm.yaml
-------------------------------------------------------------------------------
apiVersion: v1
kind: ConfigMap
metadata:
  name: aws-auth
  namespace: kube-system
data:
  mapRoles: |
    - rolearn: arn:aws:iam::6...2:role/eksNolabeledWorkerNodes-NodeInstanceRole-14RJGE47079RC
    #- rolearn: <ARN of instance role (not an instance profile)>
      username: system:node:{{EC2PrivateDNSName}}
      groups:
        - system:bootstrappers
        - system:nodes
-------------------------------------------------------------------------------
$ kubectl apply -f aws-auth-cm.yaml
  Result => configmap/aws-auth created

$ kubectl config view

$ kubectl get nodes
	NAME                                            STATUS   ROLES    AGE   VERSION
	ip-192-168-120-42.us-west-2.compute.internal    Ready    <none>   58s   v1.11.5
	ip-192-168-165-134.us-west-2.compute.internal   Ready    <none>   1m    v1.11.5
	ip-192-168-201-63.us-west-2.compute.internal    Ready    <none>   1m    v1.11.5

-------------------------------------------------------------------------------
# Now it is deployed into the Woker Nodes and so as the POD
-------------------------------------------------------------------------------
$ kubectl get pods
	NAME                           READY   STATUS    RESTARTS   AGE
	hostname-v1-56bc754656-njdgp   1/1     Running   0          1h

-------------------------------------------------------------------------------
# AutoScalingGroup_Policy
-------------------------------------------------------------------------------
	AWS -> EC2 
		-> AutoScaling 
		-> Auto Scaling Group 
		-> Choose: eksNolabeledWorkerNodes
		-> Scaling Policies  
	------------------------------------------------------------------
	Name 	Launch Config.. 	 Instances Desired Min Max Availability Zones
	eks..	eksNolabeledWorkerNodes  3		3      1    3  us-west-02a,b,c
	------------------------------------------------------------------
	Add Policy  -> Name: scale-cpu-70 
				-> metric type: Ave CPU
				-> Target Value: 70
				-> Instances need: none
				- Disable scale-in: none
				
	>>> CREATE <<<
  ------------------------------------------------------------------------------------	
  # After AutoScalePolicy creation, it immediatly reduces number of Nodes from 3 to 1
  ------------------------------------------------------------------------------------
	$ kubectl get nodes
	NAME                                           STATUS   ROLES    AGE   VERSION
	ip-192-168-120-42.us-west-2.compute.internal   Ready    <none>   29m   v1.11.5
	ip-192-168-201-63.us-west-2.compute.internal   Ready    <none>   29m   v1.11.5

	
	$ kubectl get nodes
	NAME                                           STATUS   ROLES    AGE   VERSION
	ip-192-168-120-42.us-west-2.compute.internal   Ready    <none>   30m   v1.11.5 <= Only 1

-------------------------------------------------------------------------------
# Differenciate Workers - Video 12
# Auto Labeling Nodes during Auto Scaling since number of nodes are keep changing 
  manually labeling nodes update is impossible
-------------------------------------------------------------------------------	

	Manual update: $ kubectl lab nodes <node-name> <label-key>=<label-value>
	
-------------------------------------------------------------------------------
AWS -> CloudFormation 
	-> Create Stack 
	-> Specify template 
	-> Template source 
	-> Next
	-> S3 template
	https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2018-08-30/amazon-eks-nodegroup.yaml

--------------------------------------------
# checking EKS Cluster Name
--------------------------------------------

	$ aws eks list-clusters
	----------------------------------------
	{
		"clusters": [
			"classEKS"    <== USE THIS Cluster Name !!
		]
	}
--------------------------------------------
  # Specify stack details
--------------------------------------------
	Stack name: labeledNodes
	
	EKS Cluster
		ClusterName: classEKS				<===!!!  If wrong, CAN't JOIN EKS Cluster!!!!
		ClusterControlPlaneSecurityGroup: Learning-EKS-VPC....3a)
	
	Worker Node Configuration
		NodeGroupName: labeledNodes
		NodeAutoScalingGroupMinSize: 1
		NodeAutoScalingGroupMaxSize: 3
		NodeInstanceType: t2.small
		NodeImageID: ami-0c28139856aaf9c3b		<= us-west-2(Oregon)<- ESK Optimized AMI
		KeyName: eksAdmin						<= Key Pair
		
		# A script pass to the argument and add '--node-labels' for labeling #
		BootstrapArguments:--kubelet-extra-args '--node-labels "nodetype=generalpurpose"'	
			
	
	Worker Network Configuration
		VpcId:vpc-xxx(192.168.0.0/16..)
		Subnets: subnet1(192.168.64.0./18...)
				 subnet2(192.168.128.0./18...)
				 subnet3(192.168.192.0./18...)	

	# Go to labelNodes -> Outputs -> get the ARN 
	
-------------------------------------------------------------------------------				 
# Edit and Add 'Label Nodes ARN' to aws-auth-cm+NodesLabel.yaml
-------------------------------------------------------------------------------				 
apiVersion: v1
kind: ConfigMap
metadata:
  name: aws-auth
  namespace: kube-system
data:
  mapRoles: |
	# No-Labeled Nodes Cluster
    - rolearn: arn:aws:iam::688595016292:role/eksWorkerNodesStack-NodeInstanceRole-14RJGE47079RC
      username: system:node:{{EC2PrivateDNSName}}
      groups:
        - system:bootstrappers
        - system:nodes
	# Labeled Nodes Enabled Cluster	
    - rolearn: 	arn:aws:iam::688595016292:role/labelNodes-NodeInstanceRole-8QKQNDGMVNQ5
      username: system:node:{{EC2PrivateDNSName}}
      groups:
        - system:bootstrappers
        - system:nodes		
-------------------------------------------------------------------------------	
$ kubectl apply -f aws-auth-cm+NodesLabel.yaml
# System should apply for TWO different ROLES 'No-Labeled' and 'Labeled' Clusters

$ kubectl get nodes
	  NAME                                            STATUS   ROLES    AGE   VERSION
Labeled	=> ip-192-168-112-219.us-west-2.compute.internal   Ready    <none>   8m    v1.11.5
Labeled	=> ip-192-168-137-151.us-west-2.compute.internal   Ready    <none>   7m    v1.11.5
Labeled	=> ip-192-168-199-194.us-west-2.compute.internal   Ready    <none>   6m    v1.11.5

No-Labeled=> ip-192-168-120-42.us-west-2.compute.internal    Ready    <none>   19h   v1.11.5

-------------------------------------------------------------------------------	
# $ vi hostnameLabeled.yaml
-------------------------------------------------------------------------------	
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: hostname-v2
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: hostname-v2
        version: v2
    spec:
      containers:
      - image: rstarmer/hostname:v2
        imagePullPolicy: Always
        name: hostname
      nodeSelector:								# <=
        nodetype: generalpurpose				# <= 
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: hostname-v2
  name: hostname-v2							#Labeled as hostname-v2
spec:
  ports:
  - name: web
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: hostname-v2
-------------------------------------------------------------------------------	
$ kubectl apply -f hostnameLabeled.yaml

$ kubectl get pods

				NAME                           READY   STATUS    RESTARTS   AGE
No-Labeled 	=>	hostname-v1-56bc754656-j8mwh   1/1     Running   0          19h
Labeled 	=>	hostname-v2-6499cb8cc8-w6w4s   1/1     Running   0          1m			
				 v2 <= renamed with V2

-------------------------------------------------------------------------------
$ kubectl describe pod hostname-v2-6499cb8cc8-w6w4s

Name:               hostname-v2-6499cb8cc8-w6w4s
Namespace:          default
Priority:           0
PriorityClassName:  <none>
Node:               ip-192-168-199-194.us-west-2.compute.internal/192.168.199.194
Start Time:         Wed, 06 Mar 2019 11:38:03 -0800
Labels:             app=hostname-v2						## Labels
                    pod-template-hash=2055764774
                    version=v2
Annotations:        <none>
Status:             Running
IP:                 192.168.201.177
Controlled By:      ReplicaSet/hostname-v2-6499cb8cc8
Containers:
  hostname:
    Container ID:   docker://61ce17272e9
    Image:          rstarmer/hostname:v2
    Image ID:       docker-pullable://rstarmer/hostname@sha256:e0
    Port:           <none>
    Host Port:      <none>
    State:          Running
    Started:        Wed, 06 Mar 2019 11:38:10 -0800
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rgwhg (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True
Volumes:
  default-token-rgwhg:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-rgwhg
    Optional:    false
QoS Class:       BestEffort


------------------------------------------
Node-Selectors:  nodetype=generalpurpose		<= This is what we are looking for
------------------------------------------
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age    From                    Message
  ----    ------     ----   ----                    -------


-------------------------------------------------------------------------------
# Creating Storage Class - Video 14
	Read: https://kubernetes.io/docs/concepts/storage/storage-classes/#aws-ebs
	Storage types: io1, gp2, sc1, st1. See AWS docs for details. 
	Default: gp2 <= General Purpose Storage
-------------------------------------------------------------------------------
- By default EKS doesn't have any storage classes defined, and we need to 
	have a storage class model in order to be able to create 'persistent storage.'
=> Simply enable the 'storage class connection' to the underlying EBS service.

- Create a "standard" EBS volume to set as DEFAULT.

----------------------------------------------------
	# GP2 - General Purpose Storage
----------------------------------------------------

	$ kubectl apply -f generalPurpose-storage.yaml

----------------------------------------------------
	$ vi generalPurpose-storage.yaml
----------------------------------------------------
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: gp2
  annotations:
    storageclass.kubernetes.io/is-default-class: 'true'
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2			
reclaimPolicy: Retain			<= Persistent EBS Volume Retain
mountOptions:
  - debug

----------------------------------------------------
# Fast Storage
# Creating some Fast (100 iops/GB) SSD Storage
----------------------------------------------------
	
	$ kubectl apply -f fast-storage.yaml
	
----------------------------------------------------
$ vi fast-storage.yaml
----------------------------------------------------
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: fast-100
provisioner: kubernetes.io/aws-ebs
parameters:
  type: io1							<= io1 type
  iopsPerGB: "100"					<= 20,000 iops is Max
reclaimPolicy: Retain				<= Persistent EBS Volume Retain
mountOptions:
  - debug
-------------------------------------------------------------------------------
$ kubectl create -f fast-storage.yaml

	storageclass.storage.k8s.io/fast-100 created

$ kubectl create -f generalPurpose-storage.yaml		

	Error from server (AlreadyExists): error when creating 	
	"generalPurpose-storage.yaml": storageclasses.storage.k8s.io "gp2" already exists


$ kubectl get storageclasses
	NAME            PROVISIONER             AGE
	fast-100        kubernetes.io/aws-ebs   1m
	gp2 (default)   kubernetes.io/aws-ebs   22h

-------------------------------------------------------------------------------
# Storage Persistent Claim	- Video 15 
# Mapping Storage
-------------------------------------------------------------------------------


-------------------------------------------------------------------------------
	$ vi hostname-volume.yaml
-------------------------------------------------------------------------------
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: hostname-volume
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: hostname-volume
        version: v1
    spec:
      volumes:
      - name: hostname-pvc					#PVC - persist volume claim
        persistentVolumeClaim:
          claimName: hostname-pvc
      containers:
      - image: rstarmer/hostname:v1
        imagePullPolicy: Always
        name: hostname
        volumeMounts:
          - mountPath: "/www"
            name: hostname-pvc
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: hostname-volume
  name: hostname-volume
spec:
  ports:
  - name: web
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: hostname-volume
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: hostname-pvc
spec:
  storageClassName: gp2
  accessModes:
    - ReadWriteOnce					# Can't share 'ReadWriteOnce' 
  resources:
    requests:
      storage: 1Gi
-------------------------------------------------------------------------------

$ kubectl apply -f hostname-volume.yaml

	deployment.extensions/hostname-volume created
	service/hostname-volume created
	persistentvolumeclaim/hostname-pvc created

$ kubectl get pv			# Persistent Volume

  NAME     CAPACITY  ACCESS MODES  RECLAIM POLICY STATUS CLAIM             STORAGECLASS   AGE
  pvc-60.d4  1Gi      RWO            Delete       Bound  default/hostname-pvc   gp2       19s

$ kubectl get pvc -o wide

  NAME           STATUS   VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS   AGE
  hostname-pvc   Bound    pvc-...   1Gi        RWO            gp2            3m

-------------------------------------------------------------------------------

$ kubectl get pod -l app=hostname-volume -o jsonpath={.items..metadata.name}

  hostname-volume-8479ffdd6f-nhjv2

$ kubectl exec -it $(kubectl get pod -l app=hostname-volume -o jsonpath={.items..metadata.name}) -- df -h /www

	Filesystem      Size  Used Avail Use% Mounted on
	/dev/xvdbr      976M  2.6M  958M   1% /www

-------------------------------------------------------------------------------
### Clean Up + Persistent Volumes ###
-------------------------------------------------------------------------------
clean up hostname-volume "Stack" with:

$ kubectl delete -f hostname-volume.yaml
-------------------------------------------------------------------------------
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: hostname-volume
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: hostname-volume
        version: v1
    spec:
      volumes:
      - name: hostname-pvc
        persistentVolumeClaim:
          claimName: hostname-pvc
      containers:
      - image: rstarmer/hostname:v1
        imagePullPolicy: Always
        name: hostname
        volumeMounts:
          - mountPath: "/www"
            name: hostname-pvc
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: hostname-volume
  name: hostname-volume
spec:
  ports:
  - name: web
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: hostname-volume
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: hostname-pvc
spec:
  storageClassName: gp2
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
-------------------------------------------------------------------------------
 
$ kubectl delete -f hostname-volume.yaml

	deployment.extensions "hostname-volume" deleted
	service "hostname-volume" deleted
	persistentvolumeclaim "hostname-pvc" deleted

# To Check  EC2 -> Volume 

  kubernetes-dynamic-pvc-60069873-..

$ kubectl get pv

  No resources found.

$ kubectl delete pv $(kubectl get pv -o jsonpath={.items..metadata.name})


-------------------------------------------------------------------------------
# Networking  (File > 03-05)
# Video 18
-------------------------------------------------------------------------------
Networking in EKS uses the 'VPC-CNI' project to use the AWS VPC network model 
to provide connectivity across the cluster.  
This is more efficient than having another layer of networking (e.g. Flannel, 
Calico, Weave, etc.) deployed as an overlay on top of the system, and maps 
perfectly into the VPC environment, using the VPC network management and IPAM 
services to support address management further improving the efficiency of 
the overall Kubernetes deployment.
-----------------------------------------------------------
# Deploy Alpine image -	A minimal Docker image based on Alpine Linux with 
						a complete package index and only 5 MB in size!
-----------------------------------------------------------
$ kubectl run --image alpine alpine sleep 3600 #(1hr)

	kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed 
	in a future version. 
	Use 'kubectl run --generator=run-pod/v1' or 'kubectl create' instead.
	deployment.apps/alpine created

$ kubectl get pods
	NAME                           READY   STATUS    RESTARTS   AGE
	alpine-6b9858595b-7zncb        1/1     Running   0          1m	<= Alpine image
	hostname-v1-56bc754656-j8mwh   1/1     Running   0          1d
	hostname-v2-6499cb8cc8-w6w4s   1/1     Running   0          5h

# Finding IP Addresses
$ IPs=`kubectl get pod $(kubectl get pod -l run=alpine -o \
	  jsonpath={.items..metadata.name}) -o yaml | awk '/IP/ {print $2}'`

$ echo $IPs
	192.168.137.151 192.168.133.249

$ for i in $IPs; do kubectl exec -it $(kubectl get pod -l run=alpine -o \
	jsonpath={.items..metadata.name})  traceroute $i ; done

	traceroute to 192.168.137.151 (192.168.137.151), 30 hops max, 46 byte packets
		1  192.168.137.151 (192.168.137.151)  0.006 ms  0.007 ms  0.002 ms
	
	traceroute to 192.168.133.249 (192.168.133.249), 30 hops max, 46 byte packets
		1  alpine-6b9858595b-7zncb (192.168.133.249)  0.005 ms  0.002 ms  0.002 ms

-------------------------------------------------------------------------------
# Load Balancing and Ingress( Adding ingress is a Kubernetes function)
# Adding 'traefik' Loadbalancer
# video-19 (File 03-06)
-------------------------------------------------------------------------------
	We'll add the 'Traefik load balancer' as an ingress function, and make use of 
	the EKS integration with Amazon ELB to enable external access.

	As ingress can route based on DNS, we can also do a little DNS manipulation to 
	get traffic routed to our resources.

1) Since we're using 1.10.0 Kubernetes(or newer) we'll need to make sure we have 
   a 'cluster role binding' for the services to use(Much like IAM):
   
   # RBAC <= Role-based access control  

$ kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-rbac.yaml
#-----------------------------------------------------
### Cluster Roles and Role Binding (Much like IAM) ###
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: traefik-ingress-controller
rules:
  - apiGroups:
      - ""
    resources:
      - services
      - endpoints
      - secrets
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - extensions
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
    - extensions
    resources:
    - ingresses/status
    verbs:
    - update
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: traefik-ingress-controller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: traefik-ingress-controller
subjects:
- kind: ServiceAccount
  name: traefik-ingress-controller
  namespace: kube-system
#-----------------------------------------------------
	#Result
	clusterrole.rbac.authorization.k8s.io/traefik-ingress-controller created
	clusterrolebinding.rbac.authorization.k8s.io/traefik-ingress-controller created


2) Turn on traffic deployment
	We'll leverage the deployment model for our ingress controller, as we don't 
   necessarily want to bind host address, and would rather have the ingress transit 
   through the normal 'kube-proxy' functions (note that we're changing the default 
   "NodePort" type to "LoadBalancer"):

$ kubectl apply -f <(curl -so - https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-deployment.yaml\
					| sed -e 's/NodePort/LoadBalancer/')
					
#-----------------------------------------------------					
### Turn on traffic deployment ### 
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
---
kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
  labels:
    k8s-app: traefik-ingress-lb
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: traefik-ingress-lb
  template:
    metadata:
      labels:
        k8s-app: traefik-ingress-lb
        name: traefik-ingress-lb
    spec:
      serviceAccountName: traefik-ingress-controller
      terminationGracePeriodSeconds: 60
      containers:
      - image: traefik
        name: traefik-ingress-lb
        ports:
        - name: http
          containerPort: 80
        - name: admin
          containerPort: 8080
        args:
        - --api
        - --kubernetes
        - --logLevel=INFO
---
kind: Service
apiVersion: v1
metadata:
  name: traefik-ingress-service
  namespace: kube-system
spec:
  selector:
    k8s-app: traefik-ingress-lb
  ports:
    - protocol: TCP
      port: 80
      name: web
    - protocol: TCP
      port: 8080
      name: admin
  type: NodePort
#-----------------------------------------------------
  # Result
  serviceaccount/traefik-ingress-controller created
  deployment.extensions/traefik-ingress-controller created
  service/traefik-ingress-service created

-----------------------------------------------------
# Get Services info
-----------------------------------------------------
  $ kubectl get svc

	NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
	hostname-v1   ClusterIP   10.100.81.10    <none>        80/TCP    1d
	hostname-v2   ClusterIP   10.100.148.78   <none>        80/TCP    5h
	kubernetes    ClusterIP   10.100.0.1      <none>        443/TCP   1d

  # Get system service
  $ kubectl get svc -n kube-system

	NAME                       TYPE           CLUSTER-IP     EXTERNAL-IP                     	   PORT(S)                       AGE
	kube-dns                   ClusterIP      10.100.0.10    <none>                          	   53/UDP,53/TCP                 1d
	traefik-ingress-service    LoadBalancer   10.100.35.58   a63..714.us-west-2.elb.amazonaws.com  80:32575/TCP,8080:30184/TCP   2m
	   ^ <= We're looking for  ^ <=Changed NodePort to LB

-----------------------------------------------------
# Get the Load Balancer service address
-----------------------------------------------------

$ export INGRESS=`kubectl get svc -n kube-system traefik-ingress-service -o jsonpath={.status.loadBalancer.ingress[0].hostname}`

$ echo $INGRESS
	a63d...714.us-west-2.elb.amazonaws.com			<= Same as 
			^ <= Same as: traefik-ingress-service    LoadBalancer   10.100.35.58   a63..714.us-west-2.elb.amazonaws.com  

$ export INGRESS_ADDR=`host $INGRESS | head -1 | cut -d' ' -f 4`
$ echo $INGRESS_ADDR
	52.25.57.209

$ host $INGRESS
	a63dff7ec407411e999b70ac8c63844e-2061030714.us-west-2.elb.amazonaws.com has address 52.25.57.209
	a63dff7ec407411e999b70ac8c63844e-2061030714.us-west-2.elb.amazonaws.com has address 34.217.247.157
	a63dff7ec407411e999b70ac8c63844e-2061030714.us-west-2.elb.amazonaws.com has address 52.36.19.123


# We can now expose our hostname app as an ingress resource:

$ kubectl create -f hostname-ingress.yaml

------------------------------------------------------
# hostname-ingress.yaml
------------------------------------------------------
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: hostname-ingress					# hostname-v1
  namespace: default
spec:
  rules:
  - host: hostname-v1.local
    http:
      paths:
      - path: /
        backend:
          serviceName: hostname-v1			# Pointing at
          servicePort: web
------------------------------------------------------

  # Result 
    ingress.extensions/hostname-ingress created


------------------------------------------------------
3) Add an entry to the local Linux server's /etc/hosts file to point to our resource:
------------------------------------------------------

$ echo "$INGRESS_ADDR hostname-v1.local" | sudo tee -a /etc/hosts
  
  52.25.57.209 hostname-v1.local

$ cat /etc/hosts
  127.0.0.1    localhost localhost.localdomain ...
  ::1          localhost localhost.localdomain ...
  52.25.57.209 hostname-v1.local

$ curl -v http://hostname-v1.local
  * About to connect() to hostname-v1.local port 80 (#0)
  *   Trying 52.25.57.209...
  * Connected to hostname-v1.local (52.25.57.209) port 80 (#0)
  > GET / HTTP/1.1
  > User-Agent: curl/7.29.0
  > Host: hostname-v1.local
  > Accept: */*


# Curl Data Flow

1. 	=> $Curl to Exlternal Address(52.25.57.209) with 'hostname-v1.local' 
	=> Map throught Ingress Controller
	=> AWS ELB 
	=> EKS Cluster 
	=> EKS Cluster Ingress 
	=> Talks to host-v1 service 
	=> host-v1 service Points to Deployment 
	=> Points to the POD
	
	
	
	
------------------------------------------------------
------------------------------------------------------
# Network policy with Calico
# Video 21,  file 04-01
------------------------------------------------------
------------------------------------------------------
In order to enable VPC Layer Network Policy, a CNI(Container Network Interface) network needs to be in place, 
and by default the VPC based networking in EKS is already configured appropriately.  

Policy however is not part of the VPC networking provided by Amazon, and instead, 
an integration with the Calico policy manager has been integrated with the VPC CNI service.

# calico CNI policy manifest from the Amazon VPC CNI project:
# Install Calico Extension top of VPC
# This will create a daemonset running the calico policy engine on each configured node.

$ kubectl apply -f https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/release-1.1/config/v1.1/calico.yaml

#------------------------------------------------------
# https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/release-1.1/config/v1.1/calico.yaml
---
kind: DaemonSet
apiVersion: extensions/v1beta1
metadata:
  name: calico-node
  namespace: kube-system
  labels:
    k8s-app: calico-node
spec:
  selector:
    matchLabels:
      k8s-app: calico-node
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        k8s-app: calico-node

   ........... To many lines

---
apiVersion: v1
kind: Service
metadata:
  name: calico-typha
  namespace: kube-system
  labels:
    k8s-app: calico-typha
spec:
  ports:
    - port: 5473
      protocol: TCP
      targetPort: calico-typha
      name: calico-typha
  selector:
    k8s-app: calico-typha
#------------------------------------------------------

  # Result
	daemonset.extensions/calico-node created
	
	error: error validating "https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/release-1.1/config/v1.1/calico.yaml": 
	error validating data: ValidationError(CustomResourceDefinition): unknown field "description" in io.k8s.apiextensions-
	apiserver.pkg.apis.apiextensions.v1beta1.CustomResourceDefinition; if you choose to ignore these errors, turn validation 
	off with --validate=false
	??????????????????????????????  too many errors
	
	
   # Let's run a container with curl enabled to test our target system 
	(hostname-v1 from the initial install):
	
	$ kubectl run --image rstarmer/curl:v1 curl

	  kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed 
	  in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.
	
	  => deployment.apps/curl created

	
  # Verify <= communicate to the http://hostname-v1 service endpoint:

	$ kubectl exec -it $(kubectl get pod -l run=curl -o jsonpath={.items..metadata.name})  \
	          -- curl --connect-timeout 5 http://hostname-v1
	# Output		  
	------------------------------------------------------
	<HTML>
	<HEAD>
	<TITLE>This page is on hostname-v1-56bc754656-j8mwh and is version v1</TITLE>
	</HEAD><BODY>
	<H1>THIS IS HOST hostname-v1-56bc754656-j8mwh</H1>
	<H2>And we're running version: v1</H2>
	</BODY>
	</HTML>
	------------------------------------------------------
	
	$kubectl get pods
	NAME                           READY   STATUS    RESTARTS   AGE
	alpine-6b9858595b-7zncb        1/1     Running   23         23h
	curl-66df598c4-zwz5v           1/1     Running   0          4m
	hostname-v1-56bc754656-j8mwh** 1/1     Running   0          1d		<= This is responding
	hostname-v2-6499cb8cc8-w6w4s   1/1     Running   0          1d

  #------------------------------------------------------
  # DENY All Acess
  #------------------------------------------------------
	$ vi deny-all.yaml
#------------------------------------------------------
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: deny-all
  namespace: default
spec:
  podSelector:
    matchLabels: {}		<= Nothing match, so no access
#------------------------------------------------------

	$ kubectl apply -f default-deny.yaml
		networkpolicy.networking.k8s.io/default-deny created 	<= Confirm

	
	# Verify
	
	$ kubectl exec -it $(kubectl get pod -l run=curl -o jsonpath={.items..metadata.name})  \
	          -- curl --connect-timeout 5 http://hostname-v1

	# curl:(28)Connection time out after 5001 milliseconds <= Should be 
	

  #------------------------------------------------------
  # Allow All Acess
  #------------------------------------------------------

	$ kubectl apply -f allow-all.yaml


# $ vi  allow-all.yaml

#------------------------------------------------------
kind: NetworkPolicy
apiVersion: extensions/v1beta1
metadata:
  namespace: default
  name: allow-all
spec:
  podSelector:
    matchLabels:
      app: hostname-v1				<= Allow to this host
  ingress:
    - from:
        - namespaceSelector:
            matchLabels: {}
#------------------------------------------------------


$ kubectl exec -it $(kubectl get pod -l run=curl -o jsonpath={.items..metadata.name})  \
	-- curl --connect-timeout 5 http://hostname-v1

<HTML>
<HEAD>
<TITLE>This page is on hostname-v1-56bc754656-j8mwh and is version v1</TITLE>
</HEAD><BODY>
<H1>THIS IS HOST hostname-v1-56bc754656-j8mwh</H1>
<H2>And we're running version: v1</H2>
</BODY>
</HTML>

#------------------------------------------------------
# AWS IAM and K8s RBAC(Role Based Access Control)
# Video 22 | file 04-02
#------------------------------------------------------
AW IAM(Tokens) <--> AWS-IAM-Authenticator(Local) <--> Kubectl CLI

  Users within the EKS environment are authenticated through AWS IAM, 
  which provides enhanced security.  
  If we add our 'clusterUser' credentials to the local aws client, 
  we will see that kubernetes will still try to talk to the API, but will fail:

# clusterUser Info
	User name: 			clusterUser
	Access key ID: 		AKIAIN...Y7ABA
	Secret access key:	j8/8ar...Rmgf2
	
$ cat ~/Downloads/credentials-clusterUser.csv
$ aws configure --profile=clusterUser
$ export AWS_PROFILE=clusterUser
$ env | grep AWS
	AWS_PROFILE=clusterUser
	
$ kubectl get pods		<= This will and should FAIL!!!
	error: the server doesn't have a resource type "pods"  <= Cuz of Permission

# Change to clusterAdmin profile to work again
	
$ export AWS_PROFILE=clusterAdmin

$ kubectl get pods
	-----------------------------------------------------------------
	NAME                           READY   STATUS    RESTARTS   AGE
	alpine-6b9858595b-7zncb        1/1     Running   24         1d
	curl-66df598c4-zwz5v           1/1     Running   0          54m
	hostname-v1-56bc754656-j8mwh   1/1     Running   0          2d
	hostname-v2-6499cb8cc8-w6w4s   1/1     Running   0          1d
	-----------------------------------------------------------------

$ export AWS_PROFILE=clusterAdmin

$ kubectl edit configmap aws-auth -n kube-system

  Adding additional users to the kubernetes cluster in EKS is done by adding new
  users to the "system:masters" group which maps to the equivalent of the ClusterAdmin 
  role in Kubernetes RBAC rules.

  The key parameter we need is the User's IAM ARN, which can be pulled from the 
  User IAM page in the AWS console:

---------------------------------------------
data:
  mapUsers: |
    - userarn: USER-ARN
      username: admin
      groups:
        - system:masters
---------------------------------------------
		
  We need to add the mapUsers: section to the aws-auth-cm.yaml document, and we 
  can do that either locally and "apply" the changes, or we can edit the document 
  in place in the kubernetes service.

We will edit the file in place, as we don't want to have to recreate the 
worker node role mappings which are part of the same auth structure:

$ export AWS_PROFILE=clusterAdmin
$ kubectl edit configmap aws-auth -n kube-system

Once we're done with the edit, we can switch back to our 'clusterUser' and we 
should have access to the system:

$ export AWS_PROFILE=clusterUser
$ kubectl get pods

Add the mapUsers: section right after the data: key, above the mapRoles: | line. 
It should look similar to the aws-auth-cm.yaml document.
---------------------------------------------
$ vi aws-auth-cm.yaml
---------------------------------------------
apiVersion: v1
kind: ConfigMap
metadata:
  name: aws-auth
  namespace: kube-system
data:
  mapUsers: |
    - userarn: USER-ARN
      username: admin
      groups:
        - system:masters		<= Master Group allows to access the EKS
  mapRoles: |
    - rolearn: NODE-ROLE-ARN
      username: system:node:{{EC2PrivateDNSName}}
      groups:
        - system:bootstrappers
        - system:nodes
    - rolearn: LABEL-NODE-ROLE-ARN
      username: system:node:{{EC2PrivateDNSName}}
      groups:
        - system:bootstrappers
        - system:nodes
---------------------------------------------



#------------------------------------------------------
#------------------------------------------------------
# Prometheus Install on LOCAL PC
# Video 24 | file 05-02
#------------------------------------------------------
#------------------------------------------------------

Install on CentOS7
$ wget https://storage.googleapis.com/kubernetes-helm/helm-v2.11.0-linux-amd64.tar.gz
$ tar -xzvf helm-v2.11.0-linux-amd64.tar.gz
$ sudo cp linux-amd64/helm /usr/local/bin/

---------------------------------------------
$ vi helm-rbac.yaml
---------------------------------------------
# Create a service account for Helm and grant the cluster admin role.
# It is assumed that helm should be installed with this service account
# (tiller).
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: tiller
  namespace: kube-system
---------------------------------------------

$ kubectl create -f helm-rbac.yaml
	serviceaccount/tiller created
	clusterrolebinding.rbac.authorization.k8s.io/tiller created

$ sudo cp linux-amd64/helm    /usr/local/bin/

$ helm init --service-account=tiller
------------------------------------------------------------------------------------------
Creating /home/awseks/.helm
Creating /home/awseks/.helm/repository
Creating /home/awseks/.helm/repository/cache
Creating /home/awseks/.helm/repository/local
Creating /home/awseks/.helm/plugins
Creating /home/awseks/.helm/starters
Creating /home/awseks/.helm/cache/archive
Creating /home/awseks/.helm/repository/repositories.yaml
Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com
Adding local repo with URL: http://127.0.0.1:8879/charts
$HELM_HOME has been configured at /home/awseks/.helm.

Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster.

Please note: by default, Tiller is deployed with an insecure 'allow unauthenticated users' policy.
To prevent this, run `helm init` with the --tiller-tls-verify flag.
For more information on securing your installation see: 
https://docs.helm.sh/using_helm/#securing-your-helm-installation
https://github.com/helm/helm

Helm      <= is a tool for managing Kubernetes charts. 
   Charts <= are packages of pre-configured Kubernetes resources.
------------------------------------------------------------------------------------------
 
 Once Helm is installed, launching Prometheus is a simple command, though note that we are
 defining the storage class that Prometheus should use to store it's metrics:


$ helm install --name PrometheusEKS --set server.persistentVolume.storageClass=gp2 stable/prometheus

------------------------------------------------------------------------------------------
NAME:   promeks
LAST DEPLOYED: Mon Mar 11 10:44:59 2019
NAMESPACE: default
STATUS: DEPLOYED

RESOURCES:
==> v1beta1/ClusterRole
NAME                                   AGE
promeks-prometheus-kube-state-metrics  1s
promeks-prometheus-server              1s

==> v1beta1/ClusterRoleBinding
promeks-prometheus-kube-state-metrics  1s
promeks-prometheus-server              1s

==> v1beta1/DaemonSet
promeks-prometheus-node-exporter  1s

==> v1beta1/Deployment
promeks-prometheus-alertmanager        1s
promeks-prometheus-kube-state-metrics  1s
promeks-prometheus-pushgateway         1s
promeks-prometheus-server              1s

==> v1/Pod(related)

NAME                                                    READY  STATUS             RESTARTS  AGE
promeks-prometheus-node-exporter-hrh5q                  0/1    ContainerCreating  0         1s
promeks-prometheus-node-exporter-krb62                  0/1    ContainerCreating  0         1s
promeks-prometheus-node-exporter-nd5cz                  0/1    ContainerCreating  0         1s
promeks-prometheus-node-exporter-r5k8p                  0/1    ContainerCreating  0         1s
promeks-prometheus-alertmanager-769c8b64b5-g5hfh        0/2    Pending            0         1s
promeks-prometheus-kube-state-metrics-5b44db6dbc-jx8sf  0/1    ContainerCreating  0         1s
promeks-prometheus-pushgateway-7dcf9b6cd8-wdgd4         0/1    ContainerCreating  0         1s
promeks-prometheus-server-5486d488d5-mrjvl              0/2    Init:0/1           0         1s

==> v1/ConfigMap

NAME                             AGE
promeks-prometheus-alertmanager  1s
promeks-prometheus-server        1s

==> v1/PersistentVolumeClaim
promeks-prometheus-alertmanager  1s
promeks-prometheus-server        1s

==> v1/ServiceAccount
promeks-prometheus-alertmanager        1s
promeks-prometheus-kube-state-metrics  1s
promeks-prometheus-node-exporter       1s
promeks-prometheus-pushgateway         1s
promeks-prometheus-server              1s

==> v1/Service
promeks-prometheus-alertmanager        1s
promeks-prometheus-kube-state-metrics  1s
promeks-prometheus-node-exporter       1s
promeks-prometheus-pushgateway         1s
promeks-prometheus-server              1s


NOTES:
The Prometheus server can be accessed via port 80 on the following DNS name from within your cluster:
promeks-prometheus-server.default.svc.cluster.local


Get the Prometheus server URL by running these commands in the same shell:
  export POD_NAME=$(kubectl get pods --namespace default -l "app=prometheus,component=server" -o jsonpath="{.items[0].metadata.name}")
  kubectl --namespace default port-forward $POD_NAME 9090


The Prometheus 'alertmanager' can be accessed via port 80 on the following DNS name from within your cluster:
promeks-prometheus-alertmanager.default.svc.cluster.local


Get the Alertmanager URL by running these commands in the same shell:
  export POD_NAME=$(kubectl get pods --namespace default -l "app=prometheus,component=alertmanager" -o jsonpath="{.items[0].metadata.name}")
  kubectl --namespace default port-forward $POD_NAME 9093


The Prometheus PushGateway can be accessed via port 9091 on the following DNS name from within your cluster:
promeks-prometheus-pushgateway.default.svc.cluster.local


Get the PushGateway URL by running these commands in the same shell:
  export POD_NAME=$(kubectl get pods --namespace default -l "app=prometheus,component=pushgateway" -o jsonpath="{.items[0].metadata.name}")
  kubectl --namespace default port-forward $POD_NAME 9091

------------------------------------------------------------------------------------------

# Watch the deployment Progress 
$ kubectl get pods -w  

NAME                                                     READY   STATUS              RESTARTS   AGE
alpine-6b9858595b-7zncb                                  1/1     Running             113        4d17h
curl-66df598c4-zwz5v                                     1/1     Running             8          3d17h
hostname-v1-56bc754656-j8mwh                             1/1     Running             0          5d17h
hostname-v2-6499cb8cc8-w6w4s                             1/1     Running             0          4d22h
promeks-prometheus-alertmanager-769c8b64b5-g5hfh         0/2     ContainerCreating   0          40s
promeks-prometheus-kube-state-metrics-5b44db6dbc-jx8sf   1/1     Running             0          40s
promeks-prometheus-node-exporter-hrh5q                   1/1     Running             0          40s
promeks-prometheus-node-exporter-krb62                   1/1     Running             0          40s
promeks-prometheus-node-exporter-nd5cz                   1/1     Running             0          40s
promeks-prometheus-node-exporter-r5k8p                   1/1     Running             0          40s
promeks-prometheus-pushgateway-7dcf9b6cd8-wdgd4          1/1     Running             0          40s
promeks-prometheus-server-5486d488d5-mrjvl               1/2     Running             0          40s
promeks-prometheus-alertmanager-769c8b64b5-g5hfh   1/2   Running   0     44s
promeks-prometheus-server-5486d488d5-mrjvl   2/2   Running   0     61s
promeks-prometheus-alertmanager-769c8b64b5-g5hfh   2/2   Running   0     76s
curl-66df598c4-zwz5v   0/1   Completed   8     3d18h
curl-66df598c4-zwz5v   1/1   Running   9     3d18h


$ kubectl get nodes
NAME                                            STATUS   ROLES    AGE   VERSION
ip-192-168-112-219.us-west-2.compute.internal   Ready    <none>   4d    v1.11.5
ip-192-168-120-42.us-west-2.compute.internal    Ready    <none>   5d    v1.11.5
ip-192-168-137-151.us-west-2.compute.internal   Ready    <none>   4d    v1.11.5
ip-192-168-199-194.us-west-2.compute.internal   Ready    <none>   4d    v1.11.5


TO expose the Prometheus UI(from Local PC) so that we can have a look at some of the Pod/Container level metrics:

$ kubectl --namespace default port-forward $(kubectl get pods --namespace default -l\
  "app=prometheus,component=server" -o jsonpath="{.items[0].metadata.name}") 9090 &

$ Forwarding from 127.0.0.1:9090 -> 9090
	Forwarding from [::1]:9090 -> 9090


$ links http://localhost:9090


$ kubectl get pod -o wide
NAME                            READY   STATUS    RESTARTS   AGE   IP             
alpine-6b9858595b-7zncb         1/1     Running   117        4d    192.168.133.249 
curl-66df598c4-zwz5v            1/1     Running   9          3d    192.168.78.101 

# Finding a Service's IP
$ kubectl get service --all-namespaces





-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
-------------------------------------------------------------------------------

-------------------------------------------------------------------------------


-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
# Debug	connecting AWS EKS clusterAdmin
  
  # Check Who's ID is used for connection 
  $ aws sts get-caller-identity			<= AWS Security Token Service (STS)
	{
      "UserId": "AIDA...EYRK",
      "Account": "688595016292",
      "Arn": "arn:aws:iam::688595016292:user/clusterAdmin"
	}

  $ kubectl config view
    apiVersion: v1
	clusters:
		- cluster:
			certificate-authority-data: DATA+OMITTED
			server: https://F08A5CEEF5AC38E949E4AA91C2FE028D.sk1.us-west-2.eks.amazonaws.com
			name: arn:aws:eks:us-west-2:688595016292:cluster/classCluster
			......
			
  $ kubectl get svc --v=10				<= --v=5  verbose level 5
  
  # Version Check
  $ aws --version
		aws-cli/1.16.115 Python/3.6.7 Linux/3.10.0-957.1.3.el7.x86_64 botocore/1.12.105
		
  $ kubectl version --short --client
		Client Version: v1.13.4
	
  # RBAC <= Role-based access control (RBAC)

-------------------------------------------------------------------------------

##############################################################################
### CloudFormation
#   Training: https://www.linkedin.com/learning/learning-aws-cloudformation
##############################################################################

JSON or YAML <=	Contains a description of resources to be provision

Stacks	<= Instantiation of the template

Parameters 

Resources

Events
	
-------------------------------------------------------------------------------
3. Template
	Format Version
	Description
	Parameters
	Resources
	Outputs
	
-------------------------------------------------------------------------------
Resources
	"S3Bucket" : {
		"Type" : "AWS::S3::Bucket",
		"Properties" : { ... },
		"DeletionPolicy" : "Retain"
	}	

	WebsiteURL" : {
		"Value" : {
		"Descriptin" : 
	}
	
	




-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------

///////////////////////////////////////////////////////////////////////////////
-------------------------------------------------------------------------------
# AWS Certified DevOps Engineer – Professional
-------------------------------------------------------------------------------
///////////////////////////////////////////////////////////////////////////////

The DevOps Engineer certification is all about provisioning, operating, and managing 
applications on the AWS platform. This exam focuses heavily on continuous delivery (CD) 
and automation of processes, two fundamental concepts of the DevOps movement.

Prerequisites: Status as AWS Certified Developer – Associate or AWS Certified SysOps Administrator – Associate. 
Experience in provisioning and managing AWS-based applications, as well as a firm understanding 
of modern application development such as the agile development methodology, is recommended.

Format: Multiple choice, multiple answer
Time: 170 minutes
Cost: 300 USD
Areas Covered:
The basics of modern CD methodologies
How to implement CD systems
Set up, monitoring, and logging systems on AWS
How to implement highly available and scalable systems on AWS
How to design and manage tools that enable automation of production operations
Specialty Certification
AWS specialty certifications are designed to validate a candidate’s skills in big data and networking.

Prerequisites: Current associate-level certification and a minimum of five years of relevant experience
Format: Multiple choice, multiple answer
Time: 3 hours
Cost: 300 USD
Start preparing with Cloud Academy’s DevOps Engineer – Professional Certification Preparation for AWS Learning Path.


///////////////////////////////////////////////////////////////////////////////
-------------------------------------------------------------------------------
AWS DeveOps Engineer(Profecsional Cert Series) - 1 
AWS for DevOps: Continuous Delivery and Process Automation
https://www.linkedin.com/learning/aws-for-devops-continuous-delivery-and-process-automation
-------------------------------------------------------------------------------
///////////////////////////////////////////////////////////////////////////////

-------------------------------------------------------------------------------
1. Continuous Delivery (CD) and Automation Approaches
-------------------------------------------------------------------------------
	A. Automation Tools types and functions
		Service Template: AWS service configuration as code(script)
		Source Control  : Code repository- version control
		Test Runner		: Unit tests on runner
		Build			: Build code files
		Deploymnet Pipeline : Automation for deployment


	B. Continuous Delivery (CD)
		Source		=>   Build 		=>   Staging     => Production
		
	C. Source Control Systems
		VSTS and TFS			Microsoft				Integrated with IDE
		Github and Gitbucket	Github and Atlassian	Fee 
		Subversion & Mercurial	Open Source				Lack some features
		
	  - Schema/Config as Code - version it and check it in
		
	  - Pattern for CI/CD
		  Change DB schema First
		  Change DB schema Last
		
	D. Types of Testing
	
	  - Automation Tools and AWS Services
	    
		-Tool Type-			- AWS -				- Other types -
	    
		Service Template :	CloudFormation		Terraform, Puppet, Ansible, Chef
		
		Source Control	 :	CodeCommit			Git, Github
		
		Test Runners	 :	AWS Lambda			JUnit(Java), Cucumber(Node.js)
		
		Build			 : 	CodeBuild			Maven(Java)
		
		Deploy Pipeline	 :	CodeDeploy			Cruise control, GoCD, Jenkins
							CodePipeline		Travis CI, TFS
							CodeStar
	
	
	E. Types of Deployments
		
		Blue <===> Green  Deployment
		Live	   Stand-By
		
	F. CD and Serverless Achitectures
		Lambda(Compute) + S3(Data) 
	
		CD Tools by Node.js
		Config 			- AWS CLI Scripts
		Code			- GitHub
		Tests 			- node libraris
		Build Scripts 	- Node.js libraries(Grunt)
		CD Server 		- GoCD


										CloudFormation -> EC2
	Dev -> GitHub -> AWS CodePipeline /
									  \ 
                                        CodeBuild	-> ECR  -> EC2  

2. CD and Automation with Core AWS Services

	A. CodeStar(https://aws.amazon.com/codestar/)
		lets you quickly develop, build and deploy applications on AWS.

	Create: DemoServer
	Choose: Node.js
	
	B. Flow Chart
	Source		  => Build			=> Test		=> Deploy			=> Monitoring
	AWS CodeCommit	AWS CodeBuild   			AWS CloudFormation 	AWS CloudWatch

	C. Cloud9 <= A cloud IDE for writing, running, and debugging code
	
	D. Clone Repository URL
	https://git-codecommit.us-west-2.amazonaws.com/v1/repos/DemoServerLess

	E. Set up your AWS Cloud9 environment

	F. To check the site 
		Check "Application endpoint" link
		
		https://f47c66.execute-api.us-west-2.amazonaws.com/Prod/

		// Congratulations!
		// You just created a Node.js web application



























-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------

///////////////////////////////////////////////////////////////////////////////
-------------------------------------------------------------------------------
AWS DeveOps Engineer(Profecsional Cert Series) - 2
AWS for DevOps: Security, Governance, and Validation
https://www.linkedin.com/learning/aws-for-devops-security-governance-and-validation
-------------------------------------------------------------------------------
///////////////////////////////////////////////////////////////////////////////




-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------

///////////////////////////////////////////////////////////////////////////////
-------------------------------------------------------------------------------
AWS DeveOps Engineer(Profecsional Cert Series) - 3
AWS for DevOps: High Availability and Elasticity
https://www.linkedin.com/learning/aws-for-devops-high-availability-and-elasticity
-------------------------------------------------------------------------------
///////////////////////////////////////////////////////////////////////////////












-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
AWS DeveOps Engineer(Profecsional Cert Series) - 4
AWS for DevOps: Monitoring, Metrics, and Logging
https://www.linkedin.com/learning/aws-for-devops-monitoring-metrics-and-logging
-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------
-------------------------------------------------------------------------------































































































































############################################################################
1. CloudTrail
############################################################################

	a. CloudTrail Viewer Tool
	https://github.com/githublemming/CloudTrailViewer/releases

# Create a S3 bucket	
$aws s3api create-bucket --bucket bnea-cloudtrail-bucket --region us-east-1
{
    "Location": "/bnea-cloudtrail-bucket"
}

# Create a Policy
##############################################################################
{
	"Version": "2012-10-17",
	"Statement": [{
			"Sid": "AWSCloudTrailAclCheck20150319",
			"Effect": "Allow",
			"Principal": {
				"Service": "cloudtrail.amazonaws.com"
			},
			"Action": "s3:GetBucketAcl",
			"Resource": "arn:aws:s3:::bnga-cloudtrail-bucket"
		},
		{
			"Sid": "AWSCloudTrailWrite20150319",
			"Effect": "Allow",
			"Principal": {
				"Service": "cloudtrail.amazonaws.com"
			},
			"Action": "s3:PutObject",
			"Resource": "arn:aws:s3:::bnea-cloudtrail-bucket/[optional prefix]/AWSLogs/myAccountID/*",
			"Condition": {
				"StringEquals": {
					"s3:x-amz-acl": "bucket-owner-full-control"
				}
			}
		}
	]
}
##############################################################################













